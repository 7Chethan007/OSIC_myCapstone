{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**V2 Testing**","metadata":{}},{"cell_type":"code","source":"# Pulmonary Fibrosis Progression: EDA, Modeling & Submission\n# This notebook combines the best EDA/visualization from V2 with the full modeling pipeline from V1.\n# 1. Data Loading & Exploratory Data Analysis (EDA)\nimport os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport random\nfrom tqdm import tqdm \nfrom datetime import timedelta, datetime\nfrom pathlib import Path\nimport json\nimport warnings\nimport pickle\nimport glob\n# Image processing\nfrom skimage import measure, morphology, segmentation\nfrom skimage.transform import resize\nfrom scipy.ndimage import binary_dilation, binary_erosion\nfrom skimage.measure import label, regionprops\nfrom sklearn.cluster import KMeans\nfrom skimage.segmentation import clear_border\n# Deep learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom torch.cuda.amp import autocast, GradScaler\n# Albumentations for medical augmentations\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\nwarnings.filterwarnings('ignore')\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nseed_everything(42)\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"ðŸš€ Pulmonary Fibrosis Progression Analysis\")\n# Load dataset\ntrain_df = pd.read_csv(DATA_DIR / 'train.csv')\nprint(f'{train_df.shape[0]} Rows and {train_df.shape[1]} Columns in train data')\nprint(\"\\nTrain data sample:\")\ndisplay(train_df.head())\nprint(\"\\nTrain data statistics:\")\ndisplay(train_df.describe())\n# Data visualizations\nplt.figure(figsize=(10, 8))\nnumeric_cols = train_df.select_dtypes(include=[np.number])\nsns.heatmap(numeric_cols.corr(), annot=True, cmap=plt.cm.plasma)\nplt.title('Correlation Matrix')\nplt.tight_layout()\nplt.show()\nplt.figure(figsize=(12, 6))\nsns.countplot(x='Age', hue='SmokingStatus', data=train_df)\nplt.title('Age Distribution by Smoking Status')\nplt.tight_layout()\nplt.show()\n# Uniqueness check\nunique_patients = train_df['Patient'].nunique()\nprint(f'The Number of Unique Patients in training data: {unique_patients}')\ndef chart_patient_data(patient_id, ax):\n    plot_data = train_df[train_df['Patient']==patient_id]\n    ax.set_title(f\"Patient: {patient_id}\")\n    return sns.regplot(x='Weeks', y='FVC', data=plot_data, ax=ax, ci=None, line_kws={'color':'red'})\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\npatients_to_plot = train_df['Patient'].unique()[:3]\nfor i, patient in enumerate(patients_to_plot):\n    chart_patient_data(patient, axes[i])\nplt.tight_layout()\nplt.show()\n# Patient demographics visualization\npatient_info = train_df.groupby(by=\"Patient\")[[\"Patient\", \"Age\", \"Sex\", \"SmokingStatus\"]].first().reset_index(drop=True)\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\nsns.distplot(patient_info[\"Age\"], ax=ax1, hist=False, kde_kws=dict(lw=6, ls=\"--\"))\nsns.countplot(x=\"Sex\", data=patient_info, ax=ax2)\nsns.countplot(x=\"SmokingStatus\", data=patient_info, ax=ax3)\nax1.set_title(\"Patient Age Distribution\", fontsize=16)\nax2.set_title(\"Sex Distribution\", fontsize=16)\nax3.set_title(\"Smoking Status Distribution\", fontsize=16)\nplt.tight_layout()\nplt.show()\n# FVC and Percent distribution\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\nsns.distplot(train_df[\"FVC\"], ax=ax1, hist=False, kde_kws=dict(lw=6, ls=\"--\"))\nsns.distplot(train_df[\"Percent\"], ax=ax2, hist=False, kde_kws=dict(lw=6, ls=\"-.\"))\nax1.set_title(\"FVC Distribution\", fontsize=16)\nax2.set_title(\"Percent Distribution\", fontsize=16)\nplt.tight_layout()\nplt.show()\n# 2. Train/Val/Test Split from train_df only\nfrom sklearn.model_selection import train_test_split\nall_patients = train_df['Patient'].unique()\ntrain_valid_patients, test_patients = train_test_split(\n    all_patients, test_size=0.2, random_state=42, shuffle=True)\ntrain_patients, val_patients = train_test_split(\n    train_valid_patients, test_size=0.2, random_state=42, shuffle=True)\nprint(f\"Train split: {len(train_patients)} patients ({len(train_patients)/len(all_patients):.1%})\")\nprint(f\"Validation split: {len(val_patients)} patients ({len(val_patients)/len(all_patients):.1%})\")\nprint(f\"Test split: {len(test_patients)} patients ({len(test_patients)/len(all_patients):.1%})\")\nprint(\"=\" * 60)\n# ...existing code from V1 for image processing, feature engineering, model architecture, training, and evaluation...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:40.510121Z","iopub.execute_input":"2025-08-12T15:35:40.510834Z","iopub.status.idle":"2025-08-12T15:35:42.575172Z","shell.execute_reply.started":"2025-08-12T15:35:40.510804Z","shell.execute_reply":"2025-08-12T15:35:42.574570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 1: Data Loading and Exploratory Data Analysis\n# --------------------------------------------------\n\n# Load datasets\ntrain_df = pd.read_csv(DATA_DIR / 'train.csv')\ntest_df = pd.read_csv(DATA_DIR / 'test.csv')\n\nprint(f'{train_df.shape[0]} Rows and {train_df.shape[1]} Columns in train data')\nprint(f'{test_df.shape[0]} Rows and {test_df.shape[1]} Columns in test data')\n\n# Display sample data\nprint(\"\\nTrain data sample:\")\ndisplay(train_df.head())\n\nprint(\"\\nTest data sample:\")\ndisplay(test_df.head())\n\n# Descriptive statistics\nprint(\"\\nTrain data statistics:\")\ndisplay(train_df.describe())\n\n# Data visualizations\nplt.figure(figsize=(10, 8))\nnumeric_cols = train_df.select_dtypes(include=[np.number])\nsns.heatmap(numeric_cols.corr(), annot=True, cmap=plt.cm.plasma)\nplt.title('Correlation Matrix')\nplt.tight_layout()\nplt.show()\n\n# Patient demographics\nplt.figure(figsize=(12, 6))\nsns.countplot(x='Age', hue='SmokingStatus', data=train_df)\nplt.title('Age Distribution by Smoking Status')\nplt.tight_layout()\nplt.show()\n\n# Uniqueness check\nunique_patients = train_df['Patient'].nunique()\nprint(f'The Number of Unique Patients in training data: {unique_patients}')\n\n# FVC decline visualization\ndef chart_patient_data(patient_id, ax):\n    plot_data = train_df[train_df['Patient']==patient_id]\n    ax.set_title(f\"Patient: {patient_id}\")\n    return sns.regplot(x='Weeks', y='FVC', data=plot_data, ax=ax, \n                       ci=None, line_kws={'color':'red'})\n\n# Sample 3 patients\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\npatients_to_plot = train_df['Patient'].unique()[:3]\nfor i, patient in enumerate(patients_to_plot):\n    chart_patient_data(patient, axes[i])\nplt.tight_layout()\nplt.show()\n\n# Patient demographics visualization\n# Select unique bio info for the patients\npatient_info = train_df.groupby(by=\"Patient\")[[\"Patient\", \"Age\", \"Sex\", \"SmokingStatus\"]].first().reset_index(drop=True)\n\n# Figure\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n\nsns.distplot(patient_info[\"Age\"], ax=ax1, hist=False, kde_kws=dict(lw=6, ls=\"--\"))\nsns.countplot(x=\"Sex\", data=patient_info, ax=ax2)\nsns.countplot(x=\"SmokingStatus\", data=patient_info, ax=ax3)\n\nax1.set_title(\"Patient Age Distribution\", fontsize=16)\nax2.set_title(\"Sex Distribution\", fontsize=16)\nax3.set_title(\"Smoking Status Distribution\", fontsize=16)\nplt.tight_layout()\nplt.show()\n\n# FVC and Percent distribution\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\nsns.distplot(train_df[\"FVC\"], ax=ax1, hist=False, kde_kws=dict(lw=6, ls=\"--\"))\nsns.distplot(train_df[\"Percent\"], ax=ax2, hist=False, kde_kws=dict(lw=6, ls=\"-.\"))\n\nax1.set_title(\"FVC Distribution\", fontsize=16)\nax2.set_title(\"Percent Distribution\", fontsize=16)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:47.122920Z","iopub.execute_input":"2025-08-12T15:35:47.123644Z","iopub.status.idle":"2025-08-12T15:35:49.437688Z","shell.execute_reply.started":"2025-08-12T15:35:47.123620Z","shell.execute_reply":"2025-08-12T15:35:49.436961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 2: Feature Engineering and Model Preparation\n# -------------------------------------------------\n\n# Calculate linear decay coefficients for each patient\nprint(\"Calculating linear decay coefficients...\")\nA = {}  # Decay coefficients\nTAB = {}  # Tabular features\nP = []  # Patient list\n\ndef get_tab_features(df_row):\n    \"\"\"Extract tabular features (returns 4 features)\"\"\"\n    vector = [(df_row['Age'] - 30) / 30] \n    \n    # Sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(0)\n    else:\n        vector.append(1)\n    \n    # Smoking status encoding\n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([1, 1])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 1])\n    else:\n        vector.extend([1, 0])\n    return np.array(vector)\n\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy()\n    fvc = sub['FVC'].values\n    weeks = sub['Weeks'].values\n    \n    if len(weeks) > 1:\n        c = np.vstack([weeks, np.ones(len(weeks))]).T\n        try:\n            a, b = np.linalg.lstsq(c, fvc, rcond=None)[0]\n            A[patient] = a\n            TAB[patient] = get_tab_features(sub.iloc[0])\n            P.append(patient)\n        except:\n            # Use fallback method for patients with insufficient data\n            A[patient] = (fvc[-1] - fvc[0]) / (weeks[-1] - weeks[0]) if len(weeks) > 1 else 0.0\n            TAB[patient] = get_tab_features(sub.iloc[0])\n            P.append(patient)\n    else:\n        A[patient] = 0.0\n        TAB[patient] = get_tab_features(sub.iloc[0])\n        P.append(patient)\n\nprint(f\"Processed {len(P)} patients with decay coefficients\")\n\n# Visualize decay coefficients\nplt.figure(figsize=(12, 6))\nplt.hist(list(A.values()), bins=30)\nplt.title(\"Distribution of FVC Decay Coefficients\")\nplt.xlabel(\"Decay Rate (FVC/Week)\")\nplt.ylabel(\"Count\")\nplt.axvline(0, color='red', linestyle='--')\nplt.text(0, plt.ylim()[1]*0.9, \"No Change\", rotation=90, color='red')\nplt.grid(alpha=0.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:49.439075Z","iopub.execute_input":"2025-08-12T15:35:49.439492Z","iopub.status.idle":"2025-08-12T15:35:49.740847Z","shell.execute_reply.started":"2025-08-12T15:35:49.439473Z","shell.execute_reply":"2025-08-12T15:35:49.739999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 3: DICOM Image Exploration and Processing\n# ----------------------------------------------\n\n# Load sample DICOM images for visualization\ntrain_image_files = sorted(glob.glob(os.path.join(TRAIN_DIR, '*', '*.dcm')))\nprint(f'Found {len(train_image_files)} DICOM images')\n\n# Function to load scan and convert to Hounsfield Units\ndef load_scan(path):\n    \"\"\"Load DICOM slices from a folder\"\"\"\n    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key=lambda x: int(x.InstanceNumber))\n    \n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices\n\ndef get_pixels_hu(scans):\n    \"\"\"Convert DICOM to Hounsfield Units (HU)\"\"\"\n    image = np.stack([s.pixel_array for s in scans])\n    image = image.astype(np.int16)\n    \n    # Set out-of-scan pixels to 0\n    image[image == -2000] = 0\n    \n    # Convert to HU\n    intercept = scans[0].RescaleIntercept\n    slope = scans[0].RescaleSlope\n    \n    if slope != 1:\n        image = slope * image.astype(np.float64)\n        image = image.astype(np.int16)\n        \n    image += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)\n\n# Load sample patient scans\nsample_patient_id = P[0]\nsample_patient_path = os.path.join(TRAIN_DIR, sample_patient_id)\nif os.path.exists(sample_patient_path):\n    sample_scans = load_scan(sample_patient_path)\n    sample_images_hu = get_pixels_hu(sample_scans)\n    \n    # Display some slices\n    num_slices = min(5, len(sample_images_hu))\n    fig, axes = plt.subplots(1, num_slices, figsize=(20, 5))\n    for i in range(num_slices):\n        axes[i].imshow(sample_images_hu[i], cmap=plt.cm.bone)\n        axes[i].set_title(f\"Slice {i+1}\")\n        axes[i].axis('off')\n    plt.tight_layout()\n    plt.show()\n    \n    # Create an animated view\n    def set_lungwin(img, hu=[-1200., 600.]):\n        \"\"\"Adjust window for lung visualization\"\"\"\n        lungwin = np.array(hu)\n        newimg = (img-lungwin[0]) / (lungwin[1]-lungwin[0])\n        newimg[newimg < 0] = 0\n        newimg[newimg > 1] = 1\n        newimg = (newimg * 255).astype('uint8')\n        return newimg\n    \n    # Create a lung mask function combining both approaches\n    def make_lungmask(img, display=False):\n        \"\"\"Create a mask of the lungs in the image\"\"\"\n        row_size = img.shape[0]\n        col_size = img.shape[1]\n        \n        # Normalize image\n        mean = np.mean(img)\n        std = np.std(img)\n        img = img-mean\n        img = img/std\n        \n        # Find average pixel value near lungs for normalization\n        middle = img[int(col_size/5):int(col_size/5*4),int(row_size/5):int(row_size/5*4)] \n        mean = np.mean(middle)  \n        max_val = np.max(img)\n        min_val = np.min(img)\n        \n        # Adjust outliers\n        img[img==max_val] = mean\n        img[img==min_val] = mean\n        \n        # Use KMeans to separate foreground and background\n        kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n        centers = sorted(kmeans.cluster_centers_.flatten())\n        threshold = np.mean(centers)\n        thresh_img = np.where(img<threshold,1.0,0.0)\n        \n        # Morphological operations to refine mask\n        eroded = morphology.erosion(thresh_img, np.ones([3,3]))\n        dilation = morphology.dilation(eroded, np.ones([8,8]))\n        \n        # Label regions\n        labels = measure.label(dilation)\n        regions = measure.regionprops(labels)\n        \n        # Select lung regions\n        good_labels = []\n        for prop in regions:\n            B = prop.bbox\n            if (B[2]-B[0]<row_size/10*9 and B[3]-B[1]<col_size/10*9 and \n                B[0]>row_size/5 and B[2]<col_size/5*4):\n                good_labels.append(prop.label)\n                \n        # Create final mask\n        mask = np.zeros([row_size,col_size], dtype=np.int8)\n        for n in good_labels:\n            mask = mask + np.where(labels==n,1,0)\n            \n        # Final dilation\n        mask = morphology.dilation(mask, np.ones([10,10]))\n        \n        # Display steps if requested\n        if display:\n            fig, ax = plt.subplots(3, 2, figsize=[12, 12])\n            ax[0, 0].set_title(\"Original\")\n            ax[0, 0].imshow(img, cmap='gray')\n            ax[0, 0].axis('off')\n            ax[0, 1].set_title(\"Threshold\")\n            ax[0, 1].imshow(thresh_img, cmap='gray')\n            ax[0, 1].axis('off')\n            ax[1, 0].set_title(\"After Erosion and Dilation\")\n            ax[1, 0].imshow(dilation, cmap='gray')\n            ax[1, 0].axis('off')\n            ax[1, 1].set_title(\"Color Labels\")\n            ax[1, 1].imshow(labels)\n            ax[1, 1].axis('off')\n            ax[2, 0].set_title(\"Final Mask\")\n            ax[2, 0].imshow(mask, cmap='gray')\n            ax[2, 0].axis('off')\n            ax[2, 1].set_title(\"Apply Mask on Original\")\n            ax[2, 1].imshow(mask*img, cmap='gray')\n            ax[2, 1].axis('off')\n            plt.tight_layout()\n            plt.show()\n            \n        return mask*img\n    \n    # Apply lung mask to a sample image\n    if len(sample_images_hu) > 0:\n        mask_img = make_lungmask(sample_images_hu[len(sample_images_hu)//2], display=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:49.741636Z","iopub.execute_input":"2025-08-12T15:35:49.741831Z","iopub.status.idle":"2025-08-12T15:35:50.120979Z","shell.execute_reply.started":"2025-08-12T15:35:49.741816Z","shell.execute_reply":"2025-08-12T15:35:50.120054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 4: Advanced Data Augmentation for Deep Learning\n# ---------------------------------------------------\n\nclass MedicalAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                # Geometric augmentations\n                albu.Rotate(limit=15, p=0.7),\n                albu.HorizontalFlip(p=0.5),\n                albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),\n                \n                # Medical-specific augmentations\n                albu.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n                albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n                \n                # Lung-specific augmentations for robustness\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n                albu.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n                \n                # Cutout for robustness\n                albu.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n                \n                # Normalization\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n    \n    def __call__(self, image):\n        return self.transform(image=image)['image']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:50.121456Z","iopub.status.idle":"2025-08-12T15:35:50.121696Z","shell.execute_reply.started":"2025-08-12T15:35:50.121568Z","shell.execute_reply":"2025-08-12T15:35:50.121581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 5: Dataset Class\n# --------------------\n\nclass OSICDenseNetDataset(Dataset):\n    \"\"\"Enhanced dataset with medical augmentations and robust loading\"\"\"\n    \n    def __init__(self, patients, A_dict, TAB_dict, data_dir, split='train', augment=True):\n        self.patients = [p for p in patients if p not in ['ID00011637202177653955184', 'ID00052637202186188008618']]\n        self.A_dict = A_dict\n        self.TAB_dict = TAB_dict\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augment = augment\n        self.augmentor = MedicalAugmentation(augment=augment)\n        \n        # Prepare image paths for each patient\n        self.patient_images = {}\n        for patient in self.patients:\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = [f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm']\n                if image_files:\n                    self.patient_images[patient] = image_files\n        \n        # Filter patients with available images\n        self.valid_patients = [p for p in self.patients if p in self.patient_images]\n        print(f\"Dataset {split}: {len(self.valid_patients)} patients with images\")\n    \n    def __len__(self):\n        # For training, use multiple samples per patient\n        if self.split == 'train':\n            return len(self.valid_patients) * 6  # More augmented samples\n        else:\n            return len(self.valid_patients)\n    \n    def __getitem__(self, idx):\n        if self.split == 'train':\n            patient_idx = idx % len(self.valid_patients)\n        else:\n            patient_idx = idx\n            \n        patient = self.valid_patients[patient_idx]\n        \n        # Get random image for this patient\n        available_images = self.patient_images[patient]\n        if len(available_images) > 1:\n            selected_image = np.random.choice(available_images)\n        else:\n            selected_image = available_images[0]\n        \n        # Load and preprocess image\n        img = self.load_and_preprocess_dicom(selected_image)\n        \n        # Apply augmentations\n        img_tensor = self.augmentor(img)\n        \n        # Get tabular features\n        tab_features = torch.tensor(self.TAB_dict[patient], dtype=torch.float32)\n        \n        # Get target (decay coefficient)\n        target = torch.tensor(self.A_dict[patient], dtype=torch.float32)\n        \n        return img_tensor, tab_features, target, patient\n    \n    def load_and_preprocess_dicom(self, path):\n        \"\"\"Enhanced DICOM loading with better preprocessing\"\"\"\n        try:\n            # Load DICOM\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            \n            # Handle different DICOM formats\n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]  # Take middle slice if 3D\n            \n            # Resize to target size\n            img = cv2.resize(img, (512, 512))\n            \n            # Normalize to 0-255 range\n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            \n            # Convert to 3-channel\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            \n            return img\n            \n        except Exception as e:\n            print(f\"Error loading DICOM {path}: {e}\")\n            # Return a black image as fallback\n            return np.zeros((512, 512, 3), dtype=np.uint8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:50.122749Z","iopub.status.idle":"2025-08-12T15:35:50.123084Z","shell.execute_reply.started":"2025-08-12T15:35:50.122900Z","shell.execute_reply":"2025-08-12T15:35:50.122913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 6: Model Architecture\n# -------------------------\n\n# Helper classes for the model\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_cat = torch.cat([avg_out, max_out], dim=1)\n        x_cat = self.conv1(x_cat)\n        return x * self.sigmoid(x_cat)\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n           \n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return x * self.sigmoid(out)\n\n# Main model\nclass WorkingDenseNetModel(nn.Module):\n    \"\"\"\n    DenseNet model with attention mechanisms and uncertainty estimation\n    \"\"\"\n    \n    def __init__(self, tabular_dim=4, dropout_rate=0.4):\n        super(WorkingDenseNetModel, self).__init__()\n        \n        # DenseNet121 backbone\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        \n        # Spatial attention\n        self.spatial_attention = SpatialAttention()\n        \n        # Enhanced tabular processing\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),  # Increased to 256\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 512),  # Final tabular features: 512\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        \n        # Cross-modal attention\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=1024, num_heads=8, dropout=0.2, batch_first=True\n        )\n        \n        # Multi-modal fusion\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 512, 768),  # 1024 (img) + 512 (tab) = 1536 -> 768\n            nn.BatchNorm1d(768),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(768, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2)\n        )\n        \n        # Uncertainty quantification heads\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        \n        # Extract image features\n        img_features = self.features(images)  # [B, 1024, H, W]\n        \n        # Apply spatial attention\n        img_features = self.spatial_attention(img_features)\n        \n        # Global average pooling\n        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n        img_features = img_features.view(batch_size, -1)  # [B, 1024]\n        \n        # Process tabular data\n        tab_features = self.tabular_processor(tabular)  # [B, 512]\n        \n        # Cross-modal attention\n        img_expanded = img_features.unsqueeze(1)  # [B, 1, 1024]\n        tab_expanded = tab_features.unsqueeze(1)  # [B, 1, 512]\n        \n        # Project tabular to same dimension for attention\n        tab_proj = F.linear(tab_expanded, \n                           torch.randn(1024, 512).to(images.device))  # [B, 1, 1024]\n        \n        attended_img, _ = self.cross_attention(\n            img_expanded, tab_proj, tab_proj\n        )\n        attended_img = attended_img.squeeze(1)  # [B, 1024]\n        \n        # Fusion\n        combined_features = torch.cat([attended_img, tab_features], dim=1)  # [B, 1536]\n        fused_features = self.fusion_layer(combined_features)\n        \n        # Predict mean and log variance\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        \n        return mean_pred.squeeze(), log_var.squeeze()\n\n# Initialize model\nmodel = WorkingDenseNetModel(tabular_dim=4).to(DEVICE)\nprint(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:53.684417Z","iopub.execute_input":"2025-08-12T15:35:53.685038Z","iopub.status.idle":"2025-08-12T15:35:53.965223Z","shell.execute_reply.started":"2025-08-12T15:35:53.685016Z","shell.execute_reply":"2025-08-12T15:35:53.964542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 7: Data Split and Loaders\n# -----------------------------\n\n# Split patients into train and validation\nfrom sklearn.model_selection import train_test_split\n\npatients_list = list(P)\ntrain_patients, val_patients = train_test_split(\n    patients_list, \n    test_size=0.2, \n    random_state=42,\n    shuffle=True\n)\n\nprint(f\"Train patients: {len(train_patients)}\")\nprint(f\"Validation patients: {len(val_patients)}\")\n\n# Create datasets\ntrain_dataset = OSICDenseNetDataset(\n    patients=train_patients,\n    A_dict=A,\n    TAB_dict=TAB,\n    data_dir=TRAIN_DIR,\n    split='train',\n    augment=True\n)\n\nval_dataset = OSICDenseNetDataset(\n    patients=val_patients,\n    A_dict=A,\n    TAB_dict=TAB,\n    data_dir=TRAIN_DIR,\n    split='val',\n    augment=False\n)\n\n# Create data loaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=8,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=False\n)\n\n\nprint(f\"Data loaders created: {len(train_loader)} training batches, {len(val_loader)} validation batches\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:55.839268Z","iopub.execute_input":"2025-08-12T15:35:55.839538Z","iopub.status.idle":"2025-08-12T15:35:56.095077Z","shell.execute_reply.started":"2025-08-12T15:35:55.839518Z","shell.execute_reply":"2025-08-12T15:35:56.094455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 8: Training with Uncertainty\n# --------------------------------\n\nclass CorrectedSimpleTrainer:\n    \"\"\"\n    Trainer with proper sigma learning and uncertainty estimation\n    \"\"\"\n    \n    def __init__(self, model, device, lr=1e-4):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.best_val_mae = float('inf')\n        self.best_val_lll = float('-inf')  # For actual log-likelihood (negative values)\n        \n    def uncertainty_loss(self, mean_pred, log_var, targets, reduction='mean'):\n        \"\"\"Uncertainty-aware loss function\"\"\"\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        \n        # Add penalty for poor uncertainty estimation\n        uncertainty_penalty = torch.mean(torch.abs(log_var - torch.log(mse_loss + 1e-6)))\n        \n        loss = 0.5 * (mse_loss / var + log_var) + 0.05 * uncertainty_penalty\n        \n        if reduction == 'mean':\n            return loss.mean()\n        return loss.sum()\n        \n    def laplace_log_likelihood(self, y_true, y_pred, log_var):\n        \"\"\"\n        Calculate ACTUAL Laplace Log Likelihood\n        Returns actual log-likelihood (negative values, higher is better)\n        \"\"\"\n        # Convert log variance to standard deviation (sigma)\n        sigma = torch.exp(log_var / 2.0)\n        \n        # Allow dynamic learning with reasonable bounds\n        sigma = torch.clamp(sigma, min=2.0, max=200.0)\n        \n        abs_errors = torch.abs(y_true - y_pred)\n        \n        # ACTUAL log-likelihood: log(1/(2Ïƒ)) - |y-Î¼|/Ïƒ\n        # = -log(2Ïƒ) - |y-Î¼|/Ïƒ\n        log_likelihood = -torch.log(2.0 * sigma) - abs_errors / sigma\n        \n        # Return ACTUAL log-likelihood (negative values, higher is better)\n        return torch.mean(log_likelihood)\n        \n    def train(self, train_loader, val_loader, epochs=30, patience=8):\n        # Better optimizer settings for uncertainty learning\n        optimizer = torch.optim.AdamW(\n            self.model.parameters(), \n            lr=5e-5,  # Lower learning rate for better uncertainty learning\n            weight_decay=1e-5\n        )\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='max', factor=0.5, patience=4, verbose=True  # mode='max' for log-likelihood\n        )\n        \n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            # Training phase\n            self.model.train()\n            train_loss = 0.0\n            train_mae = 0.0\n            train_lll = 0.0\n            train_batches = 0\n            \n            for batch_idx, (images, tabular, targets, _) in enumerate(train_loader):\n                try:\n                    images = images.to(self.device)\n                    tabular = tabular.to(self.device) \n                    targets = targets.to(self.device)\n                    \n                    optimizer.zero_grad()\n                    \n                    # Forward pass\n                    mean_pred, log_var = self.model(images, tabular)\n                    \n                    # Calculate losses and metrics\n                    loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                    mae = F.l1_loss(mean_pred, targets)\n                    lll = self.laplace_log_likelihood(targets, mean_pred, log_var)\n                    \n                    # Backward pass\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                    optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_mae += mae.item()\n                    train_lll += lll.item()\n                    train_batches += 1\n                    \n                except Exception as e:\n                    print(f\"Error in training batch {batch_idx}: {e}\")\n                    continue\n            \n            # Validation phase\n            self.model.eval()\n            val_loss = 0.0\n            val_mae = 0.0\n            val_lll = 0.0\n            val_predictions = []\n            val_targets = []\n            val_sigmas = []\n            \n            with torch.no_grad():\n                for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                    try:\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        \n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        # Calculate all metrics\n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        mae = F.l1_loss(mean_pred, targets)\n                        lll = self.laplace_log_likelihood(targets, mean_pred, log_var)\n                        \n                        # Calculate sigma values for debugging\n                        sigma = torch.exp(log_var / 2.0)\n                        sigma = torch.clamp(sigma, min=2.0, max=200.0)\n                        \n                        val_loss += loss.item()\n                        val_mae += mae.item()\n                        val_lll += lll.item()\n                        \n                        val_predictions.extend(mean_pred.cpu().numpy())\n                        val_targets.extend(targets.cpu().numpy())\n                        val_sigmas.extend(sigma.cpu().numpy())\n                        \n                    except Exception as e:\n                        print(f\"Error in validation batch {batch_idx}: {e}\")\n                        continue\n            \n            # Calculate comprehensive metrics\n            if train_batches > 0 and len(val_predictions) > 0:\n                # Average training metrics\n                avg_train_loss = train_loss / train_batches\n                avg_train_mae = train_mae / train_batches\n                avg_train_lll = train_lll / train_batches\n                \n                # Average validation metrics\n                avg_val_loss = val_loss / len(val_loader)\n                avg_val_mae = val_mae / len(val_loader)\n                avg_val_lll = val_lll / len(val_loader)\n                \n                # Convert to numpy arrays for additional metrics\n                val_predictions = np.array(val_predictions)\n                val_targets = np.array(val_targets)\n                val_sigmas = np.array(val_sigmas)\n                \n                # Calculate RMSE\n                val_rmse = np.sqrt(np.mean((val_predictions - val_targets) ** 2))\n                \n                # Calculate RÂ²\n                ss_res = np.sum((val_targets - val_predictions) ** 2)\n                ss_tot = np.sum((val_targets - np.mean(val_targets)) ** 2)\n                r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else -float('inf')\n                \n                # Sigma statistics\n                avg_sigma = np.mean(val_sigmas)\n                min_sigma = np.min(val_sigmas)\n                max_sigma = np.max(val_sigmas)\n                \n                # Enhanced printing with all metrics and debugging info\n                print(f\"Epoch {epoch+1}/{epochs}\")\n                print(f\"Train Loss: {avg_train_loss:.6f} | Train LLL: {avg_train_lll:.6f} | Train MAE: {avg_train_mae:.6f}\")\n                print(f\"Val Loss: {avg_val_loss:.6f} | Val LLL: {avg_val_lll:.6f} | MAE: {avg_val_mae:.6f} | RMSE: {val_rmse:.6f} | RÂ²: {r2:.6f}\")\n                print(f\"Sigma Stats: Avg={avg_sigma:.2f}, Range=[{min_sigma:.2f}, {max_sigma:.2f}]\")\n                \n                # Learning rate scheduling (using log-likelihood now)\n                scheduler.step(avg_val_lll)\n                \n                # Early stopping and model saving (using actual LLL - higher is better)\n                if avg_val_lll > self.best_val_lll:  # Higher log-likelihood is better\n                    self.best_val_lll = avg_val_lll\n                    self.best_val_mae = avg_val_mae\n                    torch.save(self.model.state_dict(), 'best_model.pth')\n                    print(\"âœ… New best model saved! (Best Log Likelihood)\")\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n                    \n                if patience_counter >= patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n                    \n                print(\"-\" * 70)\n        \n        return self.best_val_mae","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:57.089979Z","iopub.execute_input":"2025-08-12T15:35:57.090719Z","iopub.status.idle":"2025-08-12T15:35:57.108959Z","shell.execute_reply.started":"2025-08-12T15:35:57.090694Z","shell.execute_reply":"2025-08-12T15:35:57.108394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 9: Submission Generation with Confidence\n# -------------------------------------------\n\nclass TTAPredictor:\n    \"\"\"Test-time augmentation for more robust predictions\"\"\"\n    def __init__(self, model, num_augmentations=5):\n        self.model = model\n        self.num_augmentations = num_augmentations\n        self.augmentor = MedicalAugmentation(augment=True)\n        self.model.eval()\n    \n    def predict(self, image, tabular):\n        # Original prediction\n        with torch.no_grad():\n            mean_pred, log_var = self.model(image.unsqueeze(0), tabular.unsqueeze(0))\n            mean_preds = [mean_pred.item()]\n            log_vars = [log_var.item()]\n        \n        # Augmented predictions\n        for _ in range(self.num_augmentations):\n            try:\n                # Apply augmentation\n                aug_img = self.augmentor(image.permute(1, 2, 0).numpy().astype(np.uint8))\n                aug_img = aug_img.to(image.device)\n                \n                # Predict\n                with torch.no_grad():\n                    mean_pred, log_var = self.model(aug_img.unsqueeze(0), tabular.unsqueeze(0))\n                    mean_preds.append(mean_pred.item())\n                    log_vars.append(log_var.item())\n                    \n            except Exception as e:\n                print(f\"Error in TTA: {e}\")\n                continue\n        \n        # Ensemble predictions\n        mean_ensemble = np.median(mean_preds)\n        log_var_ensemble = np.median(log_vars)\n        \n        # Calculate uncertainty (standard deviation)\n        std = np.sqrt(np.exp(log_var_ensemble))\n        \n        return mean_ensemble, std\n\ndef create_submission_with_confidence(model, test_dir, output_file='submission.csv'):\n    \"\"\"Create submission with confidence intervals\"\"\"\n    print(f\"ðŸ“ Creating submission with confidence intervals...\")\n    \n    # Load test data\n    test_df = pd.read_csv(DATA_DIR / 'test.csv')\n    print(f\"âœ… Loaded test data: {len(test_df)} samples\")\n    \n    submissions = []\n    model.eval()\n    \n    # Create augmentor for test time augmentation\n    test_augmentor = MedicalAugmentation(augment=False)\n    \n    print(\"ðŸ”„ Processing test patients...\")\n    \n    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing\"):\n        patient_id = row['Patient']\n        weeks = row['Weeks']\n        \n        try:\n            # Load patient image\n            patient_dir = Path(test_dir) / patient_id\n            \n            # Default prediction values\n            fvc_pred = 2000.0  # Default FVC\n            confidence_val = 200.0  # Default confidence\n            \n            if patient_dir.exists():\n                image_files = list(patient_dir.glob('*.dcm'))\n                if image_files:\n                    # Load and preprocess image\n                    img = load_and_preprocess_dicom(image_files[0])\n                    img_tensor = test_augmentor(img).unsqueeze(0).to(DEVICE)\n                    \n                    # Prepare tabular features\n                    tab_features = get_tab_features(row)\n                    tab_tensor = torch.tensor(tab_features).float().unsqueeze(0).to(DEVICE)\n                    \n                    # Predict with uncertainty\n                    with torch.no_grad():\n                        mean_pred, log_var = model(img_tensor, tab_tensor)\n                        fvc_pred = mean_pred.item()\n                        confidence_val = max(torch.exp(log_var/2).item() * 70, 70)  # Scale and set minimum\n            \n            # Create submission rows for required weeks\n            for week in range(-12, 134):  # Standard competition range\n                patient_week = f\"{patient_id}_{week}\"\n                \n                # Adjust prediction based on time progression\n                if patient_id in A:\n                    time_adjusted_fvc = fvc_pred + (week - weeks) * A[patient_id]\n                else:\n                    time_adjusted_fvc = fvc_pred + (week - weeks) * (-7)  # Default decay\n                \n                # Ensure reasonable bounds\n                time_adjusted_fvc = max(time_adjusted_fvc, 800)  # Minimum FVC\n                time_adjusted_fvc = min(time_adjusted_fvc, 6000)  # Maximum FVC\n                \n                submissions.append({\n                    'Patient_Week': patient_week,\n                    'FVC': time_adjusted_fvc,\n                    'Confidence': confidence_val\n                })\n                \n        except Exception as e:\n            print(f\"âš ï¸ Error processing patient {patient_id}: {e}\")\n            # Use default values for this patient\n            for week in range(-12, 134):\n                patient_week = f\"{patient_id}_{week}\"\n                submissions.append({\n                    'Patient_Week': patient_week,\n                    'FVC': 2000.0,\n                    'Confidence': 200.0\n                })\n    \n    # Create submission dataframe\n    submission_df = pd.DataFrame(submissions)\n    submission_df.to_csv(output_file, index=False)\n    \n    print(f\"âœ… Submission saved to {output_file}\")\n    print(f\"ðŸ“Š Submission stats:\")\n    print(f\"   Total rows: {len(submission_df)}\")\n    print(f\"   FVC range: {submission_df['FVC'].min():.1f} - {submission_df['FVC'].max():.1f}\")\n    print(f\"   Confidence range: {submission_df['Confidence'].min():.1f} - {submission_df['Confidence'].max():.1f}\")\n    \n    return submission_df\n\n# Helper function for DICOM loading (for submission)\ndef load_and_preprocess_dicom(path):\n    \"\"\"Simplified DICOM loading for submission\"\"\"\n    try:\n        dcm = pydicom.dcmread(str(path))\n        img = dcm.pixel_array.astype(np.float32)\n        \n        if len(img.shape) == 3:\n            img = img[img.shape[0]//2]\n        \n        img = cv2.resize(img, (512, 512))\n        \n        # Normalize to 0-255\n        img_min, img_max = img.min(), img.max()\n        if img_max > img_min:\n            img = (img - img_min) / (img_max - img_min) * 255\n        else:\n            img = np.zeros_like(img)\n        \n        # Convert to 3-channel\n        img = np.stack([img, img, img], axis=2).astype(np.uint8)\n        return img\n        \n    except Exception as e:\n        # Return black image as fallback\n        return np.zeros((512, 512, 3), dtype=np.uint8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:35:57.877823Z","iopub.execute_input":"2025-08-12T15:35:57.878447Z","iopub.status.idle":"2025-08-12T15:35:57.893755Z","shell.execute_reply.started":"2025-08-12T15:35:57.878421Z","shell.execute_reply":"2025-08-12T15:35:57.892850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Part 10: Execute Training (Uncomment to run)\n# ------------------------------------------\n\nprint(\"ðŸš€ Starting training...\")\ntrainer = CorrectedSimpleTrainer(model, DEVICE, lr=5e-5)\nbest_val_mae = trainer.train(train_loader, val_loader, epochs=30, patience=8)\nprint(f\"ðŸŽ¯ Training completed! Best validation MAE: {best_val_mae:.6f}\")\n\n# Generate submission\nprint(\"ðŸ“ Generating submission...\")\nfinal_submission = create_submission_with_confidence(model, TRAIN_DIR, 'enhanced_submission.csv')\nprint(\"âœ… Submission ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T15:55:34.068117Z","iopub.execute_input":"2025-08-12T15:55:34.068398Z","iopub.status.idle":"2025-08-12T16:01:37.055716Z","shell.execute_reply.started":"2025-08-12T15:55:34.068370Z","shell.execute_reply":"2025-08-12T16:01:37.054857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------\n# LLL evaluation utilities\n# -------------------------\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nfrom math import sqrt, log\nfrom tqdm import tqdm\n\nSQRT2 = np.sqrt(2.0)\n\ndef laplace_score_per_sample(y_true, y_pred, sigma, sigma_floor=70.0):\n    \"\"\"\n    Per-sample Laplace Log-Likelihood (as used in OSIC).\n    Inputs are numpy arrays or scalars.\n    sigma is clipped to a minimum of sigma_floor.\n    Returns per-sample score (not averaged).\n    \"\"\"\n    sigma = np.maximum(sigma, sigma_floor)\n    delta = np.abs(y_true - y_pred)\n    term1 = - (SQRT2 * delta) / sigma\n    term2 = - np.log(SQRT2 * sigma)\n    return term1 + term2\n\ndef mean_laplace_score(y_true, y_pred, sigma, sigma_floor=70.0):\n    arr = laplace_score_per_sample(np.array(y_true), np.array(y_pred), np.array(sigma), sigma_floor=sigma_floor)\n    return float(np.mean(arr))\n\n# -------------------------\n# Evaluate on a DataLoader\n# -------------------------\ndef evaluate_lll_from_loader(model, loader, device, mode='log_var', tta_predictor=None, sigma_floor=70.0, save_csv=True, out_dir=None):\n    \"\"\"\n    mode:\n      - 'log_var' : model(images, tabular) -> (mean_pred, log_var). sigma = sqrt(exp(log_var))\n      - 'confidence' : model(images, tabular) -> (mean_pred, confidence). confidence used as sigma directly\n      - 'tta' : use tta_predictor.predict(image, tabular) -> (mean, std). (std used directly as sigma)\n    tta_predictor: instance of TTAPredictor if mode == 'tta'\n    Returns: (mean_lll, df) and writes CSV if save_csv True.\n    CSV columns: ['patient'(if available), 'y_true', 'y_pred', 'sigma', 'lll']\n    \"\"\"\n    model.eval()\n    preds = []\n    trues = []\n    sigmas = []\n    patients = []\n\n    device = torch.device(device)\n\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Evaluating LLL\"):\n            images, tabular, targets, patient_ids = batch\n            batch_size = images.shape[0]\n\n            images = images.to(device)\n            tabular = tabular.to(device)\n            targets = targets.to(device)\n\n            if mode == 'log_var':\n                mean_pred, log_var = model(images, tabular)\n                mean_np = mean_pred.detach().cpu().numpy().astype(float)\n                log_var_np = log_var.detach().cpu().numpy().astype(float)\n                sigma_np = np.sqrt(np.exp(log_var_np))\n            elif mode == 'confidence':\n                mean_pred, confidence = model(images, tabular)\n                mean_np = mean_pred.detach().cpu().numpy().astype(float)\n                sigma_np = confidence.detach().cpu().numpy().astype(float)\n            elif mode == 'tta':\n                mean_list = []\n                sigma_list = []\n                for i in range(batch_size):\n                    img = images[i].cpu()\n                    tab = tabular[i].cpu()\n                    mean_i, sigma_i = tta_predictor.predict(img, tab)\n                    mean_list.append(float(mean_i))\n                    sigma_list.append(float(sigma_i))\n                mean_np = np.array(mean_list, dtype=float)\n                sigma_np = np.array(sigma_list, dtype=float)\n            else:\n                raise ValueError(\"Unknown mode for evaluate_lll_from_loader\")\n\n            targets_np = targets.detach().cpu().numpy().astype(float)\n\n            preds.extend(mean_np.tolist())\n            trues.extend(targets_np.tolist())\n            sigmas.extend(sigma_np.tolist())\n            patients.extend([p if isinstance(p, str) else (p.item().decode('utf-8') if hasattr(p, 'item') else str(p)) for p in patient_ids])\n\n    preds = np.array(preds, dtype=float)\n    trues = np.array(trues, dtype=float)\n    sigmas = np.array(sigmas, dtype=float)\n    lll_per_sample = laplace_score_per_sample(trues, preds, sigmas, sigma_floor=sigma_floor)\n    mean_lll = float(np.mean(lll_per_sample))\n\n    df = pd.DataFrame({\n        'patient': patients,\n        'y_true': trues,\n        'y_pred': preds,\n        'sigma': sigmas,\n        'lll': lll_per_sample\n    })\n\n    if save_csv:\n        if out_dir is None:\n            out_dir = globals().get('auto_save_dir', '.')\n        os.makedirs(out_dir, exist_ok=True)\n        outpath = os.path.join(out_dir, 'lll_predictions.csv')\n        df.to_csv(outpath, index=False)\n        print(f\"Saved per-sample predictions + lll to: {outpath}\")\n\n    print(f\"Mean Laplace Log-Likelihood (LLL): {mean_lll:.6f}\")\n    return mean_lll, df\n\n# -------------------------\n# Helper: Convert slope -> FVC predictions and compute LLL per patient-week\n# -------------------------\ndef compute_lll_from_slope_predictions(slope_df, cur_fvc_map, cur_week_map, weeks_to_predict=None, sigma_floor=70.0, save_csv=True, out_dir=None):\n    if weeks_to_predict is None:\n        weeks_to_predict = np.arange(-12, 134)\n\n    rows = []\n    for idx, r in slope_df.iterrows():\n        patient = r['Patient']\n        slope = float(r['pred_slope'])\n        sigma_slope = float(r.get('sigma_slope', 0.0))\n        if patient not in cur_fvc_map or patient not in cur_week_map:\n            continue\n        cur_fvc = float(cur_fvc_map[patient])\n        cur_week = int(cur_week_map[patient])\n\n        intercept = cur_fvc - slope * cur_week\n\n        for w in weeks_to_predict:\n            pred_fvc = intercept + slope * w\n            sigma_fvc = max(1e-6, sigma_slope * abs(w - cur_week))\n            rows.append({\n                'Patient': patient,\n                'Week': w,\n                'y_true': None,\n                'y_pred': pred_fvc,\n                'sigma': sigma_fvc\n            })\n\n    df_expanded = pd.DataFrame(rows)\n    if save_csv:\n        out_dir = out_dir or globals().get('auto_save_dir', '.')\n        os.makedirs(out_dir, exist_ok=True)\n        df_expanded.to_csv(os.path.join(out_dir, 'slope_to_fvc_expanded.csv'), index=False)\n        print(f\"Saved expanded slope->FVC predictions to {out_dir}/slope_to_fvc_expanded.csv\")\n    return df_expanded\n\n# -------------------------\n# Example usage after training (run these cells)\n# -------------------------\n# 1) If your trained model returns (mean_pred, log_var) -> use mode='log_var'\nauto_save_dir = \"./auto_save_data\"\nimport os\nos.makedirs(auto_save_dir, exist_ok=True)\nmean_lll, df = evaluate_lll_from_loader(model, val_loader, DEVICE, mode='log_var', out_dir=auto_save_dir)\n#\n# 2) If you wrapped your model with ModelWithConfidence and it returns (mean_pred, confidence) -> mode='confidence'\nwrapped = ModelWithConfidence(base_model)  # load weights as needed\nwrapped.load_state_dict(torch.load('model_with_confidence.pth'))  # if saved\nwrapped.to(DEVICE).eval()\nmean_lll, df = evaluate_lll_from_loader(wrapped, val_loader, DEVICE, mode='confidence', out_dir=auto_save_dir)\n#\n# 3) If you want to do TTA (slower) using TTAPredictor:\ntta = TTAPredictor(model, num_augmentations=5)\nmean_lll, df = evaluate_lll_from_loader(model, val_loader, DEVICE, mode='tta', tta_predictor=tta, out_dir=auto_save_dir)\n#\n# 4) If your model predicts slope, and you have anchor cur_fvc & cur_week (per-patient), create a slope_df:\nslope_df = pd.DataFrame([\n    {'Patient': p, 'pred_slope': s, 'sigma_slope': ssize}\n    for p, s, ssize in zip(patient_list, slope_list, sigma_list)\n])\nexpanded = compute_lll_from_slope_predictions(slope_df, cur_fvc_map, cur_week_map, weeks_to_predict=np.arange(-12,134))\n#    # fill expanded['y_true'] with true FVCs if you have them, then compute mean_laplace_score:\nmean_lll = mean_laplace_score(expanded['y_true'], expanded['y_pred'], expanded['sigma'], sigma_floor=70.0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:13:19.104684Z","iopub.execute_input":"2025-08-12T16:13:19.105485Z","iopub.status.idle":"2025-08-12T16:13:19.930568Z","shell.execute_reply.started":"2025-08-12T16:13:19.105454Z","shell.execute_reply":"2025-08-12T16:13:19.929614Z"}},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Oct 24","metadata":{}},{"cell_type":"markdown","source":"üîç What's Missing From Our Original Plan (OSIC-Only)\nLooking back at our discussion, here's what you haven't done yet that we agreed was feasible:\n* .Proper data splitting - You only did simple train/val split. We discussed 5-fold cross-validation OR holding out a proper test set (20%) that you evaluate ONCE at the end. Right now you have no true held-out evaluation.\\n\n* .Clinical baseline comparison - You need to train a clinical-only model (Age, Sex, Smoking, baseline FVC) and show that adding CT scans improves predictions. This proves CT adds value beyond simple demographics.\\n\n* .Comprehensive evaluation metrics - You only reported R¬≤, MAE, LLL. Missing: classification metrics (accuracy, sensitivity, specificity for fast/moderate/slow progressors), confusion matrix, calibration plots, and prediction scatter plots.\\n\n* .Interpretability/Visualization - No attention maps showing which lung regions drive predictions, no feature importance analysis, no training curves saved as figures.\\n\n* .Error analysis - Which patients did the model fail on? Are there patterns in failures? This builds trust and shows limitations honestly.\\n\nDo these 5 things with your current code and OSIC dataset, and you'll have a complete, publishable story showing that baseline CT scans can predict fibrosis progression! üéØ\n\n","metadata":{}},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport random\nfrom tqdm import tqdm \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom pathlib import Path\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\nimport warnings\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed_everything(42)\n\n# Configuration\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"üöÄ PUBLICATION-READY OSIC Model - Comprehensive Analysis\")\nprint(\"=\" * 70)\nprint(f\"üì± Device: {DEVICE}\")\n\n# Load Data\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\nprint(f\"Loaded dataset with shape: {train_df.shape}\")\n\ndef get_optimized_tab_features(df_row):\n    \"\"\"Optimized tabular features - simpler but more effective\"\"\"\n    vector = []\n    \n    # Basic but effective features\n    age = df_row['Age']\n    vector.extend([\n        (age - 50) / 30,  # Centered age\n        age / 100,  # Scaled age\n    ])\n    \n    # Simple sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(1.0)\n    else:\n        vector.append(0.0)\n    \n    # Simple smoking status\n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([1, 0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([0, 1, 0])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 0, 1])\n    else:\n        vector.extend([0, 0, 0])\n    \n    # FVC features\n    if 'FVC' in df_row:\n        fvc = df_row['FVC']\n        vector.extend([\n            fvc / 3000,  # Normalized FVC\n            (fvc - 2500) / 1000,  # Centered FVC\n        ])\n    \n    # Percent predicted (approximate)\n    if 'FVC' in df_row and 'Age' in df_row:\n        fvc = df_row['FVC']\n        age = df_row['Age']\n        sex = df_row['Sex']\n        \n        # Approximate percent predicted FVC\n        if sex == 'Male':\n            pp_fvc = fvc / (27.63 - 0.112 * age) if age > 0 else 0.8\n        else:\n            pp_fvc = fvc / (21.78 - 0.101 * age) if age > 0 else 0.8\n            \n        vector.append(min(pp_fvc, 2.0))  # Cap at 200%\n    \n    return np.array(vector)\n\ndef calculate_lll(actual, predicted, sigma):\n    \"\"\"Calculate Log Laplace Likelihood\"\"\"\n    sigma = np.maximum(sigma, 1e-6)  # Avoid division by zero\n    delta = np.abs(actual - predicted)\n    return -np.sqrt(2) * delta / sigma - np.log(sigma * np.sqrt(2))\n\n# Improved coefficient calculation\nA = {} \nTAB = {} \nP = []\n\nprint(\"Calculating optimized linear decay coefficients...\")\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    fvc = sub['FVC'].values\n    weeks = sub['Weeks'].values\n    \n    if len(weeks) >= 2:\n        try:\n            # Simple robust slope calculation\n            if len(weeks) == 2:\n                slope = (fvc[1] - fvc[0]) / (weeks[1] - weeks[0])\n            else:\n                # Use Theil-Sen estimator for robustness\n                slopes = []\n                for i in range(len(weeks)):\n                    for j in range(i+1, len(weeks)):\n                        if weeks[j] != weeks[i]:\n                            slope = (fvc[j] - fvc[i]) / (weeks[j] - weeks[i])\n                            slopes.append(slope)\n                slope = np.median(slopes) if slopes else 0.0\n            \n            A[patient] = slope\n        except:\n            A[patient] = 0.0\n    else:\n        A[patient] = 0.0\n    \n    TAB[patient] = get_optimized_tab_features(sub.iloc[0])\n    P.append(patient)\n\nprint(f\"Processed {len(P)} patients with optimized features\")\n\n# Analyze target distribution\ndecay_values = np.array(list(A.values()))\nprint(f\"Target statistics: mean={decay_values.mean():.4f}, std={decay_values.std():.4f}\")\nprint(f\"Target range: [{decay_values.min():.4f}, {decay_values.max():.4f}]\")\n\n# ============================================================================\n# 1. PROPER DATA SPLITTING - 5-Fold Cross Validation\n# ============================================================================\n\ndef create_progressor_categories(decay_values, n_bins=3):\n    \"\"\"Categorize patients into progressor types based on slope\"\"\"\n    bin_edges = np.percentile(decay_values, [33, 66])\n    categories = np.digitize(decay_values, bin_edges)\n    return categories\n\nprint(\"\\nüìä Setting up 5-Fold Cross Validation...\")\nprogressor_categories = create_progressor_categories(decay_values)\npatients_array = np.array(P)\n\n# Store fold results\nfold_results = []\n\n# ============================================================================\n# 2. CLINICAL BASELINE MODEL\n# ============================================================================\n\nclass ClinicalBaselineModel:\n    \"\"\"Clinical-only baseline model using traditional ML\"\"\"\n    def __init__(self):\n        self.models = {\n            'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n            'linear': LinearRegression()\n        }\n        self.best_model = None\n        \n    def train(self, X_train, y_train):\n        # Train both models\n        for name, model in self.models.items():\n            model.fit(X_train, y_train)\n        \n        # Select best based on training performance (simple approach)\n        self.best_model = self.models['random_forest']\n        return self.best_model\n    \n    def predict(self, X):\n        return self.best_model.predict(X)\n    \n    def get_feature_importance(self, feature_names):\n        if hasattr(self.best_model, 'feature_importances_'):\n            return dict(zip(feature_names, self.best_model.feature_importances_))\n        return {}\n\n# ============================================================================\n# ENHANCED DEEP LEARNING MODEL (Your existing model with improvements)\n# ============================================================================\n\nclass OptimizedAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                albu.Rotate(limit=10, p=0.5),\n                albu.HorizontalFlip(p=0.4),\n                albu.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.6),\n                albu.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.4),\n                albu.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n    \n    def __call__(self, image):\n        return self.transform(image=image)['image']\n\nclass OptimizedDenseNetModel(nn.Module):\n    def __init__(self, tabular_dim=10, dropout_rate=0.2):\n        super(OptimizedDenseNetModel, self).__init__()\n        \n        # DenseNet121 backbone\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        \n        # Freeze early layers, unfreeze later layers\n        for i, param in enumerate(self.features.parameters()):\n            param.requires_grad = i > 100  # Only unfreeze later layers\n        \n        # Global pooling\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        \n        # Simple but effective tabular processor\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n        )\n        \n        # Feature fusion\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n        )\n        \n        # Output heads\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1),\n            nn.Tanh()  # Constrain output\n        )\n        \n        # Grad-CAM attributes\n        self.gradients = None\n        self.activations = None\n        \n        # Initialize output layers for better convergence\n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in [self.mean_head, self.log_var_head]:\n            if isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0.0)\n    \n    def activations_hook(self, grad):\n        self.gradients = grad\n    \n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        \n        # Extract image features\n        img_features = self.features(images)\n        \n        # Register hook for Grad-CAM\n        if img_features.requires_grad:\n            h = img_features.register_hook(self.activations_hook)\n        self.activations = img_features.detach()\n        \n        img_features = self.global_pool(img_features).view(batch_size, -1)\n        \n        # Process tabular data\n        tab_features = self.tabular_processor(tabular)\n        \n        # Feature fusion\n        combined_features = torch.cat([img_features, tab_features], dim=1)\n        fused_features = self.fusion_layer(combined_features)\n        \n        # Predict mean and log variance\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        \n        return mean_pred.squeeze(), log_var.squeeze()\n    \n    def get_activations_gradient(self):\n        return self.gradients\n    \n    def get_activations(self, x):\n        return self.features(x)\n\nclass OptimizedOSICDataset(Dataset):\n    def __init__(self, patients, A_dict, TAB_dict, data_dir, split='train'):\n        self.patients = [p for p in patients if p not in ['ID00011637202177653955184', 'ID00052637202186188008618']]\n        self.A_dict = A_dict\n        self.TAB_dict = TAB_dict\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augmentor = OptimizedAugmentation(augment=(split=='train'))\n        \n        # Prepare image paths\n        self.patient_images = {}\n        for patient in self.patients:\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = [f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm']\n                if image_files:\n                    self.patient_images[patient] = image_files\n        \n        self.valid_patients = [p for p in self.patients if p in self.patient_images]\n        print(f\"Dataset {split}: {len(self.valid_patients)} patients with images\")\n    \n    def __len__(self):\n        if self.split == 'train':\n            return len(self.valid_patients) * 8\n        else:\n            return len(self.valid_patients)\n    \n    def __getitem__(self, idx):\n        if self.split == 'train':\n            patient_idx = idx % len(self.valid_patients)\n        else:\n            patient_idx = idx\n            \n        patient = self.valid_patients[patient_idx]\n        \n        # Get random image\n        available_images = self.patient_images[patient]\n        selected_image = random.choice(available_images) if available_images else available_images[0]\n        \n        # Load and preprocess image\n        img = self.load_dicom(selected_image)\n        img_tensor = self.augmentor(img)\n        \n        # Get tabular features\n        tab_features = torch.tensor(self.TAB_dict[patient], dtype=torch.float32)\n        \n        # Get target (clipped to reasonable range)\n        target = torch.tensor(self.A_dict[patient], dtype=torch.float32)\n        \n        return img_tensor, tab_features, target, patient, str(selected_image)\n    \n    def load_dicom(self, path):\n        try:\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            \n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]\n            \n            img = cv2.resize(img, (384, 384))\n            \n            # Normalize\n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            \n            # Apply CLAHE\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            img = clahe.apply(img.astype(np.uint8))\n            \n            # Convert to 3-channel\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            \n            return img\n            \n        except Exception as e:\n            print(f\"Error loading {path}: {e}\")\n            return np.zeros((384, 384, 3), dtype=np.uint8)\n\nclass OptimizedTrainer:\n    def __init__(self, model, device, lr=1e-4, model_type='deep_learning'):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.model_type = model_type\n        self.best_val_r2 = -float('inf')\n        self.best_val_mae = float('inf')\n        self.best_val_lll = -float('inf')\n        self.train_losses = []\n        self.val_losses = []\n        self.train_r2_scores = []\n        self.val_r2_scores = []\n        \n    def uncertainty_loss(self, mean_pred, log_var, targets):\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        return 0.5 * (mse_loss / var + log_var).mean()\n    \n    def train(self, train_loader, val_loader, epochs=50):\n        if self.model_type == 'deep_learning':\n            return self._train_deep_learning(train_loader, val_loader, epochs)\n        else:\n            return self._train_clinical_baseline(train_loader, val_loader)\n    \n    def _train_deep_learning(self, train_loader, val_loader, epochs=50):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='max', factor=0.5, patience=5, verbose=True\n        )\n        \n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            # Training\n            self.model.train()\n            train_loss = 0.0\n            train_batches = 0\n            train_predictions, train_targets = [], []\n            \n            for images, tabular, targets, _, _ in train_loader:\n                images, tabular, targets = images.to(self.device), tabular.to(self.device), targets.to(self.device)\n                \n                optimizer.zero_grad()\n                mean_pred, log_var = self.model(images, tabular)\n                \n                # Combined loss\n                mse_loss = F.mse_loss(mean_pred, targets)\n                uncertainty_loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                \n                # Start with more MSE focus, transition to uncertainty\n                if epoch < 20:\n                    loss = 0.7 * mse_loss + 0.3 * uncertainty_loss\n                else:\n                    loss = 0.3 * mse_loss + 0.7 * uncertainty_loss\n                \n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n                optimizer.step()\n                \n                train_loss += loss.item()\n                train_batches += 1\n                \n                # Store predictions for R¬≤ calculation\n                train_predictions.extend(mean_pred.detach().cpu().numpy())\n                train_targets.extend(targets.cpu().numpy())\n            \n            # Calculate training R¬≤\n            train_r2 = r2_score(train_targets, train_predictions) if len(train_targets) > 0 else 0\n            self.train_r2_scores.append(train_r2)\n            self.train_losses.append(train_loss / train_batches)\n            \n            # Validation\n            self.model.eval()\n            val_predictions, val_targets, val_log_vars = [], [], []\n            \n            with torch.no_grad():\n                for images, tabular, targets, _, _ in val_loader:\n                    images, tabular, targets = images.to(self.device), tabular.to(self.device), targets.to(self.device)\n                    mean_pred, log_var = self.model(images, tabular)\n                    \n                    # Convert to numpy properly\n                    mean_pred_np = mean_pred.cpu().numpy()\n                    log_var_np = log_var.cpu().numpy()\n                    targets_np = targets.cpu().numpy()\n                    \n                    if mean_pred_np.ndim == 0:\n                        val_predictions.append(mean_pred_np.item())\n                        val_log_vars.append(log_var_np.item())\n                        val_targets.append(targets_np.item())\n                    else:\n                        val_predictions.extend(mean_pred_np.tolist())\n                        val_log_vars.extend(log_var_np.tolist())\n                        val_targets.extend(targets_np.tolist())\n            \n            if len(val_predictions) > 0:\n                val_pred_np = np.array(val_predictions)\n                val_target_np = np.array(val_targets)\n                val_log_var_np = np.array(val_log_vars)\n                val_sigma_np = np.exp(val_log_var_np / 2)\n                \n                # Calculate metrics\n                r2 = r2_score(val_target_np, val_pred_np)\n                mae = np.mean(np.abs(val_pred_np - val_target_np))\n                rmse = np.sqrt(mean_squared_error(val_target_np, val_pred_np))\n                lll_values = calculate_lll(val_target_np, val_pred_np, val_sigma_np)\n                avg_lll = np.mean(lll_values)\n                \n                avg_train_loss = train_loss / train_batches if train_batches > 0 else 0\n                current_lr = optimizer.param_groups[0]['lr']\n                \n                self.val_r2_scores.append(r2)\n                self.val_losses.append(avg_train_loss)  # Simplified for plotting\n                \n                print(f\"Epoch {epoch+1}: LR={current_lr:.2e}, Loss={avg_train_loss:.4f}\")\n                print(f\"          Train R¬≤={train_r2:.4f}, Val R¬≤={r2:.4f}\")\n                print(f\"          Val MAE={mae:.4f}, RMSE={rmse:.4f}, LLL={avg_lll:.4f}\")\n                \n                # Update scheduler\n                scheduler.step(r2)\n                \n                # Save best model\n                if r2 > self.best_val_r2:\n                    self.best_val_r2 = r2\n                    self.best_val_mae = mae\n                    self.best_val_lll = avg_lll\n                    torch.save(self.model.state_dict(), f'best_model_fold_{len(fold_results)}.pth')\n                    print(f\"üéØ NEW BEST! R¬≤: {r2:.4f}\")\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n                \n                if patience_counter >= 10:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n                \n                print(\"-\" * 60)\n        \n        return self.best_val_r2, self.best_val_mae, self.best_val_lll\n    \n    def _train_clinical_baseline(self, train_loader, val_loader):\n        # Extract features and targets\n        X_train, y_train = [], []\n        for _, tabular, targets, _, _ in train_loader:\n            X_train.extend(tabular.numpy())\n            y_train.extend(targets.numpy())\n        \n        X_val, y_val = [], []\n        for _, tabular, targets, _, _ in val_loader:\n            X_val.extend(tabular.numpy())\n            y_val.extend(targets.numpy())\n        \n        # Train clinical model\n        self.model.train(np.array(X_train), np.array(y_train))\n        \n        # Predict\n        y_pred = self.model.predict(np.array(X_val))\n        \n        # Calculate metrics\n        r2 = r2_score(y_val, y_pred)\n        mae = np.mean(np.abs(y_pred - y_val))\n        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n        \n        # For clinical model, use fixed sigma for LLL calculation\n        sigma = np.std(y_pred - y_val)\n        lll_values = calculate_lll(y_val, y_pred, np.full_like(y_val, sigma))\n        avg_lll = np.mean(lll_values)\n        \n        print(f\"Clinical Baseline - R¬≤: {r2:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}, LLL: {avg_lll:.4f}\")\n        \n        return r2, mae, avg_lll\n\n# ============================================================================\n# 3. COMPREHENSIVE EVALUATION METRICS\n# ============================================================================\n\nclass ComprehensiveEvaluator:\n    def __init__(self):\n        self.metrics = {}\n        \n    def calculate_classification_metrics(self, true_slopes, pred_slopes):\n        \"\"\"Calculate progressor classification metrics\"\"\"\n        # Define progressor categories based on tertiles\n        slow_threshold = np.percentile(true_slopes, 33)\n        fast_threshold = np.percentile(true_slopes, 66)\n        \n        true_categories = np.zeros_like(true_slopes)\n        true_categories[true_slopes <= slow_threshold] = 0  # Slow\n        true_categories[(true_slopes > slow_threshold) & (true_slopes <= fast_threshold)] = 1  # Moderate\n        true_categories[true_slopes > fast_threshold] = 2  # Fast\n        \n        pred_categories = np.zeros_like(pred_slopes)\n        pred_categories[pred_slopes <= slow_threshold] = 0\n        pred_categories[(pred_categories > slow_threshold) & (pred_slopes <= fast_threshold)] = 1\n        pred_categories[pred_slopes > fast_threshold] = 2\n        \n        # Calculate metrics\n        accuracy = np.mean(true_categories == pred_categories)\n        cm = confusion_matrix(true_categories, pred_categories)\n        report = classification_report(true_categories, pred_categories, \n                                     target_names=['Slow', 'Moderate', 'Fast'], output_dict=True)\n        \n        return {\n            'accuracy': accuracy,\n            'confusion_matrix': cm,\n            'classification_report': report,\n            'true_categories': true_categories,\n            'pred_categories': pred_categories\n        }\n    \n    def create_calibration_plot(self, true_slopes, pred_slopes, save_path='calibration_plot.png'):\n        \"\"\"Create calibration plot for regression\"\"\"\n        plt.figure(figsize=(10, 6))\n        \n        # Bin predictions\n        bins = np.linspace(min(pred_slopes), max(pred_slopes), 10)\n        bin_centers = []\n        true_means = []\n        \n        for i in range(len(bins)-1):\n            mask = (pred_slopes >= bins[i]) & (pred_slopes < bins[i+1])\n            if np.sum(mask) > 0:\n                bin_centers.append((bins[i] + bins[i+1]) / 2)\n                true_means.append(np.mean(true_slopes[mask]))\n        \n        plt.plot(bin_centers, true_means, 'o-', label='Calibration')\n        plt.plot([min(pred_slopes), max(pred_slopes)], [min(pred_slopes), max(pred_slopes)], '--', color='gray', label='Perfect calibration')\n        plt.xlabel('Predicted Slope')\n        plt.ylabel('Actual Slope')\n        plt.title('Calibration Plot')\n        plt.legend()\n        plt.grid(True, alpha=0.3)\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def create_scatter_plot(self, true_slopes, pred_slopes, save_path='scatter_plot.png'):\n        \"\"\"Create prediction vs actual scatter plot\"\"\"\n        plt.figure(figsize=(8, 6))\n        plt.scatter(true_slopes, pred_slopes, alpha=0.6, s=50)\n        plt.plot([min(true_slopes), max(true_slopes)], [min(true_slopes), max(true_slopes)], 'r--', alpha=0.8)\n        plt.xlabel('Actual Slope')\n        plt.ylabel('Predicted Slope')\n        plt.title('Predicted vs Actual Slope')\n        plt.grid(True, alpha=0.3)\n        \n        # Add R¬≤ to plot\n        r2 = r2_score(true_slopes, pred_slopes)\n        plt.text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=plt.gca().transAxes, \n                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n        \n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def plot_training_curves(self, trainer, save_path='training_curves.png'):\n        \"\"\"Plot training and validation curves\"\"\"\n        plt.figure(figsize=(12, 4))\n        \n        plt.subplot(1, 2, 1)\n        plt.plot(trainer.train_losses, label='Training Loss')\n        plt.plot(trainer.val_losses, label='Validation Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.title('Training and Validation Loss')\n        plt.grid(True, alpha=0.3)\n        \n        plt.subplot(1, 2, 2)\n        plt.plot(trainer.train_r2_scores, label='Training R¬≤')\n        plt.plot(trainer.val_r2_scores, label='Validation R¬≤')\n        plt.xlabel('Epoch')\n        plt.ylabel('R¬≤ Score')\n        plt.legend()\n        plt.title('Training and Validation R¬≤')\n        plt.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n\n# ============================================================================\n# 4. INTERPRETABILITY - GRAD-CAM (CORRECTED)\n# ============================================================================\n\nclass GradCAM:\n    def __init__(self, model):\n        self.model = model\n        self.gradients = None\n        self.activations = None\n        \n        # Register hooks\n        self.model.features[-1].register_forward_hook(self.save_activations)\n        self.model.features[-1].register_backward_hook(self.save_gradients)\n    \n    def save_activations(self, module, input, output):\n        self.activations = output.detach()\n    \n    def save_gradients(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0].detach()\n    \n    def __call__(self, x):\n        # Forward pass\n        self.model.zero_grad()\n        \n        # Get predictions\n        mean_pred, _ = self.model(x, torch.zeros(x.size(0), 9).to(x.device))  # dummy tabular\n        \n        # Backward pass\n        target = mean_pred.sum()  # Use sum of predictions for Grad-CAM\n        target.backward()\n        \n        # Check if we have gradients and activations\n        if self.gradients is None or self.activations is None:\n            raise RuntimeError(\"Gradients or activations not captured. Check hook registration.\")\n        \n        # Pool gradients across spatial dimensions\n        pooled_gradients = torch.mean(self.gradients, dim=[0, 2, 3])\n        \n        # Weight activations by gradients\n        weighted_activations = torch.zeros_like(self.activations)\n        for i in range(pooled_gradients.size(0)):\n            weighted_activations[:, i, :, :] = self.activations[:, i, :, :] * pooled_gradients[i]\n        \n        # Heatmap\n        heatmap = torch.mean(weighted_activations, dim=1).squeeze()\n        heatmap = F.relu(heatmap)\n        \n        # Normalize\n        if torch.max(heatmap) > 0:\n            heatmap /= torch.max(heatmap)\n        \n        return heatmap.detach().cpu().numpy()\n\ndef create_attention_map(model, image_tensor, original_image, save_path):\n    \"\"\"Create and save attention map using Grad-CAM\"\"\"\n    model.eval()\n    \n    # Move to device and enable gradients\n    image_tensor = image_tensor.unsqueeze(0).to(DEVICE).requires_grad_(True)\n    \n    try:\n        # Get Grad-CAM\n        gradcam = GradCAM(model)\n        heatmap = gradcam(image_tensor)\n        \n        # Resize heatmap to match original image\n        heatmap = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))\n        heatmap = np.uint8(255 * heatmap)\n        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n        \n        # Convert original image to RGB if needed\n        if len(original_image.shape) == 2:\n            original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)\n        elif original_image.shape[2] == 1:\n            original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)\n        \n        # Ensure both images have same data type and range\n        original_image = original_image.astype(np.float32)\n        heatmap = heatmap.astype(np.float32)\n        \n        # Superimpose heatmap on original image\n        superimposed_img = heatmap * 0.4 + original_image * 0.6\n        superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n        \n        # Save result\n        plt.figure(figsize=(12, 4))\n        \n        plt.subplot(1, 3, 1)\n        plt.imshow(original_image.astype(np.uint8))\n        plt.title('Original CT')\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 2)\n        plt.imshow(heatmap.astype(np.uint8))\n        plt.title('Attention Map')\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 3)\n        plt.imshow(superimposed_img)\n        plt.title('Overlay')\n        plt.axis('off')\n        \n        plt.tight_layout()\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n        \n        print(f\"‚úÖ Attention map saved: {save_path}\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error creating attention map: {e}\")\n        # Create a placeholder image to avoid breaking the pipeline\n        plt.figure(figsize=(8, 6))\n        plt.text(0.5, 0.5, f\"Grad-CAM Failed\\n{str(e)}\", \n                ha='center', va='center', transform=plt.gca().transAxes)\n        plt.axis('off')\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.close()\n\n# ============================================================================\n# 5. ERROR ANALYSIS (CORRECTED)\n# ============================================================================\n\ndef perform_error_analysis(true_slopes, pred_slopes, patients, tabular_data, save_path='error_analysis.png'):\n    \"\"\"Analyze patterns in prediction errors\"\"\"\n    errors = np.abs(pred_slopes - true_slopes)\n    \n    # Identify worst predictions (handle empty arrays)\n    if len(errors) > 0:\n        worst_indices = np.argsort(errors)[-min(10, len(errors)):]  # Top 10 worst or all if less\n    else:\n        worst_indices = []\n    \n    print(\"\\nüîç ERROR ANALYSIS - Worst Predictions:\")\n    print(\"=\" * 60)\n    for i, idx in enumerate(worst_indices):\n        if idx < len(patients) and idx < len(true_slopes):\n            print(f\"{i+1}. Patient {patients[idx]}: True={true_slopes[idx]:.2f}, Pred={pred_slopes[idx]:.2f}, Error={errors[idx]:.2f}\")\n    \n    # Plot error distribution\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 3, 1)\n    if len(errors) > 0:\n        plt.hist(errors, bins=min(20, len(errors)), alpha=0.7, edgecolor='black')\n    plt.xlabel('Absolute Error')\n    plt.ylabel('Frequency')\n    plt.title('Error Distribution')\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 3, 2)\n    if len(true_slopes) > 0 and len(errors) > 0:\n        plt.scatter(true_slopes, errors, alpha=0.6)\n    plt.xlabel('True Slope')\n    plt.ylabel('Absolute Error')\n    plt.title('Error vs True Value')\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 3, 3)\n    # Analyze errors by feature (using first tabular feature as example)\n    if len(tabular_data) > 0 and len(errors) > 0:\n        feature_errors = []\n        for i in range(min(5, tabular_data.shape[1])):  # Limit to first 5 features\n            if len(tabular_data) > i:\n                corr = np.corrcoef(tabular_data[:, i], errors)[0, 1] if len(errors) > 1 else 0\n                feature_errors.append((i, abs(corr)))\n        \n        # Plot top correlated features with errors\n        if feature_errors:\n            feature_errors.sort(key=lambda x: x[1], reverse=True)\n            features, correlations = zip(*feature_errors[:5])\n            \n            plt.bar(range(len(features)), correlations)\n            plt.xlabel('Feature Index')\n            plt.ylabel('|Correlation with Error|')\n            plt.title('Top Features Correlated with Error')\n            plt.xticks(range(len(features)), [f'F{i}' for i in features])\n    \n    plt.tight_layout()\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    return worst_indices, errors\n\n# ============================================================================\n# MAIN EXECUTION - CORRECTED CALLS\n# ============================================================================\n\ndef run_comprehensive_analysis():\n    print(\"\\nüéØ STARTING COMPREHENSIVE 5-FOLD ANALYSIS\")\n    print(\"=\" * 70)\n    \n    # Initialize evaluator\n    evaluator = ComprehensiveEvaluator()\n    \n    # 5-Fold Cross Validation\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(patients_array, progressor_categories)):\n        print(f\"\\nüìä FOLD {fold + 1}/5\")\n        print(\"-\" * 50)\n        \n        # Get patients for this fold\n        train_patients = patients_array[train_idx].tolist()\n        val_patients = patients_array[val_idx].tolist()\n        \n        print(f\"Train: {len(train_patients)} patients, Val: {len(val_patients)} patients\")\n        \n        # Get tabular dimension\n        if train_patients and train_patients[0] in TAB:\n            tabular_dim = len(TAB[train_patients[0]])\n        else:\n            tabular_dim = 9  # fallback\n            \n        # Create datasets\n        train_dataset = OptimizedOSICDataset(train_patients, A, TAB, TRAIN_DIR, 'train')\n        val_dataset = OptimizedOSICDataset(val_patients, A, TAB, TRAIN_DIR, 'val')\n        \n        # Skip fold if no valid patients\n        if len(train_dataset.valid_patients) == 0 or len(val_dataset.valid_patients) == 0:\n            print(f\"‚ö†Ô∏è  Skipping fold {fold+1} - no valid patients with images\")\n            continue\n            \n        # Data loaders\n        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n        \n        # ====================================================================\n        # 2. CLINICAL BASELINE COMPARISON\n        # ====================================================================\n        print(\"\\nü©∫ TRAINING CLINICAL BASELINE MODEL...\")\n        clinical_model = ClinicalBaselineModel()\n        clinical_trainer = OptimizedTrainer(clinical_model, DEVICE, model_type='clinical')\n        clinical_r2, clinical_mae, clinical_lll = clinical_trainer.train(train_loader, val_loader)\n        \n        # ====================================================================\n        # DEEP LEARNING MODEL\n        # ====================================================================\n        print(\"\\nüß† TRAINING DEEP LEARNING MODEL...\")\n        dl_model = OptimizedDenseNetModel(tabular_dim=tabular_dim).to(DEVICE)\n        dl_trainer = OptimizedTrainer(dl_model, DEVICE, lr=1e-4, model_type='deep_learning')\n        dl_r2, dl_mae, dl_lll = dl_trainer.train(train_loader, val_loader, epochs=30)\n        \n        # ====================================================================\n        # COMPREHENSIVE EVALUATION\n        # ====================================================================\n        print(\"\\nüìà PERFORMING COMPREHENSIVE EVALUATION...\")\n        \n        # Get predictions for comprehensive evaluation\n        dl_model.eval()\n        all_preds, all_targets, all_patients = [], [], []\n        all_tabular = []\n        \n        with torch.no_grad():\n            for images, tabular, targets, patients, _ in val_loader:\n                images, tabular = images.to(DEVICE), tabular.to(DEVICE)\n                mean_pred, _ = dl_model(images, tabular)\n                \n                # Handle both scalar and tensor cases\n                pred_np = mean_pred.cpu().numpy()\n                if pred_np.ndim == 0:\n                    all_preds.append(pred_np.item())\n                else:\n                    all_preds.extend(pred_np.tolist())\n                    \n                all_targets.extend(targets.numpy())\n                all_patients.extend(patients)\n                all_tabular.extend(tabular.cpu().numpy())\n        \n        all_preds = np.array(all_preds)\n        all_targets = np.array(all_targets)\n        all_tabular = np.array(all_tabular)\n        \n        # Skip if no predictions\n        if len(all_preds) == 0:\n            print(\"‚ö†Ô∏è  No predictions generated, skipping evaluation\")\n            continue\n            \n        # 3.1 Classification Metrics\n        classification_results = evaluator.calculate_classification_metrics(all_targets, all_preds)\n        print(f\"Classification Accuracy: {classification_results['accuracy']:.4f}\")\n        \n        # 3.2 Calibration Plot\n        evaluator.create_calibration_plot(all_targets, all_preds, f'calibration_fold_{fold+1}.png')\n        \n        # 3.3 Scatter Plot\n        evaluator.create_scatter_plot(all_targets, all_preds, f'scatter_fold_{fold+1}.png')\n        \n        # 3.4 Training Curves\n        evaluator.plot_training_curves(dl_trainer, f'training_curves_fold_{fold+1}.png')\n        \n        # ====================================================================\n        # 4. INTERPRETABILITY - GRAD-CAM\n        # ====================================================================\n        print(\"\\nüëÅÔ∏è  GENERATING ATTENTION MAPS...\")\n        # Get one sample for visualization\n        if len(val_dataset) > 0:\n            try:\n                sample_idx = 0\n                sample_image, sample_tabular, sample_target, sample_patient, sample_path = val_dataset[sample_idx]\n                \n                # Load original image properly\n                original_img = val_dataset.load_dicom(Path(sample_path))\n                \n                create_attention_map(\n                    dl_model, \n                    sample_image, \n                    original_img, \n                    f'attention_map_fold_{fold+1}.png'\n                )\n            except Exception as e:\n                print(f\"‚ö†Ô∏è  Could not generate attention map: {e}\")\n        else:\n            print(\"‚ö†Ô∏è  No validation samples for attention map\")\n        \n        # ====================================================================\n        # 5. ERROR ANALYSIS\n        # ====================================================================\n        print(\"\\nüîç PERFORMING ERROR ANALYSIS...\")\n        worst_indices, errors = perform_error_analysis(\n            all_targets, all_preds, all_patients, all_tabular, f'error_analysis_fold_{fold+1}.png'\n        )\n        \n        # Store fold results\n        fold_results.append({\n            'fold': fold + 1,\n            'clinical_r2': clinical_r2,\n            'clinical_mae': clinical_mae,\n            'clinical_lll': clinical_lll,\n            'dl_r2': dl_r2,\n            'dl_mae': dl_mae,\n            'dl_lll': dl_lll,\n            'classification_accuracy': classification_results['accuracy'],\n            'mean_error': np.mean(errors) if len(errors) > 0 else 0,\n            'std_error': np.std(errors) if len(errors) > 0 else 0\n        })\n        \n        print(f\"\\n‚úÖ FOLD {fold + 1} COMPLETED\")\n        print(f\"Clinical R¬≤: {clinical_r2:.4f}, DL R¬≤: {dl_r2:.4f}\")\n        print(f\"Improvement: {(dl_r2 - clinical_r2):.4f}\")\n    \n    # ========================================================================\n    # FINAL SUMMARY AND COMPARISON\n    # ========================================================================\n    print(\"\\n\" + \"=\"*70)\n    print(\"üéØ FINAL COMPREHENSIVE RESULTS\")\n    print(\"=\"*70)\n    \n    if not fold_results:\n        print(\"‚ùå No results generated from any fold\")\n        return pd.DataFrame()\n        \n    # Convert to DataFrame for easy analysis\n    results_df = pd.DataFrame(fold_results)\n    \n    print(\"\\nüìä 5-FOLD CROSS VALIDATION RESULTS:\")\n    print(results_df.round(4))\n    \n    print(\"\\nüìà AVERAGE PERFORMANCE ACROSS FOLDS:\")\n    avg_results = results_df.mean()\n    print(avg_results.round(4))\n    \n    print(f\"\\nüí™ DEEP LEARNING IMPROVEMENT OVER CLINICAL BASELINE:\")\n    print(f\"R¬≤ Improvement: {avg_results['dl_r2'] - avg_results['clinical_r2']:.4f}\")\n    print(f\"MAE Improvement: {avg_results['clinical_mae'] - avg_results['dl_mae']:.4f}\")\n    print(f\"LLL Improvement: {avg_results['dl_lll'] - avg_results['clinical_lll']:.4f}\")\n    \n    # Create final comparison plot\n    plt.figure(figsize=(10, 6))\n    x_pos = np.arange(len(results_df))\n    width = 0.35\n    \n    plt.bar(x_pos - width/2, results_df['clinical_r2'], width, label='Clinical Baseline', alpha=0.7)\n    plt.bar(x_pos + width/2, results_df['dl_r2'], width, label='DL Model', alpha=0.7)\n    \n    plt.xlabel('Fold')\n    plt.ylabel('R¬≤ Score')\n    plt.title('Clinical vs Deep Learning Model Performance (5-Fold CV)')\n    plt.xticks(x_pos, [f'Fold {i+1}' for i in range(len(results_df))])\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('final_comparison.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    print(f\"\\n‚úÖ COMPREHENSIVE ANALYSIS COMPLETED!\")\n    print(\"üìÅ Generated files:\")\n    print(\"   - calibration_fold_*.png (Calibration plots)\")\n    print(\"   - scatter_fold_*.png (Prediction scatter plots)\")\n    print(\"   - training_curves_fold_*.png (Training history)\")\n    print(\"   - attention_map_fold_*.png (Grad-CAM visualizations)\")\n    print(\"   - error_analysis_fold_*.png (Error analysis)\")\n    print(\"   - final_comparison.png (Model comparison)\")\n    \n    return results_df\n\nif __name__ == \"__main__\":\n    final_results = run_comprehensive_analysis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T16:41:58.600543Z","iopub.execute_input":"2025-10-24T16:41:58.600935Z","iopub.status.idle":"2025-10-24T17:07:47.277481Z","shell.execute_reply.started":"2025-10-24T16:41:58.600903Z","shell.execute_reply":"2025-10-24T17:07:47.276662Z"}},"outputs":[{"name":"stdout","text":"üöÄ PUBLICATION-READY OSIC Model - Comprehensive Analysis\n======================================================================\nüì± Device: cuda\nLoaded dataset with shape: (1549, 7)\nCalculating optimized linear decay coefficients...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 1151.90it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 176 patients with optimized features\nTarget statistics: mean=-4.8107, std=6.7150\nTarget range: [-39.0741, 11.1389]\n\nüìä Setting up 5-Fold Cross Validation...\n\nüéØ STARTING COMPREHENSIVE 5-FOLD ANALYSIS\n======================================================================\n\nüìä FOLD 1/5\n--------------------------------------------------\nTrain: 140 patients, Val: 36 patients\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Dataset train: 139 patients with images\nDataset val: 35 patients with images\n\nü©∫ TRAINING CLINICAL BASELINE MODEL...\nClinical Baseline - R¬≤: -0.3138, MAE: 4.8450, RMSE: 6.0912, LLL: -3.2784\n\nüß† TRAINING DEEP LEARNING MODEL...\nEpoch 1: LR=1.00e-04, Loss=47.9357\n          Train R¬≤=-0.2942, Val R¬≤=-0.2428\n          Val MAE=4.2587, RMSE=5.9245, LLL=-4.7148\nüéØ NEW BEST! R¬≤: -0.2428\n------------------------------------------------------------\nEpoch 2: LR=1.00e-04, Loss=34.1029\n          Train R¬≤=0.0616, Val R¬≤=-0.0150\n          Val MAE=3.8338, RMSE=5.3541, LLL=-4.2742\nüéØ NEW BEST! R¬≤: -0.0150\n------------------------------------------------------------\nEpoch 3: LR=1.00e-04, Loss=31.5362\n          Train R¬≤=0.1306, Val R¬≤=-0.2412\n          Val MAE=4.4853, RMSE=5.9206, LLL=-4.8216\n------------------------------------------------------------\nEpoch 4: LR=1.00e-04, Loss=31.2274\n          Train R¬≤=0.1356, Val R¬≤=-0.2128\n          Val MAE=4.5661, RMSE=5.8524, LLL=-4.8216\n------------------------------------------------------------\nEpoch 5: LR=1.00e-04, Loss=29.1160\n          Train R¬≤=0.1940, Val R¬≤=-0.2084\n          Val MAE=4.3026, RMSE=5.8419, LLL=-4.6165\n------------------------------------------------------------\nEpoch 6: LR=1.00e-04, Loss=28.6135\n          Train R¬≤=0.2064, Val R¬≤=-0.0546\n          Val MAE=4.0743, RMSE=5.4574, LLL=-4.4213\n------------------------------------------------------------\nEpoch 7: LR=1.00e-04, Loss=26.4327\n          Train R¬≤=0.2673, Val R¬≤=-0.0214\n          Val MAE=4.1192, RMSE=5.3708, LLL=-4.4357\n------------------------------------------------------------\nEpoch 8: LR=1.00e-04, Loss=25.9351\n          Train R¬≤=0.2805, Val R¬≤=-0.2502\n          Val MAE=4.5170, RMSE=5.9419, LLL=-4.8877\n------------------------------------------------------------\nEpoch 9: LR=5.00e-05, Loss=24.0701\n          Train R¬≤=0.3326, Val R¬≤=0.0222\n          Val MAE=4.0356, RMSE=5.2550, LLL=-4.4148\nüéØ NEW BEST! R¬≤: 0.0222\n------------------------------------------------------------\nEpoch 10: LR=5.00e-05, Loss=21.7031\n          Train R¬≤=0.3984, Val R¬≤=-0.0373\n          Val MAE=4.0211, RMSE=5.4125, LLL=-4.3819\n------------------------------------------------------------\nEpoch 11: LR=5.00e-05, Loss=21.2551\n          Train R¬≤=0.4109, Val R¬≤=-0.2851\n          Val MAE=4.4330, RMSE=6.0244, LLL=-4.7371\n------------------------------------------------------------\nEpoch 12: LR=5.00e-05, Loss=19.0559\n          Train R¬≤=0.4723, Val R¬≤=-0.8570\n          Val MAE=5.3954, RMSE=7.2419, LLL=-5.4851\n------------------------------------------------------------\nEpoch 13: LR=5.00e-05, Loss=18.7020\n          Train R¬≤=0.4821, Val R¬≤=-0.3465\n          Val MAE=4.6313, RMSE=6.1667, LLL=-4.8680\n------------------------------------------------------------\nEpoch 14: LR=5.00e-05, Loss=19.7554\n          Train R¬≤=0.4525, Val R¬≤=-0.6517\n          Val MAE=5.1261, RMSE=6.8297, LLL=-5.2915\n------------------------------------------------------------\nEpoch 15: LR=5.00e-05, Loss=19.1361\n          Train R¬≤=0.4697, Val R¬≤=0.0448\n          Val MAE=4.0439, RMSE=5.1938, LLL=-4.3515\nüéØ NEW BEST! R¬≤: 0.0448\n------------------------------------------------------------\nEpoch 16: LR=5.00e-05, Loss=19.7167\n          Train R¬≤=0.4535, Val R¬≤=-0.4138\n          Val MAE=4.8200, RMSE=6.3188, LLL=-5.1028\n------------------------------------------------------------\nEpoch 17: LR=5.00e-05, Loss=18.9221\n          Train R¬≤=0.4756, Val R¬≤=-0.2791\n          Val MAE=4.7151, RMSE=6.0104, LLL=-4.9622\n------------------------------------------------------------\nEpoch 18: LR=5.00e-05, Loss=16.9470\n          Train R¬≤=0.5309, Val R¬≤=-0.3762\n          Val MAE=4.5418, RMSE=6.2344, LLL=-4.7615\n------------------------------------------------------------\nEpoch 19: LR=5.00e-05, Loss=17.0420\n          Train R¬≤=0.5281, Val R¬≤=-0.5661\n          Val MAE=5.0371, RMSE=6.6505, LLL=-5.1865\n------------------------------------------------------------\nEpoch 20: LR=5.00e-05, Loss=15.9009\n          Train R¬≤=0.5599, Val R¬≤=0.0217\n          Val MAE=4.2887, RMSE=5.2562, LLL=-4.5457\n------------------------------------------------------------\nEpoch 21: LR=5.00e-05, Loss=8.8746\n          Train R¬≤=0.5809, Val R¬≤=-0.0224\n          Val MAE=4.3436, RMSE=5.3734, LLL=-4.5951\n------------------------------------------------------------\nEpoch 22: LR=2.50e-05, Loss=8.4480\n          Train R¬≤=0.6020, Val R¬≤=-0.1515\n          Val MAE=4.8041, RMSE=5.7027, LLL=-4.9883\n------------------------------------------------------------\nEpoch 23: LR=2.50e-05, Loss=8.5401\n          Train R¬≤=0.5974, Val R¬≤=-0.5623\n          Val MAE=5.3471, RMSE=6.6424, LLL=-5.4571\n------------------------------------------------------------\nEpoch 24: LR=2.50e-05, Loss=8.8537\n          Train R¬≤=0.5819, Val R¬≤=0.1119\n          Val MAE=3.9147, RMSE=5.0081, LLL=-4.2191\nüéØ NEW BEST! R¬≤: 0.1119\n------------------------------------------------------------\nEpoch 25: LR=2.50e-05, Loss=8.7384\n          Train R¬≤=0.5874, Val R¬≤=-0.1270\n          Val MAE=4.5013, RMSE=5.6416, LLL=-4.7338\n------------------------------------------------------------\nEpoch 26: LR=2.50e-05, Loss=7.4781\n          Train R¬≤=0.6495, Val R¬≤=0.0163\n          Val MAE=4.2745, RMSE=5.2709, LLL=-4.5221\n------------------------------------------------------------\nEpoch 27: LR=2.50e-05, Loss=7.6416\n          Train R¬≤=0.6413, Val R¬≤=-0.0524\n          Val MAE=4.3327, RMSE=5.4518, LLL=-4.5841\n------------------------------------------------------------\nEpoch 28: LR=2.50e-05, Loss=7.8864\n          Train R¬≤=0.6292, Val R¬≤=0.0862\n          Val MAE=3.8901, RMSE=5.0801, LLL=-4.2015\n------------------------------------------------------------\nEpoch 29: LR=2.50e-05, Loss=7.1124\n          Train R¬≤=0.6674, Val R¬≤=-0.1000\n          Val MAE=4.3654, RMSE=5.5735, LLL=-4.6005\n------------------------------------------------------------\nEpoch 30: LR=2.50e-05, Loss=7.0447\n          Train R¬≤=0.6707, Val R¬≤=-0.0536\n          Val MAE=4.3402, RMSE=5.4549, LLL=-4.6160\n------------------------------------------------------------\n\nüìà PERFORMING COMPREHENSIVE EVALUATION...\nClassification Accuracy: 0.4000\n\nüëÅÔ∏è  GENERATING ATTENTION MAPS...\n‚úÖ Attention map saved: attention_map_fold_1.png\n\nüîç PERFORMING ERROR ANALYSIS...\n\nüîç ERROR ANALYSIS - Worst Predictions:\n============================================================\n1. Patient ID00423637202312137826377: True=-9.80, Pred=-3.43, Error=6.37\n2. Patient ID00339637202287377736231: True=-8.89, Pred=-2.49, Error=6.40\n3. Patient ID00109637202210454292264: True=0.10, Pred=-6.69, Error=6.79\n4. Patient ID00251637202267455595113: True=-4.87, Pred=2.10, Error=6.97\n5. Patient ID00035637202182204917484: True=-8.61, Pred=-1.34, Error=7.26\n6. Patient ID00111637202210956877205: True=-11.69, Pred=-3.83, Error=7.86\n7. Patient ID00012637202177665765362: True=-6.89, Pred=1.51, Error=8.40\n8. Patient ID00398637202303897337979: True=-22.80, Pred=-14.02, Error=8.79\n9. Patient ID00276637202271694539978: True=-13.42, Pred=-2.08, Error=11.33\n10. Patient ID00104637202208063407045: True=-17.23, Pred=-2.60, Error=14.63\n\n‚úÖ FOLD 1 COMPLETED\nClinical R¬≤: -0.3138, DL R¬≤: 0.1119\nImprovement: 0.4257\n\nüìä FOLD 2/5\n--------------------------------------------------\nTrain: 141 patients, Val: 35 patients\nDataset train: 140 patients with images\nDataset val: 34 patients with images\n\nü©∫ TRAINING CLINICAL BASELINE MODEL...\nClinical Baseline - R¬≤: -0.7454, MAE: 6.6601, RMSE: 8.0550, LLL: -3.6176\n\nüß† TRAINING DEEP LEARNING MODEL...\nEpoch 1: LR=1.00e-04, Loss=44.9377\n          Train R¬≤=-0.3063, Val R¬≤=-0.0845\n          Val MAE=4.7151, RMSE=6.3494, LLL=-5.1817\nüéØ NEW BEST! R¬≤: -0.0845\n------------------------------------------------------------\nEpoch 2: LR=1.00e-04, Loss=31.4715\n          Train R¬≤=0.0716, Val R¬≤=-0.0104\n          Val MAE=4.5747, RMSE=6.1288, LLL=-5.0511\nüéØ NEW BEST! R¬≤: -0.0104\n------------------------------------------------------------\nEpoch 3: LR=1.00e-04, Loss=29.3725\n          Train R¬≤=0.1329, Val R¬≤=-0.1712\n          Val MAE=4.9182, RMSE=6.5985, LLL=-5.4763\n------------------------------------------------------------\nEpoch 4: LR=1.00e-04, Loss=27.9849\n          Train R¬≤=0.1728, Val R¬≤=-0.2151\n          Val MAE=4.7643, RMSE=6.7208, LLL=-5.1372\n------------------------------------------------------------\nEpoch 5: LR=1.00e-04, Loss=26.1500\n          Train R¬≤=0.2270, Val R¬≤=-0.0868\n          Val MAE=4.8505, RMSE=6.3560, LLL=-5.2798\n------------------------------------------------------------\nEpoch 6: LR=1.00e-04, Loss=24.7175\n          Train R¬≤=0.2692, Val R¬≤=-0.1691\n          Val MAE=5.0070, RMSE=6.5926, LLL=-5.3079\n------------------------------------------------------------\nEpoch 7: LR=1.00e-04, Loss=24.9618\n          Train R¬≤=0.2614, Val R¬≤=-0.1712\n          Val MAE=4.8747, RMSE=6.5983, LLL=-5.1926\n------------------------------------------------------------\nEpoch 8: LR=1.00e-04, Loss=21.5585\n          Train R¬≤=0.3626, Val R¬≤=-0.1744\n          Val MAE=5.1946, RMSE=6.6074, LLL=-5.4129\n------------------------------------------------------------\nEpoch 9: LR=5.00e-05, Loss=19.7298\n          Train R¬≤=0.4167, Val R¬≤=-0.6362\n          Val MAE=5.6949, RMSE=7.7989, LLL=-5.8791\n------------------------------------------------------------\nEpoch 10: LR=5.00e-05, Loss=20.5269\n          Train R¬≤=0.3932, Val R¬≤=-0.0734\n          Val MAE=4.5123, RMSE=6.3167, LLL=-4.8200\n------------------------------------------------------------\nEpoch 11: LR=5.00e-05, Loss=18.0459\n          Train R¬≤=0.4670, Val R¬≤=-0.6037\n          Val MAE=5.9086, RMSE=7.7211, LLL=-6.0094\n------------------------------------------------------------\nEpoch 12: LR=5.00e-05, Loss=18.2836\n          Train R¬≤=0.4599, Val R¬≤=-0.0887\n          Val MAE=4.8634, RMSE=6.3618, LLL=-5.1155\nEarly stopping at epoch 12\n\nüìà PERFORMING COMPREHENSIVE EVALUATION...\nClassification Accuracy: 0.3824\n\nüëÅÔ∏è  GENERATING ATTENTION MAPS...\n‚úÖ Attention map saved: attention_map_fold_2.png\n\nüîç PERFORMING ERROR ANALYSIS...\n\nüîç ERROR ANALYSIS - Worst Predictions:\n============================================================\n1. Patient ID00132637202222178761324: True=-0.32, Pred=-7.35, Error=7.03\n2. Patient ID00291637202279398396106: True=-9.41, Pred=-2.08, Error=7.34\n3. Patient ID00283637202278714365037: True=0.65, Pred=-7.30, Error=7.95\n4. Patient ID00168637202237852027833: True=-9.28, Pred=-0.88, Error=8.40\n5. Patient ID00130637202220059448013: True=-9.23, Pred=-0.54, Error=8.69\n6. Patient ID00355637202295106567614: True=10.93, Pred=0.39, Error=10.54\n7. Patient ID00047637202184938901501: True=-11.15, Pred=-0.04, Error=11.10\n8. Patient ID00102637202206574119190: True=-5.27, Pred=-16.96, Error=11.69\n9. Patient ID00076637202199015035026: True=11.14, Pred=-2.84, Error=13.98\n10. Patient ID00381637202299644114027: True=-20.42, Pred=-2.09, Error=18.32\n\n‚úÖ FOLD 2 COMPLETED\nClinical R¬≤: -0.7454, DL R¬≤: -0.0104\nImprovement: 0.7349\n\nüìä FOLD 3/5\n--------------------------------------------------\nTrain: 141 patients, Val: 35 patients\nDataset train: 139 patients with images\nDataset val: 35 patients with images\n\nü©∫ TRAINING CLINICAL BASELINE MODEL...\nClinical Baseline - R¬≤: -0.4843, MAE: 6.4896, RMSE: 9.6175, LLL: -3.5644\n\nüß† TRAINING DEEP LEARNING MODEL...\nEpoch 1: LR=1.00e-04, Loss=37.7400\n          Train R¬≤=-0.2453, Val R¬≤=-0.2508\n          Val MAE=5.7913, RMSE=8.8287, LLL=-6.1334\nüéØ NEW BEST! R¬≤: -0.2508\n------------------------------------------------------------\nEpoch 2: LR=1.00e-04, Loss=24.7899\n          Train R¬≤=0.1644, Val R¬≤=-0.2328\n          Val MAE=5.4799, RMSE=8.7649, LLL=-5.7499\nüéØ NEW BEST! R¬≤: -0.2328\n------------------------------------------------------------\nEpoch 3: LR=1.00e-04, Loss=22.1709\n          Train R¬≤=0.2520, Val R¬≤=-0.3708\n          Val MAE=5.6718, RMSE=9.2425, LLL=-6.1976\n------------------------------------------------------------\nEpoch 4: LR=1.00e-04, Loss=21.8858\n          Train R¬≤=0.2599, Val R¬≤=-0.5195\n          Val MAE=6.4419, RMSE=9.7309, LLL=-6.4714\n------------------------------------------------------------\nEpoch 5: LR=1.00e-04, Loss=20.3886\n          Train R¬≤=0.3105, Val R¬≤=-0.8388\n          Val MAE=7.0993, RMSE=10.7048, LLL=-7.1262\n------------------------------------------------------------\nEpoch 6: LR=1.00e-04, Loss=18.6914\n          Train R¬≤=0.3680, Val R¬≤=-0.2569\n          Val MAE=5.3599, RMSE=8.8501, LLL=-5.6633\n------------------------------------------------------------\nEpoch 7: LR=1.00e-04, Loss=18.7624\n          Train R¬≤=0.3649, Val R¬≤=-0.3580\n          Val MAE=5.9488, RMSE=9.1994, LLL=-6.0483\n------------------------------------------------------------\nEpoch 8: LR=1.00e-04, Loss=17.6800\n          Train R¬≤=0.4015, Val R¬≤=-0.5342\n          Val MAE=6.5197, RMSE=9.7778, LLL=-6.5814\n------------------------------------------------------------\nEpoch 9: LR=5.00e-05, Loss=15.5811\n          Train R¬≤=0.4732, Val R¬≤=-0.4674\n          Val MAE=6.3112, RMSE=9.5627, LLL=-6.3561\n------------------------------------------------------------\nEpoch 10: LR=5.00e-05, Loss=15.6361\n          Train R¬≤=0.4712, Val R¬≤=-0.2307\n          Val MAE=5.4126, RMSE=8.7577, LLL=-5.5436\nüéØ NEW BEST! R¬≤: -0.2307\n------------------------------------------------------------\nEpoch 11: LR=5.00e-05, Loss=14.0455\n          Train R¬≤=0.5254, Val R¬≤=-0.3742\n          Val MAE=6.2246, RMSE=9.2539, LLL=-6.2261\n------------------------------------------------------------\nEpoch 12: LR=5.00e-05, Loss=13.8806\n          Train R¬≤=0.5311, Val R¬≤=-0.2525\n          Val MAE=5.8639, RMSE=8.8349, LLL=-5.9386\n------------------------------------------------------------\nEpoch 13: LR=5.00e-05, Loss=13.5565\n          Train R¬≤=0.5420, Val R¬≤=-0.3646\n          Val MAE=6.2726, RMSE=9.2215, LLL=-6.2803\n------------------------------------------------------------\nEpoch 14: LR=5.00e-05, Loss=13.2402\n          Train R¬≤=0.5528, Val R¬≤=-0.3738\n          Val MAE=6.3339, RMSE=9.2527, LLL=-6.3015\n------------------------------------------------------------\nEpoch 15: LR=5.00e-05, Loss=12.1134\n          Train R¬≤=0.5912, Val R¬≤=-0.3452\n          Val MAE=6.6834, RMSE=9.1559, LLL=-6.5943\n------------------------------------------------------------\nEpoch 16: LR=5.00e-05, Loss=12.9367\n          Train R¬≤=0.5631, Val R¬≤=-0.8085\n          Val MAE=7.4911, RMSE=10.6161, LLL=-7.3082\n------------------------------------------------------------\nEpoch 17: LR=2.50e-05, Loss=11.2263\n          Train R¬≤=0.6215, Val R¬≤=-0.2900\n          Val MAE=6.0746, RMSE=8.9662, LLL=-6.0794\n------------------------------------------------------------\nEpoch 18: LR=2.50e-05, Loss=10.7451\n          Train R¬≤=0.6379, Val R¬≤=-0.3401\n          Val MAE=6.3026, RMSE=9.1385, LLL=-6.2750\n------------------------------------------------------------\nEpoch 19: LR=2.50e-05, Loss=10.6733\n          Train R¬≤=0.6404, Val R¬≤=-0.1935\n          Val MAE=5.6034, RMSE=8.6243, LLL=-5.6810\nüéØ NEW BEST! R¬≤: -0.1935\n------------------------------------------------------------\nEpoch 20: LR=2.50e-05, Loss=9.8125\n          Train R¬≤=0.6698, Val R¬≤=-0.3714\n          Val MAE=6.2140, RMSE=9.2446, LLL=-6.2284\n------------------------------------------------------------\nEpoch 21: LR=2.50e-05, Loss=6.2379\n          Train R¬≤=0.6459, Val R¬≤=-0.2186\n          Val MAE=5.7093, RMSE=8.7144, LLL=-5.7790\n------------------------------------------------------------\nEpoch 22: LR=2.50e-05, Loss=5.8093\n          Train R¬≤=0.6717, Val R¬≤=-0.4095\n          Val MAE=6.2801, RMSE=9.3722, LLL=-6.2657\n------------------------------------------------------------\nEpoch 23: LR=2.50e-05, Loss=6.1872\n          Train R¬≤=0.6497, Val R¬≤=-0.4410\n          Val MAE=6.3098, RMSE=9.4761, LLL=-6.2849\n------------------------------------------------------------\nEpoch 24: LR=2.50e-05, Loss=6.2257\n          Train R¬≤=0.6467, Val R¬≤=-0.4334\n          Val MAE=6.3256, RMSE=9.4511, LLL=-6.2950\n------------------------------------------------------------\nEpoch 25: LR=2.50e-05, Loss=6.3746\n          Train R¬≤=0.6377, Val R¬≤=-0.5036\n          Val MAE=6.2102, RMSE=9.6799, LLL=-6.1988\n------------------------------------------------------------\nEpoch 26: LR=1.25e-05, Loss=5.0707\n          Train R¬≤=0.7160, Val R¬≤=-0.5417\n          Val MAE=6.7864, RMSE=9.8018, LLL=-6.6975\n------------------------------------------------------------\nEpoch 27: LR=1.25e-05, Loss=5.6352\n          Train R¬≤=0.6821, Val R¬≤=-0.1452\n          Val MAE=5.7603, RMSE=8.4477, LLL=-5.8127\nüéØ NEW BEST! R¬≤: -0.1452\n------------------------------------------------------------\nEpoch 28: LR=1.25e-05, Loss=6.3006\n          Train R¬≤=0.6421, Val R¬≤=-0.4446\n          Val MAE=6.1730, RMSE=9.4880, LLL=-6.1584\n------------------------------------------------------------\nEpoch 29: LR=1.25e-05, Loss=5.0934\n          Train R¬≤=0.7146, Val R¬≤=-0.4157\n          Val MAE=6.5537, RMSE=9.3928, LLL=-6.4863\n------------------------------------------------------------\nEpoch 30: LR=1.25e-05, Loss=5.1068\n          Train R¬≤=0.7138, Val R¬≤=-0.2264\n          Val MAE=5.6390, RMSE=8.7421, LLL=-5.7109\n------------------------------------------------------------\n\nüìà PERFORMING COMPREHENSIVE EVALUATION...\nClassification Accuracy: 0.3143\n\nüëÅÔ∏è  GENERATING ATTENTION MAPS...\n‚úÖ Attention map saved: attention_map_fold_3.png\n\nüîç PERFORMING ERROR ANALYSIS...\n\nüîç ERROR ANALYSIS - Worst Predictions:\n============================================================\n1. Patient ID00170637202238079193844: True=4.60, Pred=-2.39, Error=6.99\n2. Patient ID00319637202283897208687: True=1.93, Pred=-5.44, Error=7.37\n3. Patient ID00068637202190879923934: True=-6.88, Pred=0.75, Error=7.63\n4. Patient ID00235637202261451839085: True=2.79, Pred=-5.29, Error=8.08\n5. Patient ID00207637202252526380974: True=-2.80, Pred=5.65, Error=8.45\n6. Patient ID00136637202224951350618: True=-0.97, Pred=-12.54, Error=11.58\n7. Patient ID00077637202199102000916: True=6.83, Pred=-5.64, Error=12.47\n8. Patient ID00032637202181710233084: True=-17.94, Pred=-5.21, Error=12.74\n9. Patient ID00249637202266730854017: True=-21.25, Pred=-3.09, Error=18.16\n10. Patient ID00110637202210673668310: True=-39.07, Pred=-2.42, Error=36.65\n\n‚úÖ FOLD 3 COMPLETED\nClinical R¬≤: -0.4843, DL R¬≤: -0.1452\nImprovement: 0.3391\n\nüìä FOLD 4/5\n--------------------------------------------------\nTrain: 141 patients, Val: 35 patients\nDataset train: 139 patients with images\nDataset val: 35 patients with images\n\nü©∫ TRAINING CLINICAL BASELINE MODEL...\nClinical Baseline - R¬≤: 0.0320, MAE: 5.4238, RMSE: 7.3845, LLL: -3.3860\n\nüß† TRAINING DEEP LEARNING MODEL...\nEpoch 1: LR=1.00e-04, Loss=39.5352\n          Train R¬≤=-0.2620, Val R¬≤=-0.1302\n          Val MAE=5.4666, RMSE=7.9790, LLL=-5.9571\nüéØ NEW BEST! R¬≤: -0.1302\n------------------------------------------------------------\nEpoch 2: LR=1.00e-04, Loss=28.7077\n          Train R¬≤=0.0608, Val R¬≤=-0.0498\n          Val MAE=5.5323, RMSE=7.6903, LLL=-5.8958\nüéØ NEW BEST! R¬≤: -0.0498\n------------------------------------------------------------\nEpoch 3: LR=1.00e-04, Loss=26.9613\n          Train R¬≤=0.1162, Val R¬≤=0.1247\n          Val MAE=5.1048, RMSE=7.0220, LLL=-5.3496\nüéØ NEW BEST! R¬≤: 0.1247\n------------------------------------------------------------\nEpoch 4: LR=1.00e-04, Loss=25.6068\n          Train R¬≤=0.1592, Val R¬≤=0.2254\n          Val MAE=5.1513, RMSE=6.6056, LLL=-5.3941\nüéØ NEW BEST! R¬≤: 0.2254\n------------------------------------------------------------\nEpoch 5: LR=1.00e-04, Loss=23.9446\n          Train R¬≤=0.2133, Val R¬≤=0.0590\n          Val MAE=5.2609, RMSE=7.2809, LLL=-5.4721\n------------------------------------------------------------\nEpoch 6: LR=1.00e-04, Loss=24.0919\n          Train R¬≤=0.2072, Val R¬≤=0.1564\n          Val MAE=4.7813, RMSE=6.8936, LLL=-5.0137\n------------------------------------------------------------\nEpoch 7: LR=1.00e-04, Loss=22.2720\n          Train R¬≤=0.2673, Val R¬≤=-0.0553\n          Val MAE=5.5575, RMSE=7.7103, LLL=-5.8560\n------------------------------------------------------------\nEpoch 8: LR=1.00e-04, Loss=19.9918\n          Train R¬≤=0.3424, Val R¬≤=-0.0799\n          Val MAE=5.8500, RMSE=7.7997, LLL=-5.9620\n------------------------------------------------------------\nEpoch 9: LR=1.00e-04, Loss=19.3793\n          Train R¬≤=0.3626, Val R¬≤=-0.1974\n          Val MAE=5.8418, RMSE=8.2130, LLL=-5.9561\n------------------------------------------------------------\nEpoch 10: LR=1.00e-04, Loss=20.7874\n          Train R¬≤=0.3154, Val R¬≤=-0.0545\n          Val MAE=5.3062, RMSE=7.7072, LLL=-5.4651\n------------------------------------------------------------\nEpoch 11: LR=5.00e-05, Loss=16.8867\n          Train R¬≤=0.4448, Val R¬≤=-0.0662\n          Val MAE=5.9220, RMSE=7.7499, LLL=-6.0172\n------------------------------------------------------------\nEpoch 12: LR=5.00e-05, Loss=16.3096\n          Train R¬≤=0.4639, Val R¬≤=0.1262\n          Val MAE=5.3045, RMSE=7.0159, LLL=-5.4353\n------------------------------------------------------------\nEpoch 13: LR=5.00e-05, Loss=13.9446\n          Train R¬≤=0.5423, Val R¬≤=0.0827\n          Val MAE=5.1806, RMSE=7.1884, LLL=-5.3553\n------------------------------------------------------------\nEpoch 14: LR=5.00e-05, Loss=15.2787\n          Train R¬≤=0.4979, Val R¬≤=0.0850\n          Val MAE=5.2383, RMSE=7.1793, LLL=-5.4031\nEarly stopping at epoch 14\n\nüìà PERFORMING COMPREHENSIVE EVALUATION...\nClassification Accuracy: 0.2857\n\nüëÅÔ∏è  GENERATING ATTENTION MAPS...\n‚úÖ Attention map saved: attention_map_fold_4.png\n\nüîç PERFORMING ERROR ANALYSIS...\n\nüîç ERROR ANALYSIS - Worst Predictions:\n============================================================\n1. Patient ID00122637202216437668965: True=-9.26, Pred=-2.38, Error=6.88\n2. Patient ID00342637202287526592911: True=-11.31, Pred=-4.14, Error=7.17\n3. Patient ID00025637202179541264076: True=-10.12, Pred=-1.02, Error=9.09\n4. Patient ID00218637202258156844710: True=6.12, Pred=-3.32, Error=9.44\n5. Patient ID00014637202177757139317: True=-15.41, Pred=-5.68, Error=9.72\n6. Patient ID00414637202310318891556: True=-20.66, Pred=-10.10, Error=10.55\n7. Patient ID00351637202289476567312: True=2.42, Pred=-8.35, Error=10.78\n8. Patient ID00364637202296074419422: True=-16.70, Pred=-3.97, Error=12.73\n9. Patient ID00073637202198167792918: True=-15.33, Pred=-1.71, Error=13.62\n10. Patient ID00186637202242472088675: True=-31.67, Pred=-14.29, Error=17.38\n\n‚úÖ FOLD 4 COMPLETED\nClinical R¬≤: 0.0320, DL R¬≤: 0.2254\nImprovement: 0.1934\n\nüìä FOLD 5/5\n--------------------------------------------------\nTrain: 141 patients, Val: 35 patients\nDataset train: 139 patients with images\nDataset val: 35 patients with images\n\nü©∫ TRAINING CLINICAL BASELINE MODEL...\nClinical Baseline - R¬≤: -0.1237, MAE: 4.7402, RMSE: 5.7391, LLL: -3.2620\n\nüß† TRAINING DEEP LEARNING MODEL...\nEpoch 1: LR=1.00e-04, Loss=47.7563\n          Train R¬≤=-0.2866, Val R¬≤=-0.0927\n          Val MAE=4.2560, RMSE=5.6595, LLL=-4.9991\nüéØ NEW BEST! R¬≤: -0.0927\n------------------------------------------------------------\nEpoch 2: LR=1.00e-04, Loss=32.4863\n          Train R¬≤=0.0992, Val R¬≤=-0.0058\n          Val MAE=4.3977, RMSE=5.4297, LLL=-4.8264\nüéØ NEW BEST! R¬≤: -0.0058\n------------------------------------------------------------\nEpoch 3: LR=1.00e-04, Loss=29.4092\n          Train R¬≤=0.1821, Val R¬≤=-0.1334\n          Val MAE=4.5883, RMSE=5.7639, LLL=-5.1096\n------------------------------------------------------------\nEpoch 4: LR=1.00e-04, Loss=28.0985\n          Train R¬≤=0.2171, Val R¬≤=0.0427\n          Val MAE=4.3899, RMSE=5.2972, LLL=-4.7879\nüéØ NEW BEST! R¬≤: 0.0427\n------------------------------------------------------------\nEpoch 5: LR=1.00e-04, Loss=26.8762\n          Train R¬≤=0.2509, Val R¬≤=0.0408\n          Val MAE=4.3620, RMSE=5.3024, LLL=-4.7273\n------------------------------------------------------------\nEpoch 6: LR=1.00e-04, Loss=27.0551\n          Train R¬≤=0.2449, Val R¬≤=-0.4351\n          Val MAE=5.2628, RMSE=6.4859, LLL=-5.4775\n------------------------------------------------------------\nEpoch 7: LR=1.00e-04, Loss=25.5063\n          Train R¬≤=0.2881, Val R¬≤=-0.1946\n          Val MAE=4.6597, RMSE=5.9174, LLL=-4.9080\n------------------------------------------------------------\nEpoch 8: LR=1.00e-04, Loss=24.1408\n          Train R¬≤=0.3261, Val R¬≤=-0.1314\n          Val MAE=4.6343, RMSE=5.7589, LLL=-4.8767\n------------------------------------------------------------\nEpoch 9: LR=1.00e-04, Loss=23.0016\n          Train R¬≤=0.3577, Val R¬≤=0.1203\n          Val MAE=4.0591, RMSE=5.0781, LLL=-4.3524\nüéØ NEW BEST! R¬≤: 0.1203\n------------------------------------------------------------\nEpoch 10: LR=1.00e-04, Loss=23.1019\n          Train R¬≤=0.3547, Val R¬≤=-0.1566\n          Val MAE=4.5658, RMSE=5.8226, LLL=-4.8068\n------------------------------------------------------------\nEpoch 11: LR=1.00e-04, Loss=19.9683\n          Train R¬≤=0.4428, Val R¬≤=-0.2351\n          Val MAE=4.7490, RMSE=6.0170, LLL=-4.9761\n------------------------------------------------------------\nEpoch 12: LR=1.00e-04, Loss=19.5310\n          Train R¬≤=0.4551, Val R¬≤=-0.3765\n          Val MAE=4.8002, RMSE=6.3519, LLL=-5.0008\n------------------------------------------------------------\nEpoch 13: LR=1.00e-04, Loss=21.2977\n          Train R¬≤=0.4054, Val R¬≤=-0.2263\n          Val MAE=4.8133, RMSE=5.9955, LLL=-4.9986\n------------------------------------------------------------\nEpoch 14: LR=1.00e-04, Loss=17.6352\n          Train R¬≤=0.5082, Val R¬≤=-0.4046\n          Val MAE=5.0028, RMSE=6.4165, LLL=-5.1580\n------------------------------------------------------------\nEpoch 15: LR=1.00e-04, Loss=17.5926\n          Train R¬≤=0.5094, Val R¬≤=-0.1944\n          Val MAE=4.7970, RMSE=5.9170, LLL=-4.9822\n------------------------------------------------------------\nEpoch 16: LR=5.00e-05, Loss=16.2382\n          Train R¬≤=0.5474, Val R¬≤=-0.3342\n          Val MAE=4.8604, RMSE=6.2537, LLL=-5.0265\n------------------------------------------------------------\nEpoch 17: LR=5.00e-05, Loss=18.0378\n          Train R¬≤=0.4968, Val R¬≤=-0.2655\n          Val MAE=4.8149, RMSE=6.0906, LLL=-5.0019\n------------------------------------------------------------\nEpoch 18: LR=5.00e-05, Loss=15.7421\n          Train R¬≤=0.5614, Val R¬≤=-0.4310\n          Val MAE=5.1082, RMSE=6.4765, LLL=-5.2466\n------------------------------------------------------------\nEpoch 19: LR=5.00e-05, Loss=15.1811\n          Train R¬≤=0.5772, Val R¬≤=-0.3920\n          Val MAE=4.7816, RMSE=6.3876, LLL=-4.9578\nEarly stopping at epoch 19\n\nüìà PERFORMING COMPREHENSIVE EVALUATION...\nClassification Accuracy: 0.2857\n\nüëÅÔ∏è  GENERATING ATTENTION MAPS...\n‚úÖ Attention map saved: attention_map_fold_5.png\n\nüîç PERFORMING ERROR ANALYSIS...\n\nüîç ERROR ANALYSIS - Worst Predictions:\n============================================================\n1. Patient ID00009637202177434476278: True=-8.44, Pred=-2.08, Error=6.36\n2. Patient ID00048637202185016727717: True=-1.60, Pred=-8.10, Error=6.50\n3. Patient ID00202637202249376026949: True=-13.01, Pred=-5.43, Error=7.58\n4. Patient ID00086637202203494931510: True=0.52, Pred=-7.38, Error=7.90\n5. Patient ID00061637202188184085559: True=2.63, Pred=-5.73, Error=8.37\n6. Patient ID00419637202311204720264: True=-3.77, Pred=-12.51, Error=8.74\n7. Patient ID00307637202282126172865: True=-11.38, Pred=-1.52, Error=9.85\n8. Patient ID00010637202177584971671: True=-19.91, Pred=-6.22, Error=13.69\n9. Patient ID00288637202279148973731: True=8.60, Pred=-6.34, Error=14.94\n10. Patient ID00042637202184406822975: True=-1.02, Pred=-16.01, Error=14.99\n\n‚úÖ FOLD 5 COMPLETED\nClinical R¬≤: -0.1237, DL R¬≤: 0.1203\nImprovement: 0.2439\n\n======================================================================\nüéØ FINAL COMPREHENSIVE RESULTS\n======================================================================\n\nüìä 5-FOLD CROSS VALIDATION RESULTS:\n   fold  clinical_r2  clinical_mae  clinical_lll   dl_r2  dl_mae  dl_lll  \\\n0     1      -0.3138        4.8450       -3.2784  0.1119  3.9147 -4.2191   \n1     2      -0.7454        6.6601       -3.6176 -0.0104  4.5747 -5.0511   \n2     3      -0.4843        6.4896       -3.5644 -0.1452  5.7603 -5.8127   \n3     4       0.0320        5.4238       -3.3860  0.2254  5.1513 -5.3941   \n4     5      -0.1237        4.7402       -3.2620  0.1203  4.0591 -4.3524   \n\n   classification_accuracy  mean_error  std_error  \n0                   0.4000      4.4461     3.2560  \n1                   0.3824      5.1437     4.1934  \n2                   0.3143      5.5817     6.7077  \n3                   0.2857      5.2958     4.1215  \n4                   0.2857      4.5614     4.0974  \n\nüìà AVERAGE PERFORMANCE ACROSS FOLDS:\nfold                       3.0000\nclinical_r2               -0.3270\nclinical_mae               5.6317\nclinical_lll              -3.4217\ndl_r2                      0.0604\ndl_mae                     4.6920\ndl_lll                    -4.9659\nclassification_accuracy    0.3336\nmean_error                 5.0057\nstd_error                  4.4752\ndtype: float64\n\nüí™ DEEP LEARNING IMPROVEMENT OVER CLINICAL BASELINE:\nR¬≤ Improvement: 0.3874\nMAE Improvement: 0.9397\nLLL Improvement: -1.5442\n\n‚úÖ COMPREHENSIVE ANALYSIS COMPLETED!\nüìÅ Generated files:\n   - calibration_fold_*.png (Calibration plots)\n   - scatter_fold_*.png (Prediction scatter plots)\n   - training_curves_fold_*.png (Training history)\n   - attention_map_fold_*.png (Grad-CAM visualizations)\n   - error_analysis_fold_*.png (Error analysis)\n   - final_comparison.png (Model comparison)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**V2 Testing**\n# Critical implementation bugs (fix first)\n\n\n1. pydicom API misuse\n\n- AttributeError: module 'pydicom' has no attribute 'read_file'. Use the supported API: pydicom.dcmread(...) (older read_file deprecations).\n- Verify pydicom version and use dcmread. Also use .pixel_array only after confirming hasattr.\n\n2. Random projection inside forward pass (major bug)\n\n- tab_proj = F.linear(tab_expanded, torch.randn(1024, 512).to(images.device))\n- You are using a new random matrix every forward pass. That destroys learning of cross-modal attention. Replace with a trainable nn.Linear(512, 1024) (initialized once). This is probably the single biggest structural bug.\n\n3. Inconsistent sigma / scale handling and arbitrary multipliers\n\n- In training you clamp sigma = exp(log_var/2) to min 2.0 — while evaluation uses sigma floor 70.0. In submission you set confidence_val = max(exp(log_var/2) * 70, 70) (why multiply by 70?). This mismatch creates meaningless confidences and ruins LLL.\n- Fix: keep internal sigma in natural units of FVC; do not multiply by arbitrary constants. Only apply the contest evaluation floor (70) at scoring time — not during training.\n\n4. Submission pipeline clipping hides bug\n\n- You clamp predictions to [800,6000] during submission — all predictions hitting 800 likely reflect upstream underprediction or wrong scale. Remove clipping while debugging; investigate raw predictions distribution first.\n\n5. Hard-coded patient exclusions & path issues\n\n- Filtering out two patient IDs silently in dataset init is suspicious. Document why or remove. Ensure mapping patient → image files is correct and complete.\n\n6. ModelWithConfidence referenced but not defined → NameError later. Keep code consistent.","metadata":{}},{"cell_type":"code","source":"# Downgrade numpy and scipy to compatible versions for scikit-learn and scipy\n!pip install --quiet numpy==1.26.4 scipy==1.13.0\nimport os\nos._exit(00)  # Force kernel restart after pip install","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T06:59:07.239655Z","iopub.execute_input":"2025-09-05T06:59:07.240276Z","execution_failed":"2025-09-05T06:59:19.664Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibjpeg-libjpeg 2.3.0 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# =============================================================================\n# Revised Implementation: Tabular + Image Model with Laplace Log-Likelihood Loss\n# =============================================================================\n\n# Imports\nimport os\nimport cv2\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GroupKFold\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\nimport math\nimport random\nfrom pathlib import Path\n\n# Set device\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {DEVICE}\")\n\n# Seed for reproducibility\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\n\n# =============================================================================\n# Load Data and Basic Processing\n# =============================================================================\n\nDATA_DIR = Path(\"/kaggle/input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTRAIN_CSV = DATA_DIR / \"train.csv\"\n\n# Load training csv\ntrain_df = pd.read_csv(TRAIN_CSV)\n\n# Compute baseline features for each patient\nbaseline_features = {}\npatient_data_dict = {}\nfor patient in train_df['Patient'].unique():\n    patient_data = train_df[train_df['Patient'] == patient].sort_values('Weeks')\n    baseline = patient_data.iloc[0]\n    patient_data_dict[patient] = patient_data\n    baseline_features[patient] = {\n        'Age': baseline['Age'],\n        'Sex': baseline['Sex'],\n        'SmokingStatus': baseline['SmokingStatus'],\n        'BaselineFVC': baseline['FVC'],\n        'BaselineWeeks': baseline['Weeks'],\n        'Percent': baseline.get('Percent', 50.0)\n    }\n\n# Prepare scalers (8 features w/o week delta, 9 with)\ntabular_data_8 = []\ntabular_data_9 = []\nfor feats in baseline_features.values():\n    row_8 = [\n        feats['Age'],\n        1 if feats['Sex']=='Female' else 0,\n        1 if feats['SmokingStatus']=='Never smoked' else 0,\n        1 if feats['SmokingStatus']=='Ex-smoker' else 0,\n        1 if feats['SmokingStatus']=='Currently smokes' else 0,\n        feats['BaselineFVC'],\n        feats['BaselineWeeks'],\n        feats['Percent']\n    ]\n    tabular_data_8.append(row_8)\n    tabular_data_9.append(row_8 + [0.0])  # baseline delta = 0\nscaler_8 = StandardScaler().fit(tabular_data_8)\nscaler_9 = StandardScaler().fit(tabular_data_9)\n\n# Function to get scaled tabular features\ndef get_tabular_features(patient_id, current_week):\n    feats = baseline_features[patient_id]\n    features = [\n        feats['Age'],\n        1 if feats['Sex']=='Female' else 0,\n        1 if feats['SmokingStatus']=='Never smoked' else 0,\n        1 if feats['SmokingStatus']=='Ex-smoker' else 0,\n        1 if feats['SmokingStatus']=='Currently smokes' else 0,\n        feats['BaselineFVC'],\n        feats['BaselineWeeks'],\n        feats['Percent']\n    ]\n    week_delta = current_week - feats['BaselineWeeks']\n    features.append(week_delta)\n    scaled = scaler_9.transform([features])\n    return scaled.flatten().astype(np.float32)\n\n# Create target dict: patient -> {week: FVC}\ntarget_dict = {}\nfor patient, data in patient_data_dict.items():\n    target_dict[patient] = {row.Weeks: row.FVC for _, row in data.iterrows()}\n\n# =============================================================================\n# Dataset: Tabular + Image\n# =============================================================================\n\nclass TabularImageDataset(Dataset):\n    def __init__(self, patient_data, target_dict, img_dir, transform=None):\n        \"\"\"\n        patient_data: dict of patient -> DataFrame (weeks, FVC, etc)\n        img_dir: base directory with patient subfolders of DICOM images\n        transform: optional image transformation (albumentations)\n        \"\"\"\n        self.samples = []\n        self.img_dir = img_dir\n        self.transform = transform\n        self.patient_images = {}\n        \n        # Gather samples and baseline image\n        for patient, data in patient_data.items():\n            data = data.sort_values('Weeks')\n            patient_folder = img_dir / patient\n            if patient_folder.exists():\n                files = sorted([str(f) for f in patient_folder.rglob(\"*.dcm\")])\n                if files:\n                    # Choose middle slice as representative CT image\n                    mid_idx = len(files)//2\n                    self.patient_images[patient] = files[mid_idx]\n                else:\n                    self.patient_images[patient] = None\n            else:\n                self.patient_images[patient] = None\n            \n            for _, row in data.iterrows():\n                self.samples.append((patient, row['Weeks'], row['FVC']))\n        print(f\"Dataset initialized: {len(self.samples)} samples for {len(self.patient_images)} patients\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        patient, week, fvc = self.samples[idx]\n        # Tabular features\n        tab_feats = get_tabular_features(patient, week)\n        tab_tensor = torch.tensor(tab_feats, dtype=torch.float32)\n        # Image features\n        img_path = self.patient_images.get(patient, None)\n        if img_path is not None:\n            ds = pydicom.dcmread(img_path)\n            img = ds.pixel_array.astype(np.float32)\n            # Normalize to [0, 1]\n            img -= img.min()\n            img /= (img.max() + 1e-6)\n            # Convert to 3 channels\n            img = np.stack([img, img, img], axis=-1)\n            if self.transform:\n                img = self.transform(image=img)['image']  # Albumentations returns a dict\n            else:\n                img = torch.from_numpy(img.transpose(2, 0, 1)).float()\n        else:\n            # If no image found, use zeros\n            img = torch.zeros((3, 224, 224), dtype=torch.float32)\n        target = torch.tensor(fvc, dtype=torch.float32)\n        return img, tab_tensor, target\n\n# =============================================================================\n# Model: CNN (ResNet) + Tabular MLP\n# =============================================================================\n\nclass TabularImageModel(nn.Module):\n    def __init__(self, tab_input_dim=9, pretrained=True):\n        super().__init__()\n        # CNN backbone (ResNet18)\n        self.cnn = models.resnet18(pretrained=pretrained)\n        num_features = self.cnn.fc.in_features\n        self.cnn.fc = nn.Identity()  # Remove final classification layer\n        \n        # Tabular branch MLP\n        self.tab_net = nn.Sequential(\n            nn.Linear(tab_input_dim, 32), nn.ReLU(),\n            nn.Linear(32, 32), nn.ReLU()\n        )\n        \n        # Combined head\n        self.head = nn.Sequential(\n            nn.Linear(num_features + 32, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1)\n        )\n        # Learnable log-scale (sigma) parameter for Laplace\n        self.log_scale = nn.Parameter(torch.tensor(0.0))\n    \n    def forward(self, img, tab):\n        img_feat = self.cnn(img)               # [batch, num_features]\n        tab_feat = self.tab_net(tab)           # [batch, 32]\n        combined = torch.cat([img_feat, tab_feat], dim=1)\n        mean_pred = self.head(combined).squeeze(-1)\n        log_scale = self.log_scale.expand(mean_pred.size(0))\n        return mean_pred, log_scale\n\n# =============================================================================\n# Loss and Metrics (Laplace log-likelihood)\n# =============================================================================\n\ndef laplace_nll_loss(mean_pred, log_scale, targets):\n    scale = torch.exp(log_scale) + 1e-6\n    return torch.mean(torch.abs(targets - mean_pred) / scale + log_scale + math.log(2))\n\ndef laplace_log_likelihood(y_true, y_pred, sigma):\n    sigma = np.maximum(sigma, 1e-6)\n    delta = np.abs(y_true - y_pred)\n    return -np.sqrt(2) * delta / sigma - np.log(np.sqrt(2) * sigma)\n\ndef compute_metrics(mean_pred, log_scale, targets):\n    mean_np = mean_pred.detach().cpu().numpy()\n    targ_np = targets.detach().cpu().numpy()\n    sigma_np = np.exp(log_scale.detach().cpu().numpy())\n    mse = ((targ_np - mean_np)**2).mean()\n    rmse = np.sqrt(mse)\n    # R2 score\n    r2 = 1 - np.sum((targ_np - mean_np)**2) / np.sum((targ_np - targ_np.mean())**2)\n    lll = np.mean(laplace_log_likelihood(targ_np, mean_np, sigma_np))\n    return {'mse': mse, 'rmse': rmse, 'r2': r2, 'lll': lll}\n\n# =============================================================================\n# Prepare DataLoaders\n# =============================================================================\n\n# Split patients into train/val groups using GroupKFold\npatients = list(baseline_features.keys())\ngkf = GroupKFold(n_splits=5)\ntrain_idx, val_idx = next(gkf.split(patients, groups=patients))\ntrain_patients = [patients[i] for i in train_idx]\nval_patients = [patients[i] for i in val_idx]\n\ntrain_data = {p: patient_data_dict[p] for p in train_patients}\nval_data = {p: patient_data_dict[p] for p in val_patients}\n\n# Image transformation: resize + normalize\ntransform = albu.Compose([\n    albu.Resize(224, 224),\n    albu.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n    ToTensorV2()\n])\n\ntrain_dataset = TabularImageDataset(train_data, target_dict, TRAIN_DIR, transform=transform)\nval_dataset = TabularImageDataset(val_data, target_dict, TRAIN_DIR, transform=transform)\n\nBATCH_SIZE = 8\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# =============================================================================\n# Training Loop\n# =============================================================================\n\nclass Trainer:\n    def __init__(self, model, device, lr=1e-3):\n        self.model = model.to(device)\n        self.device = device\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            self.optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n        self.best_lll = -float('inf')\n    \n    def train_epoch(self, loader):\n        self.model.train()\n        total_loss = 0\n        metrics_sum = {'mse': 0, 'rmse': 0, 'r2': 0, 'lll': 0}\n        for images, tabular, targets in loader:\n            images = images.to(self.device)\n            tabular = tabular.to(self.device)\n            targets = targets.to(self.device)\n            self.optimizer.zero_grad()\n            mean_pred, log_scale = self.model(images, tabular)\n            loss = laplace_nll_loss(mean_pred, log_scale, targets)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            self.optimizer.step()\n            total_loss += loss.item()\n            batch_metrics = compute_metrics(mean_pred, log_scale, targets)\n            for k in metrics_sum:\n                metrics_sum[k] += batch_metrics[k]\n        n_batches = len(loader)\n        avg_metrics = {k: v / n_batches for k,v in metrics_sum.items()}\n        return total_loss / n_batches, avg_metrics\n    \n    def validate(self, loader):\n        self.model.eval()\n        total_loss = 0\n        metrics_sum = {'mse': 0, 'rmse': 0, 'r2': 0, 'lll': 0}\n        with torch.no_grad():\n            for images, tabular, targets in loader:\n                images = images.to(self.device)\n                tabular = tabular.to(self.device)\n                targets = targets.to(self.device)\n                mean_pred, log_scale = self.model(images, tabular)\n                loss = laplace_nll_loss(mean_pred, log_scale, targets)\n                total_loss += loss.item()\n                batch_metrics = compute_metrics(mean_pred, log_scale, targets)\n                for k in metrics_sum:\n                    metrics_sum[k] += batch_metrics[k]\n        n_batches = len(loader)\n        avg_metrics = {k: v / n_batches for k,v in metrics_sum.items()}\n        return total_loss / n_batches, avg_metrics\n    \n    def train(self, train_loader, val_loader, epochs=10):\n        for epoch in range(1, epochs+1):\n            train_loss, train_metrics = self.train_epoch(train_loader)\n            val_loss, val_metrics = self.validate(val_loader)\n            self.scheduler.step(val_loss)\n            print(f\"Epoch {epoch}/{epochs}: Train Loss={train_loss:.3f}, Val Loss={val_loss:.3f}\")\n            print(f\"  Train RMSE: {train_metrics['rmse']:.1f}, R2: {train_metrics['r2']:.3f}, LLL: {train_metrics['lll']:.3f}\")\n            print(f\"  Val   RMSE: {val_metrics['rmse']:.1f}, R2: {val_metrics['r2']:.3f}, LLL: {val_metrics['lll']:.3f}\")\n            if val_metrics['lll'] > self.best_lll:\n                self.best_lll = val_metrics['lll']\n                torch.save(self.model.state_dict(), \"best_model.pth\")\n                print(\"  --> New best model saved (improved LLL).\")\n                print(\"-\" * 50)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:03:14.699926Z","iopub.execute_input":"2025-09-05T07:03:14.700838Z","iopub.status.idle":"2025-09-05T07:04:34.609926Z","shell.execute_reply.started":"2025-09-05T07:03:14.700803Z","shell.execute_reply":"2025-09-05T07:04:34.609232Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nDataset initialized: 1236 samples for 140 patients\nDataset initialized: 313 samples for 36 patients\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Instantiate model and train\nmodel = TabularImageModel(tab_input_dim=9, pretrained=True)\ntrainer = Trainer(model, DEVICE, lr=1e-4)\ntrainer.train(train_loader, val_loader, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:04:34.611036Z","iopub.execute_input":"2025-09-05T07:04:34.611614Z","iopub.status.idle":"2025-09-05T07:06:06.585523Z","shell.execute_reply.started":"2025-09-05T07:04:34.611592Z","shell.execute_reply":"2025-09-05T07:06:06.584473Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 229MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10: Train Loss=2734.969, Val Loss=2333.327\n  Train RMSE: 2867.8, R2: -17.617, LLL: -3866.810\n  Val   RMSE: 2401.7, R2: -inf, LLL: -3299.186\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 2/10: Train Loss=2616.116, Val Loss=2144.188\n  Train RMSE: 2793.6, R2: -16.421, LLL: -3698.737\n  Val   RMSE: 2246.7, R2: -inf, LLL: -3031.696\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 3/10: Train Loss=2286.081, Val Loss=1650.843\n  Train RMSE: 2501.8, R2: -12.086, LLL: -3232.047\n  Val   RMSE: 1784.8, R2: -inf, LLL: -2333.994\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 4/10: Train Loss=1545.156, Val Loss=879.873\n  Train RMSE: 1818.6, R2: -6.423, LLL: -2184.350\n  Val   RMSE: 1042.0, R2: -inf, LLL: -1243.672\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 5/10: Train Loss=925.533, Val Loss=765.721\n  Train RMSE: 1187.8, R2: -1.918, LLL: -1308.153\n  Val   RMSE: 951.1, R2: -inf, LLL: -1082.231\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 6/10: Train Loss=726.074, Val Loss=624.886\n  Train RMSE: 958.7, R2: -0.962, LLL: -1026.095\n  Val   RMSE: 802.2, R2: -inf, LLL: -883.057\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 7/10: Train Loss=608.150, Val Loss=630.681\n  Train RMSE: 807.9, R2: -0.443, LLL: -859.346\n  Val   RMSE: 789.5, R2: -inf, LLL: -891.248\nEpoch 8/10: Train Loss=495.918, Val Loss=572.031\n  Train RMSE: 677.5, R2: -0.117, LLL: -700.634\n  Val   RMSE: 713.3, R2: -inf, LLL: -808.302\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 9/10: Train Loss=439.080, Val Loss=533.432\n  Train RMSE: 593.5, R2: 0.227, LLL: -620.256\n  Val   RMSE: 671.4, R2: -inf, LLL: -753.712\n  --> New best model saved (improved LLL).\n--------------------------------------------------\nEpoch 10/10: Train Loss=402.509, Val Loss=567.963\n  Train RMSE: 547.5, R2: 0.280, LLL: -568.538\n  Val   RMSE: 695.3, R2: -inf, LLL: -802.545\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# OSIC: Tabular + 2.5D CT Model with Proper Laplace Objective\n# ============================================================\n\nimport os, random, math, glob\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\n\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\n# ---------------------------\n# Reproducibility & Device\n# ---------------------------\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# ---------------------------\n# Data paths\n# ---------------------------\nDATA_DIR = Path(\"/kaggle/input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTRAIN_CSV = DATA_DIR / \"train.csv\"\n\ndf = pd.read_csv(TRAIN_CSV)\n\n# ---------------------------\n# Patient-level structures\n# ---------------------------\npatient_data = {}\nbaseline = {}\nfor pid in df[\"Patient\"].unique():\n    d = df[df[\"Patient\"] == pid].sort_values(\"Weeks\")\n    patient_data[pid] = d.reset_index(drop=True)\n    b = d.iloc[0]\n    baseline[pid] = {\n        \"Age\": b[\"Age\"],\n        \"Sex\": b[\"Sex\"],  # \"Male\"/\"Female\"\n        \"SmokingStatus\": b[\"SmokingStatus\"],\n        \"BaselineFVC\": b[\"FVC\"],\n        \"BaselineWeeks\": b[\"Weeks\"],\n        \"Percent\": b.get(\"Percent\", 50.0),\n    }\n\n# ---------------------------\n# KFold split by patient\n# ---------------------------\npatients = list(patient_data.keys())\ngkf = GroupKFold(n_splits=5)\ntrain_idx, val_idx = next(gkf.split(patients, groups=patients))\ntrain_pids = [patients[i] for i in train_idx]\nval_pids   = [patients[i] for i in val_idx]\n\ntrain_pat_data = {p: patient_data[p] for p in train_pids}\nval_pat_data   = {p: patient_data[p] for p in val_pids}\n\n# ---------------------------\n# Scalers: fit on TRAIN ONLY\n# ---------------------------\ndef build_rows(feats, week_delta=0.0):\n    return [\n        feats[\"Age\"],\n        1 if feats[\"Sex\"] == \"Female\" else 0,\n        1 if feats[\"SmokingStatus\"] == \"Never smoked\" else 0,\n        1 if feats[\"SmokingStatus\"] == \"Ex-smoker\" else 0,\n        1 if feats[\"SmokingStatus\"] == \"Currently smokes\" else 0,\n        feats[\"BaselineFVC\"],\n        feats[\"BaselineWeeks\"],\n        feats[\"Percent\"],\n        week_delta,\n    ]\n\nX_train_for_scaler = []\nfor p in train_pids:\n    X_train_for_scaler.append(build_rows(baseline[p], week_delta=0.0))\nX_train_for_scaler = np.array(X_train_for_scaler, dtype=np.float32)\nscaler = StandardScaler().fit(X_train_for_scaler)  # 9 features incl. delta\n\ndef get_features(pid, current_week):\n    feats = baseline[pid]\n    week_delta = float(current_week - feats[\"BaselineWeeks\"])\n    x = np.array(build_rows(feats, week_delta), dtype=np.float32).reshape(1, -1)\n    x = scaler.transform(x).astype(np.float32).flatten()\n    return x\n\n# ---------------------------\n# DICOM utils (HU-ish window)\n# ---------------------------\ndef load_dicom(path):\n    d = pydicom.dcmread(path, force=True)\n    img = d.pixel_array.astype(np.float32)\n\n    # HU conversion if possible\n    intercept = getattr(d, \"RescaleIntercept\", 0.0)\n    slope = getattr(d, \"RescaleSlope\", 1.0)\n    img = img * float(slope) + float(intercept)\n\n    # Window to lung-ish range and normalize to [-1, 1]\n    img = np.clip(img, -1200, 600)\n    img = (img + 300.0) / 900.0  # center ~ -300 HU\n    img = np.clip(img, -1.0, 1.0)\n    return img\n\ndef get_patient_slices(patient_folder):\n    files = sorted(glob.glob(str(patient_folder / \"*.dcm\")))\n    return files\n\ndef load_2p5d(patient_folder, target_hw=(224, 224)):\n    files = get_patient_slices(patient_folder)\n    if len(files) == 0:\n        # 3 blank channels for missing patients\n        return np.zeros((*target_hw, 3), dtype=np.float32)\n\n    mid = len(files) // 2\n    idxs = [max(0, mid - 1), mid, min(len(files) - 1, mid + 1)]\n    slices = []\n    for i in idxs:\n        img = load_dicom(files[i])\n        if img.shape != target_hw:\n            img = cv2.resize(img, target_hw, interpolation=cv2.INTER_AREA)\n        slices.append(img)\n    arr = np.stack(slices, axis=-1)  # H x W x 3 (three adjacent slices)\n    return arr\n\n# ---------------------------\n# Albumentations\n# ---------------------------\ntrain_tfms = albu.Compose([\n    albu.HorizontalFlip(p=0.25),\n    albu.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.05, rotate_limit=5, p=0.3, border_mode=cv2.BORDER_REFLECT_101),\n    ToTensorV2()\n])\n\nval_tfms = albu.Compose([ToTensorV2()])\n\n# ---------------------------\n# Dataset\n# ---------------------------\nclass OSICDataset(Dataset):\n    def __init__(self, pat_dict, split=\"train\", img_dir=TRAIN_DIR, tfms=None):\n        self.samples = []\n        self.img_dir = img_dir\n        self.tfms = tfms\n        self.split = split\n\n        # Pre-compute a per-patient representative 2.5D volume (mid ±1)\n        self.patient_img = {}\n        for p, d in pat_dict.items():\n            folder = img_dir / p\n            if folder.exists():\n                arr = load_2p5d(folder, target_hw=(224, 224))  # H,W,3\n            else:\n                arr = np.zeros((224, 224, 3), dtype=np.float32)\n            self.patient_img[p] = arr  # cached\n\n            # build samples (one per visit)\n            for _, row in d.iterrows():\n                self.samples.append((p, int(row[\"Weeks\"]), float(row[\"FVC\"])))\n\n        print(f\"{split} dataset: {len(self.samples)} samples, {len(self.patient_img)} patients\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        pid, week, fvc = self.samples[idx]\n        x_tab = get_features(pid, week)                       # (9,)\n        img = self.patient_img[pid]                           # H,W,3\n        if self.tfms is not None:\n            img = self.tfms(image=img)[\"image\"]               # 3,H,W\n        else:\n            img = torch.from_numpy(img.transpose(2, 0, 1))    # 3,H,W\n\n        return img.float(), torch.tensor(x_tab, dtype=torch.float32), torch.tensor(fvc, dtype=torch.float32)\n\n# ---------------------------\n# Model: ResNet18 + Tabular MLP\n# ---------------------------\nclass FusionNet(nn.Module):\n    def __init__(self, tab_dim=9, pretrained=True):\n        super().__init__()\n        self.cnn = models.resnet18(pretrained=pretrained)\n        n = self.cnn.fc.in_features\n        self.cnn.fc = nn.Identity()\n\n        self.tab = nn.Sequential(\n            nn.Linear(tab_dim, 64), nn.ReLU(),\n            nn.Linear(64, 64), nn.ReLU()\n        )\n\n        self.fuse = nn.Sequential(\n            nn.Linear(n + 64, 128), nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64), nn.ReLU()\n        )\n\n        # Separate heads: mean and log_sigma\n        self.head_mean = nn.Linear(64, 1)\n        self.head_logsig = nn.Linear(64, 1)\n\n    def forward(self, img, tab):\n        f_img = self.cnn(img)          # [B, n]\n        f_tab = self.tab(tab)          # [B, 64]\n        f = torch.cat([f_img, f_tab], dim=1)\n        f = self.fuse(f)               # [B, 64]\n        mean = self.head_mean(f).squeeze(-1)\n        log_sig = self.head_logsig(f).squeeze(-1)\n        return mean, log_sig\n\n# ---------------------------\n# Loss/metrics (OSIC Laplace)\n# ---------------------------\ndef laplace_nll_with_floor(mean, log_sigma, target, sigma_floor=70.0):\n    # OSIC uses sigma_clipped = max(sigma, 70)\n    sigma = torch.exp(log_sigma)\n    sigma = torch.clamp(sigma, min=sigma_floor)\n    # Negative of OSIC LLL to minimize:\n    # LLL = -sqrt(2)*|e|/sigma - log(sqrt(2)*sigma)\n    e = torch.abs(target - mean)\n    loss = (math.sqrt(2.0) * e / sigma) + torch.log(math.sqrt(2.0) * sigma)\n    return loss.mean()\n\n@torch.no_grad()\ndef evaluate_loader(model, loader, device, sigma_floor=70.0):\n    model.eval()\n    all_mean = []\n    all_sigma = []\n    all_target = []\n    for img, tab, y in loader:\n        img, tab, y = img.to(device), tab.to(device), y.to(device)\n        mean, log_sigma = model(img, tab)\n        sigma = torch.exp(log_sigma)\n        sigma = torch.clamp(sigma, min=sigma_floor)\n        all_mean.append(mean.cpu().numpy())\n        all_sigma.append(sigma.cpu().numpy())\n        all_target.append(y.cpu().numpy())\n    yhat = np.concatenate(all_mean)\n    sigma = np.concatenate(all_sigma)\n    y = np.concatenate(all_target)\n\n    # Metrics across full validation set\n    mse = np.mean((y - yhat) ** 2)\n    rmse = float(np.sqrt(mse))\n    var = np.var(y)\n    r2 = float(1.0 - np.sum((y - yhat) ** 2) / (np.sum((y - np.mean(y)) ** 2) + 1e-12)) if var > 0 else 0.0\n    # OSIC LLL (higher is better)\n    lll = float(np.mean(-np.sqrt(2.0) * np.abs(y - yhat) / sigma - np.log(np.sqrt(2.0) * sigma)))\n    return {\"rmse\": rmse, \"r2\": r2, \"lll\": lll}\n\n# ---------------------------\n# DataLoaders\n# ---------------------------\ntrain_ds = OSICDataset(train_pat_data, split=\"train\", img_dir=TRAIN_DIR, tfms=train_tfms)\nval_ds   = OSICDataset(val_pat_data,   split=\"val\",   img_dir=TRAIN_DIR, tfms=val_tfms)\n\nBATCH_SIZE = 8\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# ---------------------------\n# Trainer\n# ---------------------------\nclass Trainer:\n    def __init__(self, model, device, lr=1e-4):\n        self.model = model.to(device)\n        self.opt = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)\n        self.sched = torch.optim.lr_scheduler.ReduceLROnPlateau(self.opt, mode=\"min\", patience=3, factor=0.5, verbose=True)\n        self.best_lll = -1e18\n\n    def fit(self, train_loader, val_loader, epochs=10):\n        for epoch in range(1, epochs+1):\n            self.model.train()\n            losses = []\n            for img, tab, y in train_loader:\n                img, tab, y = img.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n                self.opt.zero_grad()\n                mean, log_sigma = self.model(img, tab)\n                loss = laplace_nll_with_floor(mean, log_sigma, y, sigma_floor=70.0)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n                self.opt.step()\n                losses.append(loss.item())\n            tr_loss = float(np.mean(losses)) if losses else 0.0\n\n            # Validation\n            with torch.no_grad():\n                val_loss_batches = []\n                for img, tab, y in val_loader:\n                    img, tab, y = img.to(DEVICE), tab.to(DEVICE), y.to(DEVICE)\n                    mean, log_sigma = self.model(img, tab)\n                    vloss = laplace_nll_with_floor(mean, log_sigma, y, sigma_floor=70.0)\n                    val_loss_batches.append(vloss.item())\n                val_loss = float(np.mean(val_loss_batches)) if val_loss_batches else 0.0\n\n                metrics = evaluate_loader(self.model, val_loader, DEVICE, sigma_floor=70.0)\n\n            self.sched.step(val_loss)\n            print(f\"Epoch {epoch:02d} | Train NLL: {tr_loss:.3f} | Val NLL: {val_loss:.3f} | \"\n                  f\"Val RMSE: {metrics['rmse']:.1f} | Val R²: {metrics['r2']:.3f} | Val LLL: {metrics['lll']:.3f}\")\n\n            if metrics[\"lll\"] > self.best_lll:\n                self.best_lll = metrics[\"lll\"]\n                torch.save(self.model.state_dict(), \"best_model.pth\")\n                print(\"  -> Saved new best (LLL).\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:09:54.168154Z","iopub.execute_input":"2025-09-05T07:09:54.169023Z","iopub.status.idle":"2025-09-05T07:10:01.127342Z","shell.execute_reply.started":"2025-09-05T07:09:54.168992Z","shell.execute_reply":"2025-09-05T07:10:01.126599Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\ntrain dataset: 1236 samples, 140 patients\nval dataset: 313 samples, 36 patients\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ---------------------------\n# Run training\n# ---------------------------\nmodel = FusionNet(tab_dim=9, pretrained=True)\ntrainer = Trainer(model, DEVICE, lr=1e-4)\ntrainer.fit(train_loader, val_loader, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:10:01.128542Z","iopub.execute_input":"2025-09-05T07:10:01.128891Z","iopub.status.idle":"2025-09-05T07:10:57.507657Z","shell.execute_reply.started":"2025-09-05T07:10:01.128871Z","shell.execute_reply":"2025-09-05T07:10:57.506703Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Train NLL: 57.405 | Val NLL: 11.168 | Val RMSE: 2446.6 | Val R²: -11.119 | Val LLL: -11.693\n  -> Saved new best (LLL).\nEpoch 02 | Train NLL: 10.494 | Val NLL: 9.890 | Val RMSE: 2451.3 | Val R²: -11.167 | Val LLL: -9.601\n  -> Saved new best (LLL).\nEpoch 03 | Train NLL: 9.976 | Val NLL: 9.728 | Val RMSE: 2457.4 | Val R²: -11.227 | Val LLL: -9.547\n  -> Saved new best (LLL).\nEpoch 04 | Train NLL: 9.836 | Val NLL: 9.761 | Val RMSE: 2458.6 | Val R²: -11.239 | Val LLL: -9.513\n  -> Saved new best (LLL).\nEpoch 05 | Train NLL: 9.767 | Val NLL: 9.582 | Val RMSE: 2460.6 | Val R²: -11.259 | Val LLL: -9.475\n  -> Saved new best (LLL).\nEpoch 06 | Train NLL: 9.747 | Val NLL: 9.598 | Val RMSE: 2460.8 | Val R²: -11.261 | Val LLL: -9.499\nEpoch 07 | Train NLL: 9.711 | Val NLL: 9.598 | Val RMSE: 2460.9 | Val R²: -11.262 | Val LLL: -9.528\nEpoch 08 | Train NLL: 9.708 | Val NLL: 9.573 | Val RMSE: 2460.1 | Val R²: -11.253 | Val LLL: -9.496\nEpoch 09 | Train NLL: 9.700 | Val NLL: 9.582 | Val RMSE: 2459.8 | Val R²: -11.251 | Val LLL: -9.469\n  -> Saved new best (LLL).\nEpoch 10 | Train NLL: 9.685 | Val NLL: 9.550 | Val RMSE: 2459.5 | Val R²: -11.248 | Val LLL: -9.602\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nTabular-only baseline training script for OSIC (Laplace NLL)\n- Predicts FVC per visit (direct target)\n- Outputs mean and log_scale (per-sample)\n- Uses GroupKFold (patient-wise split)\n- Fits scalers on training patients only\n- Provides baseline comparisons and sigma calibration\n\"\"\"\n\nimport os, math, random\nfrom pathlib import Path\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# --------------------------\n# Repro / device\n# --------------------------\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_everything(42)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# --------------------------\n# Paths & load CSV\n# --------------------------\nDATA_DIR = Path(\"/kaggle/input/osic-pulmonary-fibrosis-progression\")  # adapt path if needed\ntrain_csv = DATA_DIR / \"train.csv\"\ndf = pd.read_csv(train_csv)\nprint(\"Loaded rows:\", len(df))\n\n# --------------------------\n# Build patient-level baseline info and samples\n# --------------------------\npatients = df['Patient'].unique().tolist()\npatient_samples = defaultdict(list)\nbaseline_info = {}\n\nfor p in patients:\n    d = df[df['Patient'] == p].sort_values('Weeks').reset_index(drop=True)\n    baseline = d.iloc[0]\n    baseline_info[p] = {\n        'Age': float(baseline['Age']),\n        'Sex': baseline['Sex'],             # 'Male'/'Female'\n        'SmokingStatus': baseline['SmokingStatus'],\n        'BaselineFVC': float(baseline['FVC']),\n        'BaselineWeeks': int(baseline['Weeks']),\n        'Percent': float(baseline.get('Percent', 50.0))\n    }\n    for _, row in d.iterrows():\n        patient_samples[p].append({'Weeks': int(row['Weeks']), 'FVC': float(row['FVC'])})\n\n# --------------------------\n# Feature builder (explicit order)\n# --------------------------\ndef build_raw_features(pid, week):\n    b = baseline_info[pid]\n    week_delta = float(week - b['BaselineWeeks'])\n    # explicit ordering:\n    raw = [\n        b['Age'],\n        1.0 if b['Sex'] == 'Female' else 0.0,\n        1.0 if b['SmokingStatus'] == 'Never smoked' else 0.0,\n        1.0 if b['SmokingStatus'] == 'Ex-smoker' else 0.0,\n        1.0 if b['SmokingStatus'] == 'Currently smokes' else 0.0,\n        b['BaselineFVC'],\n        b['BaselineWeeks'],\n        b['Percent'],\n        week_delta\n    ]\n    return np.array(raw, dtype=np.float32)\n\n# --------------------------\n# Build dataset lists (samples)\n# --------------------------\nsamples = []  # (patient, week, fvc)\nfor p, recs in patient_samples.items():\n    for rec in recs:\n        samples.append((p, rec['Weeks'], rec['FVC']))\n\nprint(\"Total samples:\", len(samples))\n# Shuffle samples for robustness in DataLoader (split by patient later)\nrandom.shuffle(samples)\n\n# --------------------------\n# GroupKFold split on patients (train-val)\n# --------------------------\nunique_patients = list(baseline_info.keys())\ngkf = GroupKFold(n_splits=5)\ntrain_pid_idx, val_pid_idx = next(gkf.split(unique_patients, groups=unique_patients))\ntrain_pids = [unique_patients[i] for i in train_pid_idx]\nval_pids   = [unique_patients[i] for i in val_pid_idx]\nprint(\"Train patients:\", len(train_pids), \"Val patients:\", len(val_pids))\n\n# Build sample lists per split\ntrain_samples = [s for s in samples if s[0] in train_pids]\nval_samples   = [s for s in samples if s[0] in val_pids]\nprint(\"Train samples:\", len(train_samples), \"Val samples:\", len(val_samples))\n\n# --------------------------\n# Fit scalers on TRAIN patients only\n# --------------------------\nX_train_for_scaler = np.stack([build_raw_features(p, w) for p, w, _ in train_samples])\nscaler = StandardScaler().fit(X_train_for_scaler)\n\ndef make_features(pid, week):\n    x_raw = build_raw_features(pid, week).reshape(1, -1)\n    x_scaled = scaler.transform(x_raw).astype(np.float32).flatten()\n    return x_scaled\n\n# --------------------------\n# Dataset & DataLoader\n# --------------------------\nclass TabularDataset(Dataset):\n    def __init__(self, samples):\n        self.samples = samples\n    def __len__(self):\n        return len(self.samples)\n    def __getitem__(self, idx):\n        pid, week, fvc = self.samples[idx]\n        x = make_features(pid, week)\n        return torch.from_numpy(x), torch.tensor(fvc, dtype=torch.float32), pid\n\nBATCH = 64\ntrain_loader = DataLoader(TabularDataset(train_samples), batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)\nval_loader   = DataLoader(TabularDataset(val_samples), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n\n# --------------------------\n# Simple MLP model: predicts mean and log_scale (per-sample)\n# --------------------------\nclass TabularMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n        )\n        self.mean_head = nn.Linear(64, 1)\n        self.log_scale_head = nn.Linear(64, 1)\n        # Initialize log_scale bias so initial sigma is reasonable (e.g., ~300)\n        nn.init.constant_(self.log_scale_head.bias, math.log(300.0))\n    def forward(self, x):\n        h = self.net(x)\n        mean = self.mean_head(h).squeeze(-1)\n        log_scale = self.log_scale_head(h).squeeze(-1)\n        return mean, log_scale\n\nINPUT_DIM = X_train_for_scaler.shape[1]\nmodel = TabularMLP(INPUT_DIM).to(DEVICE)\nprint(\"Model params:\", sum(p.numel() for p in model.parameters()))\n\n# --------------------------\n# Laplace NLL loss & utilities\n# --------------------------\ndef laplace_nll_torch(mean, log_scale, target, sigma_floor=1e-6):\n    # We train on raw sigma (no competition floor). But we avoid sigma -> 0.\n    sigma = torch.exp(log_scale) + sigma_floor\n    # Laplace NLL: |e|/b + log(2b), where b = sigma\n    loss = (torch.abs(target - mean) / sigma) + torch.log(2.0 * sigma)\n    return loss.mean()\n\n@torch.no_grad()\ndef evaluate_model(model, loader, device, apply_competition_sigma_floor=True, sigma_floor_val=70.0):\n    model.eval()\n    preds = []\n    sigs = []\n    trues = []\n    pids = []\n    for x, y, pid in loader:\n        x = x.to(device)\n        y = y.to(device)\n        mean, log_scale = model(x)\n        mean_np = mean.detach().cpu().numpy()\n        sigma_np = np.exp(log_scale.detach().cpu().numpy())\n        if apply_competition_sigma_floor:\n            sigma_np = np.maximum(sigma_np, sigma_floor_val)\n        preds.append(mean_np)\n        sigs.append(sigma_np)\n        trues.append(y.detach().cpu().numpy())\n        pids.extend(pid)\n    preds = np.concatenate(preds)\n    sigs = np.concatenate(sigs)\n    trues = np.concatenate(trues)\n    # Metrics across full val set\n    rmse = float(np.sqrt(mean_squared_error(trues, preds)))\n    # r2 safe:\n    denom = np.sum((trues - trues.mean())**2)\n    r2 = float(1.0 - np.sum((trues - preds)**2) / (denom + 1e-12))\n    # Laplace LLL (per-sample), higher is better\n    lll = np.mean(-np.sqrt(2.0) * np.abs(trues - preds) / sigs - np.log(np.sqrt(2.0) * sigs))\n    return {'rmse': rmse, 'r2': r2, 'lll': float(lll)}\n\n# --------------------------\n# Baselines for sanity checks\n#  - baseline predict = baseline FVC at each visit\n#  - global mean\n# --------------------------\ndef baseline_metrics(samples):\n    # baseline predict baseline_FVC (per sample)\n    y_true = []\n    y_basepred = []\n    for pid, week, fvc in samples:\n        y_true.append(fvc)\n        y_basepred.append(baseline_info[pid]['BaselineFVC'])\n    y_true = np.array(y_true)\n    y_basepred = np.array(y_basepred)\n    rmse_base = float(np.sqrt(mean_squared_error(y_true, y_basepred)))\n    mean_pred = np.array([y_true.mean()] * len(y_true))\n    rmse_mean = float(np.sqrt(mean_squared_error(y_true, mean_pred)))\n    return {'rmse_baseline': rmse_base, 'rmse_global_mean': rmse_mean}\n\nprint(\"Baselines (val):\", baseline_metrics(val_samples))\n\n# --------------------------\n# Training loop\n# --------------------------\nopt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\nsched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3, verbose=True)\n\nEPOCHS = 20\nbest_lll = -1e18\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    losses = []\n    for x, y, pid in train_loader:\n        x = x.to(DEVICE)\n        y = y.to(DEVICE)\n        opt.zero_grad()\n        mean, log_scale = model(x)\n        loss = laplace_nll_torch(mean, log_scale, y)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        losses.append(loss.item())\n    train_loss = float(np.mean(losses)) if losses else 0.0\n\n    val_stats = evaluate_model(model, val_loader, DEVICE, apply_competition_sigma_floor=True, sigma_floor_val=70.0)\n    sched.step(val_stats['lll'] * -1.0)  # scheduler expects loss (we invert LLL)\n    print(f\"Epoch {epoch:02d} | Train NLL: {train_loss:.4f} | Val RMSE: {val_stats['rmse']:.2f} | Val R²: {val_stats['r2']:.4f} | Val LLL: {val_stats['lll']:.4f}\")\n\n    # Save best by LLL\n    if val_stats['lll'] > best_lll:\n        best_lll = val_stats['lll']\n        torch.save(model.state_dict(), \"tabular_best.pth\")\n        print(\"Saved best tabular model (LLL).\")\n\n# --------------------------\n# Load best and compute final metrics (including no-floor and with-floor)\n# --------------------------\nmodel.load_state_dict(torch.load(\"tabular_best.pth\"))\nm_no_floor = evaluate_model(model, val_loader, DEVICE, apply_competition_sigma_floor=False)\nm_with_floor = evaluate_model(model, val_loader, DEVICE, apply_competition_sigma_floor=True, sigma_floor_val=70.0)\nprint(\"Final metrics (no floor):\", m_no_floor)\nprint(\"Final metrics (with 70 floor):\", m_with_floor)\n\n# --------------------------\n# Sigma calibration (learn scalar multiplier on sigma to maximize LLL on val)\n# We fit alpha >= 0 such that sigma_cal = alpha * sigma_pred\n# Optimize alpha by simple grid search on validation set (cheap)\n# --------------------------\ndef calibrate_sigma_scalar(model, loader, device, grid=np.linspace(0.1, 10.0, 100)):\n    model.eval()\n    preds = []\n    sigs = []\n    trues = []\n    with torch.no_grad():\n        for x, y, pid in loader:\n            x = x.to(device)\n            y = y.to(device)\n            mean, log_scale = model(x)\n            preds.append(mean.cpu().numpy())\n            sigs.append(np.exp(log_scale.cpu().numpy()))\n            trues.append(y.cpu().numpy())\n    preds = np.concatenate(preds)\n    sigs = np.concatenate(sigs)\n    trues = np.concatenate(trues)\n\n    best_alpha = 1.0\n    best_lll = -1e18\n    for a in grid:\n        s_cal = np.maximum(sigs * a, 70.0)  # competition floor\n        lll = np.mean(-np.sqrt(2.0) * np.abs(trues - preds) / s_cal - np.log(np.sqrt(2.0) * s_cal))\n        if lll > best_lll:\n            best_lll = lll\n            best_alpha = a\n    return best_alpha, best_lll\n\nalpha, best_lll = calibrate_sigma_scalar(model, val_loader, DEVICE)\nprint(f\"Calibration alpha (sigma multiplier): {alpha:.4f}, calibrated LLL: {best_lll:.4f}\")\n\n# --------------------------\n# If tabular baseline works (i.e., RMSE << 2000 and ideally < ~400), proceed to add images.\n# --------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:18:17.179276Z","iopub.execute_input":"2025-09-05T07:18:17.179593Z","iopub.status.idle":"2025-09-05T07:18:24.725314Z","shell.execute_reply.started":"2025-09-05T07:18:17.179566Z","shell.execute_reply":"2025-09-05T07:18:24.724368Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nLoaded rows: 1549\nTotal samples: 1549\nTrain patients: 140 Val patients: 36\nTrain samples: 1236 Val samples: 313\nModel params: 9666\nBaselines (val): {'rmse_baseline': 253.36408156539483, 'rmse_global_mean': 702.7735537599037}\nEpoch 01 | Train NLL: 11.3629 | Val RMSE: 2507.11 | Val R²: -11.7267 | Val LLL: -9.6789\nSaved best tabular model (LLL).\nEpoch 02 | Train NLL: 9.7148 | Val RMSE: 2506.54 | Val R²: -11.7209 | Val LLL: -9.5526\nSaved best tabular model (LLL).\nEpoch 03 | Train NLL: 9.6349 | Val RMSE: 2505.86 | Val R²: -11.7140 | Val LLL: -9.5085\nSaved best tabular model (LLL).\nEpoch 04 | Train NLL: 9.6181 | Val RMSE: 2505.19 | Val R²: -11.7072 | Val LLL: -9.4847\nSaved best tabular model (LLL).\nEpoch 05 | Train NLL: 9.6135 | Val RMSE: 2504.65 | Val R²: -11.7017 | Val LLL: -9.4984\nEpoch 06 | Train NLL: 9.6054 | Val RMSE: 2504.11 | Val R²: -11.6963 | Val LLL: -9.5073\nEpoch 07 | Train NLL: 9.6068 | Val RMSE: 2503.49 | Val R²: -11.6900 | Val LLL: -9.4969\nEpoch 08 | Train NLL: 9.6033 | Val RMSE: 2502.92 | Val R²: -11.6842 | Val LLL: -9.4986\nEpoch 09 | Train NLL: 9.6010 | Val RMSE: 2502.67 | Val R²: -11.6817 | Val LLL: -9.5031\nEpoch 10 | Train NLL: 9.5961 | Val RMSE: 2502.32 | Val R²: -11.6782 | Val LLL: -9.4924\nEpoch 11 | Train NLL: 9.6023 | Val RMSE: 2502.04 | Val R²: -11.6753 | Val LLL: -9.4928\nEpoch 12 | Train NLL: 9.5987 | Val RMSE: 2501.81 | Val R²: -11.6730 | Val LLL: -9.5047\nEpoch 13 | Train NLL: 9.5926 | Val RMSE: 2501.63 | Val R²: -11.6711 | Val LLL: -9.4985\nEpoch 14 | Train NLL: 9.5960 | Val RMSE: 2501.46 | Val R²: -11.6694 | Val LLL: -9.4945\nEpoch 15 | Train NLL: 9.6031 | Val RMSE: 2501.30 | Val R²: -11.6678 | Val LLL: -9.4920\nEpoch 16 | Train NLL: 9.5937 | Val RMSE: 2501.17 | Val R²: -11.6665 | Val LLL: -9.4963\nEpoch 17 | Train NLL: 9.5959 | Val RMSE: 2501.11 | Val R²: -11.6659 | Val LLL: -9.4973\nEpoch 18 | Train NLL: 9.5985 | Val RMSE: 2501.04 | Val R²: -11.6651 | Val LLL: -9.4972\nEpoch 19 | Train NLL: 9.5943 | Val RMSE: 2501.00 | Val R²: -11.6647 | Val LLL: -9.5025\nEpoch 20 | Train NLL: 9.5940 | Val RMSE: 2500.90 | Val R²: -11.6638 | Val LLL: -9.4992\nFinal metrics (no floor): {'rmse': 2505.191650390625, 'r2': -11.707236877513523, 'lll': -9.48470401763916}\nFinal metrics (with 70 floor): {'rmse': 2505.191650390625, 'r2': -11.707236877513523, 'lll': -9.48470401763916}\nCalibration alpha (sigma multiplier): 1.2000, calibrated LLL: -9.4613\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fixed end-to-end tabular Laplace training script (no input_dim mismatch)\nimport os, math, random\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------- config -----------------\nSEED = 42\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDATA_DIR = Path(\"/kaggle/input/osic-pulmonary-fibrosis-progression\")\nTRAIN_CSV = DATA_DIR / \"train.csv\"\n\nBATCH_SIZE = 64\nEPOCHS = 10\nLR = 1e-3\nWEIGHT_DECAY = 1e-5\nSIGMA_REG = 1e-4\nSIGMA_FLOOR = 70.0\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# ----------------- load data -----------------\ndf = pd.read_csv(TRAIN_CSV)\nprint(f\"Loaded {len(df)} rows\")\n\n# ----------------- categorical encoding -----------------\n# Factorize to numeric if present\nfor col in [\"Sex\", \"SmokingStatus\"]:\n    if col in df.columns and df[col].dtype == \"object\":\n        df[col], _ = pd.factorize(df[col])\n\n# ----------------- baseline week per patient -----------------\npatient_baseline_week = df.groupby(\"Patient\")[\"Weeks\"].first().to_dict()\n\n# ----------------- engineered features -----------------\ndef make_row_features(row):\n    pid = row[\"Patient\"]\n    base_w = patient_baseline_week[pid]\n    rel_w = float(row[\"Weeks\"] - base_w)\n    percent = float(row[\"Percent\"]) if \"Percent\" in row and not pd.isna(row[\"Percent\"]) else 50.0\n    age = float(row[\"Age\"])\n    # engineered\n    return {\n        \"Age\": age,\n        \"Percent\": percent,\n        \"Sex\": float(row[\"Sex\"]),\n        \"SmokingStatus\": float(row[\"SmokingStatus\"]),\n        \"rel_week\": rel_w,\n        \"rel_week_sq\": rel_w ** 2,\n        \"rel_week_x_percent\": rel_w * percent,\n        \"age_x_percent\": age * percent,\n    }\n\neng_list = []\nfor _, r in df.iterrows():\n    eng_list.append(make_row_features(r))\neng_df = pd.DataFrame(eng_list)\ndf = pd.concat([df.reset_index(drop=True), eng_df.reset_index(drop=True)], axis=1)\n\n# Explicit feature column order (you can add/remove features here)\nfeature_cols = [\"Age\", \"Percent\", \"Sex\", \"SmokingStatus\",\n                \"rel_week\", \"rel_week_sq\", \"rel_week_x_percent\", \"age_x_percent\"]\n\nprint(\"Feature columns:\", feature_cols)\nprint(\"Feature count:\", len(feature_cols))\n\n# ----------------- train/val split by patient -----------------\npatients = df[\"Patient\"].unique().tolist()\ngkf = GroupKFold(n_splits=5)\ntrain_idx, val_idx = next(gkf.split(patients, groups=patients))\ntrain_pids = [patients[i] for i in train_idx]\nval_pids = [patients[i] for i in val_idx]\n\ntrain_df = df[df[\"Patient\"].isin(train_pids)].reset_index(drop=True)\nval_df = df[df[\"Patient\"].isin(val_pids)].reset_index(drop=True)\nprint(f\"Train rows: {len(train_df)}, Val rows: {len(val_df)}\")\n\n# ----------------- scalers fit on train only -----------------\nscaler_X = StandardScaler().fit(train_df[feature_cols].values.astype(np.float32))\ny_train = train_df[\"FVC\"].values.astype(np.float32)\ny_mean = y_train.mean()\ny_std = y_train.std() if y_train.std() > 0 else 1.0\n\n# ----------------- Dataset -----------------\nclass TabularDS(Dataset):\n    def __init__(self, df, feature_cols):\n        self.df = df.reset_index(drop=True)\n        self.feature_cols = feature_cols\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        x_raw = r[self.feature_cols].values.astype(np.float32)\n        x = scaler_X.transform(x_raw.reshape(1, -1)).astype(np.float32).flatten()\n        y = np.float32(r[\"FVC\"])\n        y_scaled = (y - y_mean) / y_std\n        return torch.from_numpy(x), torch.tensor(y_scaled, dtype=torch.float32)\n\ntrain_ds = TabularDS(train_df, feature_cols)\nval_ds = TabularDS(val_df, feature_cols)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# Print first batch shapes for a sanity check\nxb, yb = next(iter(train_loader))\nprint(\"First batch xb shape:\", xb.shape, \"yb shape:\", yb.shape)\n# xb.shape[1] is the actual input_dim from data\n\n# ----------------- Model (input_dim derived from data) -----------------\nclass ResidualBlock(nn.Module):\n    def __init__(self, dim, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(dim, dim)\n        self.fc2 = nn.Linear(dim, dim)\n        self.act = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.norm = nn.LayerNorm(dim)\n    def forward(self, x):\n        r = x\n        out = self.act(self.fc1(x))\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.norm(out + r)\n        return self.act(out)\n\nclass TabularLaplace(nn.Module):\n    def __init__(self, input_dim, hidden_dim=64, num_blocks=2):\n        super().__init__()\n        self.input = nn.Linear(input_dim, hidden_dim)\n        self.blocks = nn.ModuleList([ResidualBlock(hidden_dim) for _ in range(num_blocks)])\n        self.mean_head = nn.Linear(hidden_dim, 1)\n        self.log_s_head = nn.Linear(hidden_dim, 1)\n        nn.init.constant_(self.log_s_head.bias, math.log(1.0))\n    def forward(self, x):\n        h = torch.relu(self.input(x))\n        for b in self.blocks:\n            h = b(h)\n        mu = self.mean_head(h).squeeze(-1)\n        log_s = self.log_s_head(h).squeeze(-1)\n        return mu, log_s\n\n# initialize with true input_dim\ninput_dim = xb.shape[1]\nmodel = TabularLaplace(input_dim=input_dim, hidden_dim=64, num_blocks=2).to(DEVICE)\nprint(\"Initialized model with input_dim =\", input_dim, \" ; total params =\", sum(p.numel() for p in model.parameters()))\n\n# ----------------- loss with softplus sigma -----------------\nsoftplus = nn.Softplus()\ndef laplace_nll_scaled(mu_s, log_s, y_s, sigma_reg=1e-4):\n    b = softplus(log_s) + 1e-6         # positive scale (in scaled-space)\n    loss = torch.abs(y_s - mu_s) / b + torch.log(2.0 * b)\n    return loss.mean() + sigma_reg * (log_s ** 2).mean()\n\n# ----------------- evaluation helper (unscale, compute RMSE, R2, LLL) -----------------\ndef evaluate(model, loader, device=DEVICE, sigma_floor=SIGMA_FLOOR):\n    model.eval()\n    preds, sigs, trues = [], [], []\n    with torch.no_grad():\n        for xb, yb_s in loader:\n            xb = xb.to(device).float()\n            yb_s = yb_s.to(device).float()\n            mu_s, log_s = model(xb)\n            b_s = softplus(log_s) + 1e-6\n            # unscale\n            mu = (mu_s.cpu().numpy() * y_std) + y_mean\n            b = (b_s.cpu().numpy() * y_std)   # scale sigma to original units\n            y_true = (yb_s.cpu().numpy() * y_std) + y_mean\n            preds.append(mu)\n            sigs.append(b)\n            trues.append(y_true)\n    preds = np.concatenate(preds)\n    sigs = np.concatenate(sigs)\n    trues = np.concatenate(trues)\n    sigs_floor = np.maximum(sigs, sigma_floor)\n    rmse = float(np.sqrt(np.mean((trues - preds) ** 2)))\n    denom = np.sum((trues - trues.mean()) ** 2)\n    r2 = float(1.0 - np.sum((trues - preds) ** 2) / (denom + 1e-12)) if denom > 0 else 0.0\n    lll = float(np.mean(-math.sqrt(2.0) * np.abs(trues - preds) / sigs_floor - np.log(math.sqrt(2.0) * sigs_floor)))\n    return {\"rmse\": rmse, \"r2\": r2, \"lll\": lll, \"preds\": preds, \"sigs\": sigs, \"trues\": trues}\n\n# ----------------- optimizer / scheduler -----------------\nopt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nsched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=4, verbose=True)\n\n# ----------------- train loop -----------------\nbest_lll = -1e18\nfor epoch in range(1, EPOCHS + 1):\n    model.train()\n    losses = []\n    for step, (xb, yb_s) in enumerate(train_loader):\n        xb = xb.to(DEVICE).float()\n        yb_s = yb_s.to(DEVICE).float()\n        mu_s, log_s = model(xb)\n        loss = laplace_nll_scaled(mu_s, log_s, yb_s, sigma_reg=SIGMA_REG)\n        opt.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        losses.append(loss.item())\n        # debug print first batch shapes (only once)\n        if epoch == 1 and step == 0:\n            print(\"DEBUG shapes (batch0): xb\", xb.shape, \"mu_s\", mu_s.shape, \"log_s\", log_s.shape, \"yb_s\", yb_s.shape)\n\n    train_loss = float(np.mean(losses)) if losses else 0.0\n    val_stats = evaluate(model, val_loader, device=DEVICE, sigma_floor=SIGMA_FLOOR)\n    # scheduler steps on validation LLL (we want to maximize LLL -> use 'max' above)\n    sched.step(val_stats[\"lll\"])\n    print(f\"Epoch {epoch:02d} | TrainLoss: {train_loss:.6f} | Val RMSE: {val_stats['rmse']:.2f} | Val R2: {val_stats['r2']:.4f} | Val LLL: {val_stats['lll']:.4f}\")\n\n    if val_stats[\"lll\"] > best_lll:\n        best_lll = val_stats[\"lll\"]\n        torch.save(model.state_dict(), \"best_tabular_laplace_fixed.pt\")\n        print(\" -> saved best model (LLL)\")\n\n# ----------------- final calibrated LLL on val -----------------\nres = evaluate(model, val_loader, device=DEVICE, sigma_floor=0.0)  # raw sigmas\npreds, sigs, trues = res[\"preds\"], res[\"sigs\"], res[\"trues\"]\nsigs = np.maximum(sigs, 1e-6)\n\nbest_alpha, best_lll = 1.0, -1e18\nfor a in np.linspace(0.1, 5.0, 50):\n    s_cal = np.maximum(sigs * a, SIGMA_FLOOR)\n    lll = np.mean(-math.sqrt(2.0) * np.abs(trues - preds) / s_cal - np.log(math.sqrt(2.0) * s_cal))\n    if lll > best_lll:\n        best_lll = lll\n        best_alpha = a\n\nprint(\"Final val RMSE, R2, LLL (before calib):\", evaluate(model, val_loader, DEVICE, SIGMA_FLOOR))\nprint(f\"Sigma calibration -> alpha: {best_alpha:.3f}, calibrated LLL: {best_lll:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:28:41.553783Z","iopub.execute_input":"2025-09-05T07:28:41.554582Z","iopub.status.idle":"2025-09-05T07:28:49.813554Z","shell.execute_reply.started":"2025-09-05T07:28:41.554550Z","shell.execute_reply":"2025-09-05T07:28:49.812448Z"}},"outputs":[{"name":"stdout","text":"Loaded 1549 rows\nFeature columns: ['Age', 'Percent', 'Sex', 'SmokingStatus', 'rel_week', 'rel_week_sq', 'rel_week_x_percent', 'age_x_percent']\nFeature count: 8\nTrain rows: 1236, Val rows: 313\nFirst batch xb shape: torch.Size([64, 12]) yb shape: torch.Size([64])\nInitialized model with input_dim = 12  ; total params = 17858\nDEBUG shapes (batch0): xb torch.Size([64, 12]) mu_s torch.Size([64]) log_s torch.Size([64]) yb_s torch.Size([64])\nEpoch 01 | TrainLoss: 0.962912 | Val RMSE: 311.96 | Val R2: 0.8030 | Val LLL: -7.2297\n -> saved best model (LLL)\nEpoch 02 | TrainLoss: 0.548413 | Val RMSE: 302.91 | Val R2: 0.8142 | Val LLL: -7.2821\nEpoch 03 | TrainLoss: 0.438487 | Val RMSE: 272.39 | Val R2: 0.8498 | Val LLL: -7.1264\n -> saved best model (LLL)\nEpoch 04 | TrainLoss: 0.393646 | Val RMSE: 256.50 | Val R2: 0.8668 | Val LLL: -7.0930\n -> saved best model (LLL)\nEpoch 05 | TrainLoss: 0.355745 | Val RMSE: 249.76 | Val R2: 0.8737 | Val LLL: -7.0356\n -> saved best model (LLL)\nEpoch 06 | TrainLoss: 0.345564 | Val RMSE: 260.97 | Val R2: 0.8621 | Val LLL: -7.0364\nEpoch 07 | TrainLoss: 0.297739 | Val RMSE: 245.71 | Val R2: 0.8778 | Val LLL: -6.9852\n -> saved best model (LLL)\nEpoch 08 | TrainLoss: 0.266483 | Val RMSE: 247.88 | Val R2: 0.8756 | Val LLL: -7.0663\nEpoch 09 | TrainLoss: 0.252357 | Val RMSE: 239.10 | Val R2: 0.8842 | Val LLL: -7.0499\nEpoch 10 | TrainLoss: 0.252990 | Val RMSE: 241.42 | Val R2: 0.8820 | Val LLL: -6.9810\n -> saved best model (LLL)\nFinal val RMSE, R2, LLL (before calib): {'rmse': 241.41867065429688, 'r2': 0.8819921440618953, 'lll': -6.980981349945068, 'preds': array([3755.6343, 3585.2292, 3547.1978, 3113.4746, 3164.0498, 3252.4724,\n       3000.0273, 2494.2563, 2605.9229, 2058.1252, 2002.0704, 1949.1335,\n       1986.4869, 1924.9937, 2015.668 , 1866.7554, 1639.6798, 1488.4844,\n       2806.5212, 3005.5535, 3110.3994, 2917.5798, 3116.1736, 2897.1743,\n       2748.3816, 2685.2283, 2418.5713, 2810.6099, 2699.4983, 2742.6023,\n       2790.1008, 2822.2861, 2856.8386, 2499.8027, 2274.0122, 2351.1255,\n       1617.2405, 1573.3475, 1634.1715, 1609.6656, 1600.4308, 1579.4208,\n       1557.2196, 1444.1704, 1393.9817, 3447.9858, 3265.2122, 3401.5928,\n       3622.185 , 3327.7163, 3351.8135, 3162.3135, 3353.2039, 2376.226 ,\n       2647.3594, 2226.3613, 2419.4502, 2398.409 , 2502.5566, 2735.033 ,\n       2929.7432, 2770.3728, 2240.8257, 2293.3027, 2317.0518, 2252.088 ,\n       2070.9165, 1994.513 , 1866.8922, 1850.0011, 1762.1941, 2661.6165,\n       2603.6177, 2338.3164, 2451.5752, 2155.533 , 1863.4458, 2185.3086,\n       2358.0786, 2495.6504, 2364.9944, 2301.9814, 2271.4302, 2240.8423,\n       2048.2593, 1858.9758, 1725.5001, 1679.5835, 2716.414 , 2519.1614,\n       2492.6458, 2412.814 , 2348.609 , 2310.4539, 2152.2427, 2230.7202,\n       2183.979 , 1647.3527, 1695.3973, 1692.4553, 1689.2535, 1633.0336,\n       1592.623 , 1480.7222, 1407.0732, 1372.2797, 2395.159 , 2465.9326,\n       2578.9521, 2537.901 , 2460.511 , 2462.519 , 2276.7917, 2312.5425,\n       2311.487 , 4327.041 , 4304.025 , 4215.128 , 4217.355 , 4145.817 ,\n       4073.439 , 4158.926 , 4163.449 , 4046.284 , 2244.464 , 2241.4531,\n       2280.6826, 2248.5293, 2192.9097, 2244.4302, 2329.9531, 2108.7466,\n       2235.9377, 2599.674 , 2678.0068, 2702.951 , 2705.8625, 2754.2812,\n       2721.5051, 2694.037 , 2736.525 , 2599.5823, 2910.6943, 2659.5327,\n       2707.1292, 2685.774 , 2619.9043, 2461.378 , 2085.54  , 2447.698 ,\n       2460.6875, 2664.758 , 2741.0896, 2687.4673, 2439.1978, 2582.4941,\n       2586.2385, 2672.1885, 3156.6301, 3139.2458, 3204.4482, 3214.0576,\n       3152.647 , 3079.463 , 2963.4426, 3179.942 , 3093.9712, 2459.088 ,\n       2306.109 , 2449.9275, 2490.3503, 2492.2244, 2493.8518, 2158.018 ,\n       2213.0396, 2194.596 , 1939.6511, 2026.3282, 2212.2666, 1826.8639,\n       1767.5088, 1601.8843, 2251.3042, 1735.1936, 2202.8037, 1623.1101,\n       1618.3151, 1617.3363, 1635.46  , 1613.8583, 1609.7109, 1506.2892,\n       1468.9283, 1350.8633, 1466.8861, 1473.4741, 1507.1239, 1408.9662,\n       1368.5237, 1227.18  , 1197.9221, 1370.5035, 2961.8613, 2650.2773,\n       2582.4695, 2641.1687, 2762.8015, 2401.174 , 2477.6436, 2528.928 ,\n       2381.8503, 2499.1445, 2488.8865, 2342.1152, 2487.4878, 2328.7485,\n       2124.8232, 2529.2188, 2569.969 , 2733.9292, 2714.692 , 2777.807 ,\n       2216.8813, 2343.1687, 2549.4326, 2586.3   , 2107.279 , 2059.8157,\n       2032.7297, 2077.0503, 2030.033 , 1936.8628, 1708.7208, 1834.6187,\n       3415.5017, 3322.7488, 3306.1484, 3473.5225, 3571.3833, 3509.687 ,\n       3600.099 , 3448.5342, 3513.4946, 2305.188 , 2269.426 , 2338.2607,\n       2264.1743, 2222.215 , 2193.5708, 2046.6053, 1963.241 , 2180.97  ,\n       2663.4294, 2407.101 , 2437.232 , 2594.66  , 2325.5977, 2252.5723,\n       2422.5708, 2556.6543, 2585.0063, 2685.5564, 2605.4248, 2875.3328,\n       2696.8206, 2678.4492, 2592.0261, 2579.793 , 2379.9785, 4302.2666,\n       4339.7114, 4391.492 , 4374.701 , 4382.756 , 4326.1714, 4329.9624,\n       4406.198 , 4272.3   , 2078.168 , 1994.898 , 2067.8604, 2022.5342,\n       1950.4543, 1954.7913, 1907.3923, 1805.815 , 1856.8777, 1428.6793,\n       1400.9108, 1401.9976, 1345.4536, 1402.5784, 1374.6279, 1292.8706,\n       1217.2919, 1295.3577, 1844.8391, 1937.0952, 1961.9451, 1923.8671,\n       1872.8562, 1928.3615, 1871.4823, 1867.72  , 1852.8997, 2769.4849,\n       2766.6177, 2773.3276, 2635.8547, 2684.0027, 2707.0698, 2687.0361,\n       2547.0022], dtype=float32), 'sigs': array([298.97073 , 259.65674 , 258.07343 , 197.62575 , 207.36127 ,\n       237.23038 , 210.59816 , 172.13043 , 174.2669  , 161.89069 ,\n       158.88126 , 155.32771 , 156.18904 , 152.49664 , 149.81439 ,\n       146.49298 , 155.47574 , 173.48198 , 148.34363 , 186.01929 ,\n       213.20691 , 177.0218  , 226.15056 , 204.83911 , 182.55215 ,\n       169.61055 , 174.61324 , 168.08038 , 155.84033 , 163.23737 ,\n       172.66747 , 181.8519  , 205.61058 , 183.82295 , 171.37146 ,\n       184.47821 , 136.57828 , 138.69157 , 137.17873 , 137.48291 ,\n       137.64882 , 140.39699 , 158.63284 , 190.12465 , 198.42796 ,\n       259.9078  , 229.31631 , 261.00848 , 296.2461  , 259.1942  ,\n       273.51672 , 237.79056 , 222.0147  , 128.18048 , 155.38905 ,\n       126.49075 , 140.67268 , 144.15549 , 163.84966 , 209.59541 ,\n       229.29071 , 208.95932 , 147.70122 , 151.79024 , 154.3817  ,\n       149.23404 , 131.64496 , 124.85355 , 115.92632 , 122.01601 ,\n       146.12791 , 150.30057 , 147.72273 , 134.13333 , 141.56789 ,\n       128.88084 , 124.81408 , 147.27943 , 162.34152 , 171.4257  ,\n       174.07646 , 171.46185 , 169.43846 , 163.90186 , 137.33438 ,\n       127.73668 , 125.42913 , 141.43687 , 154.31944 , 148.21341 ,\n       147.9199  , 144.66533 , 142.507   , 146.308   , 157.34596 ,\n       153.47943 , 164.08461 , 142.13039 , 143.98778 , 144.39397 ,\n       144.41022 , 141.02948 , 141.47908 , 143.48502 , 148.9301  ,\n       174.75706 , 138.85078 , 141.78581 , 148.28467 , 145.86925 ,\n       141.33572 , 149.90977 , 163.46239 , 177.26462 , 183.30219 ,\n       328.14902 , 328.62857 , 322.40158 , 322.24048 , 313.9184  ,\n       310.5461  , 296.09976 , 308.50244 , 305.9474  , 128.76846 ,\n       128.84743 , 130.56055 , 130.30807 , 129.28853 , 134.06139 ,\n       152.1592  , 155.36713 , 156.70135 , 188.26694 , 209.92703 ,\n       220.99754 , 225.67154 , 233.6484  , 239.09068 , 249.74266 ,\n       228.82965 , 213.0564  , 182.63454 , 152.7759  , 162.03175 ,\n       161.44577 , 155.71297 , 148.14023 , 169.56593 , 138.46658 ,\n       139.1905  , 151.4075  , 156.86943 , 157.84355 , 145.9595  ,\n       177.77603 , 167.62192 , 173.98898 , 225.98763 , 226.68875 ,\n       244.42664 , 245.15158 , 238.14395 , 233.20895 , 243.3128  ,\n       250.56435 , 228.82288 , 141.69626 , 141.26462 , 148.52464 ,\n       153.23097 , 155.2741  , 167.04535 , 161.3375  , 174.09819 ,\n       182.58484 , 147.32657 , 149.56798 , 158.07414 , 133.07495 ,\n       127.69323 , 118.52436 , 166.8962  , 139.21251 , 171.19063 ,\n       154.29552 , 154.1031  , 154.94823 , 159.04373 , 157.35173 ,\n       165.19505 , 181.76128 , 200.92436 , 183.91594 , 148.51884 ,\n       149.05685 , 150.72105 , 148.98515 , 153.66487 , 156.83029 ,\n       160.96013 , 178.66736 , 224.48622 , 227.37192 , 226.60132 ,\n       228.3854  , 224.46263 , 228.50562 , 216.15715 , 168.4857  ,\n       149.79405 , 142.43394 , 141.19003 , 145.62617 , 130.24634 ,\n       144.02563 , 171.22702 , 224.5239  , 223.70923 , 219.07814 ,\n       217.95978 , 214.17891 , 207.57777 , 214.31625 , 191.70636 ,\n       190.01997 , 127.85554 , 126.668816, 126.51756 , 127.398964,\n       129.71059 , 129.63445 , 128.51378 , 153.79298 , 131.3664  ,\n       126.225525, 122.58584 , 123.73738 , 122.28125 , 112.467445,\n       106.37973 , 107.95571 , 139.03818 , 136.0706  , 133.11255 ,\n       132.76091 , 131.27954 , 129.40938 , 132.43555 , 144.02562 ,\n       150.46141 , 175.74397 , 223.67317 , 219.23398 , 222.09654 ,\n       222.11203 , 220.2281  , 222.07553 , 210.05637 , 191.84549 ,\n       187.92496 , 170.56557 , 165.31381 , 207.71014 , 191.98602 ,\n       193.38782 , 201.19543 , 220.62378 , 197.1658  , 251.86758 ,\n       255.32658 , 262.75705 , 254.73946 , 256.84915 , 242.48047 ,\n       250.34906 , 250.53261 , 226.75114 , 130.7348  , 131.02586 ,\n       129.25888 , 128.62534 , 127.49177 , 124.91241 , 123.51314 ,\n       129.7021  , 153.22993 , 148.79225 , 150.25108 , 151.12119 ,\n       152.43771 , 153.40161 , 157.46083 , 163.05544 , 162.84192 ,\n       173.79044 , 130.5521  , 129.42566 , 128.00937 , 127.56768 ,\n       126.42319 , 125.15578 , 120.57138 , 133.74677 , 149.57555 ,\n       217.50066 , 231.68845 , 234.21309 , 222.28209 , 231.58286 ,\n       245.72458 , 246.3624  , 222.76448 ], dtype=float32), 'trues': array([3523.    , 3373.    , 3327.    , 2993.    , 3030.    , 3103.    ,\n       2993.    , 2474.    , 2518.    , 2100.    , 2047.    , 2001.    ,\n       2054.    , 2002.    , 2116.    , 1946.    , 1808.    , 1778.    ,\n       2903.    , 3159.    , 3277.    , 3042.    , 3277.    , 3086.    ,\n       2880.    , 2811.    , 2533.    , 2728.    , 2603.    , 2634.    ,\n       2668.    , 2684.    , 2787.    , 2391.    , 2195.    , 2272.    ,\n       1697.    , 1569.    , 1776.    , 1718.    , 1682.    , 1624.    ,\n       1616.    , 1520.    , 1532.    , 3456.    , 3295.    , 3420.    ,\n       3608.    , 3363.    , 3410.    , 3256.    , 3230.    , 2298.    ,\n       2576.    , 2182.    , 2374.    , 2370.    , 2480.    , 2683.    ,\n       2914.    , 2853.    , 2478.    , 2539.    , 2571.    , 2511.    ,\n       2297.    , 2241.    , 2076.    , 2031.    , 1918.    , 2553.    ,\n       2510.    , 2294.    , 2400.    , 2133.    , 1651.    , 2196.    ,\n       2336.    , 2404.    , 1995.    , 1884.    , 1806.    , 1666.    ,\n       1316.    , 1085.    ,  938.    ,  919.0001, 2581.    , 2427.    ,\n       2404.    , 2335.    , 2279.    , 2254.    , 2146.    , 2155.    ,\n       2091.    , 1677.    , 1781.    , 1773.    , 1771.    , 1667.    ,\n       1643.    , 1584.    , 1533.    , 1551.    , 2582.    , 2614.    ,\n       2743.    , 2674.    , 2579.    , 2608.    , 2588.    , 2630.    ,\n       2594.    , 4510.    , 4443.    , 4339.    , 4324.    , 4247.    ,\n       4196.    , 4320.    , 4267.    , 4151.    , 2102.    , 2102.    ,\n       2172.    , 2136.    , 2067.    , 2161.    , 2296.    , 2129.    ,\n       2184.    , 2603.    , 2715.    , 2740.    , 2749.    , 2833.    ,\n       2830.    , 2772.    , 2801.    , 2623.    , 3096.    , 2781.    ,\n       2826.    , 2759.    , 2591.    , 2428.    , 2119.    , 2672.    ,\n       2683.    , 2868.    , 2949.    , 2907.    , 2686.    , 2832.    ,\n       2844.    , 2889.    , 2869.    , 2853.    , 2912.    , 2929.    ,\n       2886.    , 2867.    , 2829.    , 2874.    , 2791.    , 2644.    ,\n       2345.    , 2492.    , 2540.    , 2549.    , 2579.    , 2371.    ,\n       2384.    , 2316.    , 1909.    , 1977.    , 2095.    , 1841.    ,\n       1803.    , 1732.    , 2095.    , 1813.    , 1845.    , 1399.    ,\n       1365.    , 1349.    , 1373.    , 1331.    , 1344.    , 1313.    ,\n       1290.    , 1188.    , 1563.    , 1584.    , 1647.    , 1498.    ,\n       1487.    , 1317.    , 1315.    , 1607.    , 3107.    , 2879.    ,\n       2828.    , 2908.    , 3002.    , 2718.    , 2738.    , 2283.    ,\n       2175.    , 2315.    , 2300.    , 2103.    , 2314.    , 2135.    ,\n       1814.    , 2109.    , 2182.    , 2297.    , 2293.    , 2328.    ,\n       1741.    , 1992.    , 2141.    , 2126.    , 2375.    , 2305.    ,\n       2263.    , 2325.    , 2277.    , 2173.    , 1653.    , 1861.    ,\n       3135.    , 2986.    , 2965.    , 3177.    , 3272.    , 3135.    ,\n       3232.    , 3153.    , 3221.    , 2345.    , 2295.    , 2346.    ,\n       2276.    , 2242.    , 2253.    , 2160.    , 2000.    , 2222.    ,\n       2808.    , 2441.    , 2567.    , 2788.    , 2470.    , 2475.    ,\n       2627.    , 2694.    , 2690.    , 2421.    , 2335.    , 2581.    ,\n       2416.    , 2398.    , 2230.    , 2294.    , 2122.    , 4284.    ,\n       4316.    , 4386.    , 4319.    , 4320.    , 4157.    , 4186.    ,\n       4251.    , 4125.    , 2231.    , 2104.    , 2214.    , 2159.    ,\n       2040.    , 2058.    , 1996.    , 1830.    , 1808.    , 1560.    ,\n       1546.    , 1565.    , 1471.    , 1603.    , 1584.    , 1523.    ,\n       1412.    , 1547.    , 1556.    , 1788.    , 1843.    , 1772.    ,\n       1668.    , 1799.    , 1682.    , 1746.    , 1650.    , 1930.    ,\n       1936.    , 1955.    , 1848.    , 1897.    , 1946.    , 1862.    ,\n       1713.    ], dtype=float32)}\nSigma calibration -> alpha: 1.500, calibrated LLL: -6.888197\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full corrected script — fixes scaler / feature mismatch (no more 12 vs 8 bug)\n# Run as a single cell. Assumes /kaggle/input/osic-pulmonary-fibrosis-progression/train/ exists.\nimport os, time, math, random\nfrom pathlib import Path\nfrom glob import glob\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as T\nimport torchvision.models as models\nimport cv2\nimport pydicom\n\n# ---------- CONFIG ----------\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\nDATA_DIR = Path(\"/kaggle/input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTRAIN_CSV = DATA_DIR / \"train.csv\"\n\nEMBED_CACHE_DIR = Path(\"./cache_embeddings\")\nEMBED_CACHE_DIR.mkdir(exist_ok=True)\n\nBATCH_SIZE = 48\nEPOCHS = 12\nLR = 1e-3\nWEIGHT_DECAY = 1e-5\nSIGMA_REG = 1e-4\nSIGMA_FLOOR = 70.0\n\n# ---------- Helper: DICOM -> HU -> windowed image ----------\ndef load_dicom_hu(path):\n    d = pydicom.dcmread(str(path), force=True)\n    arr = d.pixel_array.astype(np.float32)\n    intercept = float(getattr(d, \"RescaleIntercept\", 0.0))\n    slope = float(getattr(d, \"RescaleSlope\", 1.0))\n    arr = arr * slope + intercept\n    return arr\n\ndef window_and_norm_uint8(img_hu, win_min=-1200, win_max=600, to_255=True):\n    img = np.clip(img_hu, win_min, win_max)\n    if to_255:\n        img = (img - win_min) / (win_max - win_min)\n        img = (img * 255.0).astype(np.uint8)\n    return img\n\ndef build_3slice_image(patient_dir, target_size=(224,224)):\n    files = sorted(glob(str(patient_dir / \"*.dcm\")))\n    if len(files) == 0:\n        return np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n    mid = len(files) // 2\n    idxs = [max(0, mid-1), mid, min(len(files)-1, mid+1)]\n    channels = []\n    for i in idxs:\n        try:\n            hu = load_dicom_hu(files[i])\n            w = window_and_norm_uint8(hu)\n            w = cv2.resize(w, target_size, interpolation=cv2.INTER_AREA)\n        except Exception:\n            w = np.zeros(target_size, dtype=np.uint8)\n        channels.append(w)\n    return np.stack(channels, axis=2)\n\n# ---------- Embedding extractor (caches per patient) ----------\ndef extract_and_cache_embeddings(patient_list, target_size=(224,224), force=False):\n    device = DEVICE\n    backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n    modules = list(backbone.children())[:-1]\n    backbone = nn.Sequential(*modules).to(device).eval()\n    transform = T.Compose([T.ToTensor(), T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])])\n    t0 = time.time()\n    for i, pid in enumerate(patient_list, 1):\n        cache_file = EMBED_CACHE_DIR / f\"{pid}.npy\"\n        if cache_file.exists() and not force:\n            continue\n        patient_dir = TRAIN_DIR / pid\n        if not patient_dir.exists():\n            np.save(cache_file, np.zeros(512, dtype=np.float32))\n            continue\n        img = build_3slice_image(patient_dir, target_size=target_size)\n        x = transform(img).unsqueeze(0).to(device)\n        with torch.no_grad():\n            feat = backbone(x)  # [1,512,1,1]\n            feat = feat.reshape(-1).cpu().numpy().astype(np.float32)\n        np.save(cache_file, feat)\n        if i % 20 == 0 or i==len(patient_list):\n            print(f\"Cached {i}/{len(patient_list)} embeddings — elapsed {time.time()-t0:.0f}s\")\n\n# ---------- Load CSV and create features (explicit) ----------\ndf = pd.read_csv(TRAIN_CSV)\nprint(\"Loaded rows:\", len(df))\n\n# Safe factorize\nfor c in [\"Sex\", \"SmokingStatus\"]:\n    if c in df.columns and df[c].dtype == \"object\":\n        df[c], _ = pd.factorize(df[c])\n\n# baseline week per patient\npatient_baseline_week = df.groupby(\"Patient\")[\"Weeks\"].first().to_dict()\n\n# Explicit engineered features (only these will be used)\ndef make_features(row):\n    pid = row[\"Patient\"]\n    base = patient_baseline_week[pid]\n    rel_week = float(row[\"Weeks\"] - base)\n    percent = float(row[\"Percent\"]) if not pd.isna(row[\"Percent\"]) else 50.0\n    age = float(row[\"Age\"])\n    return {\n        \"Age\": age,\n        \"Percent\": percent,\n        \"Sex\": float(row[\"Sex\"]),\n        \"SmokingStatus\": float(row[\"SmokingStatus\"]),\n        \"rel_week\": rel_week,\n        \"rel_week_sq\": rel_week**2,\n        \"rel_week_x_percent\": rel_week * percent,\n        \"age_x_percent\": age * percent\n    }\n\neng = [make_features(r) for _, r in df.iterrows()]\neng_df = pd.DataFrame(eng)\n# Replace any previously existing feature columns to avoid duplication/conflict:\nfor c in eng_df.columns:\n    if c in df.columns:\n        df.drop(columns=[c], inplace=True)\ndf = pd.concat([df.reset_index(drop=True), eng_df.reset_index(drop=True)], axis=1)\n\nfeature_cols = [\"Age\",\"Percent\",\"Sex\",\"SmokingStatus\",\"rel_week\",\"rel_week_sq\",\"rel_week_x_percent\",\"age_x_percent\"]\nprint(\"Using explicit feature_cols:\", feature_cols, \"count:\", len(feature_cols))\n\n# ---------- Patient-wise split ----------\npatients = df[\"Patient\"].unique().tolist()\ngkf = GroupKFold(n_splits=5)\ntrain_idx, val_idx = next(gkf.split(patients, groups=patients))\ntrain_pids = [patients[i] for i in train_idx]\nval_pids = [patients[i] for i in val_idx]\n\ntrain_df = df[df[\"Patient\"].isin(train_pids)].reset_index(drop=True)\nval_df = df[df[\"Patient\"].isin(val_pids)].reset_index(drop=True)\nprint(f\"Train rows: {len(train_df)}, Val rows: {len(val_df)}\")\n\n# ---------- IMPORTANT: Fit scaler only on feature_cols from train_df ----------\n# This is the crucial fix. We explicitly select columns in the same order as feature_cols.\nscaler_X = StandardScaler().fit(train_df[feature_cols].values.astype(np.float32))\nprint(\"Scaler fit: mean shape\", scaler_X.mean_.shape, \" expected features:\", len(feature_cols))\n\n# Defensive sanity: if shapes still mismatch, print columns and abort with clear message.\nif scaler_X.mean_.shape[0] != len(feature_cols):\n    print(\"Scaler mean shape mismatch — scaler was fit on different columns. Debug info:\")\n    print(\"scaler.mean_.shape[0] =\", scaler_X.mean_.shape[0])\n    print(\"len(feature_cols) =\", len(feature_cols))\n    print(\"feature_cols:\", feature_cols)\n    raise AssertionError(\"Scaler feature count mismatch. Recreate scaler explicitly on train_df[feature_cols].\")\n\ny_train = train_df[\"FVC\"].values.astype(np.float32)\ny_mean, y_std = float(y_train.mean()), float(y_train.std() if y_train.std()>0 else 1.0)\nprint(\"y_mean, y_std:\", y_mean, y_std)\n\n# ---------- Cache embeddings (train+val patients) ----------\nneeded_pids = list(set(train_df[\"Patient\"].unique().tolist() + val_df[\"Patient\"].unique().tolist()))\nprint(\"Caching embeddings for\", len(needed_pids), \"patients (one-time).\")\nextract_and_cache_embeddings(needed_pids, target_size=(224,224), force=False)\n\n# ---------- Fusion Dataset (guaranteed to use feature_cols and scaler_X) ----------\nclass FusionDataset(Dataset):\n    def __init__(self, df, feature_cols, embed_dir):\n        self.df = df.reset_index(drop=True)\n        self.feature_cols = feature_cols\n        self.embed_dir = Path(embed_dir)\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        pid = r[\"Patient\"]\n        emb_path = self.embed_dir / f\"{pid}.npy\"\n        emb = np.load(emb_path).astype(np.float32) if emb_path.exists() else np.zeros(512, dtype=np.float32)\n        x_raw = r[self.feature_cols].values.astype(np.float32)\n        x = scaler_X.transform(x_raw.reshape(1,-1)).astype(np.float32).flatten()\n        y = np.float32(r[\"FVC\"])\n        y_s = (y - y_mean) / y_std\n        return torch.from_numpy(emb), torch.from_numpy(x), torch.tensor(y_s, dtype=torch.float32)\n\ntrain_ds = FusionDataset(train_df, feature_cols, EMBED_CACHE_DIR)\nval_ds = FusionDataset(val_df, feature_cols, EMBED_CACHE_DIR)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# ---------- Debug: inspect one batch and derive dims ----------\nemb_sample, tab_sample, y_sample = next(iter(train_loader))\nprint(\"DEBUG sample shapes -> emb:\", emb_sample.shape, \"tab:\", tab_sample.shape, \"y:\", y_sample.shape)\ninferred_emb_dim = int(emb_sample.shape[1])\ninferred_tab_dim = int(tab_sample.shape[1])\nprint(\"Inferred emb_dim:\", inferred_emb_dim, \"inferred_tab_dim:\", inferred_tab_dim)\n# defensive check: tab dim must equal scaler feature count\nassert inferred_tab_dim == len(feature_cols), f\"Data tab dim ({inferred_tab_dim}) != len(feature_cols) ({len(feature_cols)})\"\n\n# ---------- Model (built using inferred_tab_dim) ----------\nclass FusionLaplaceModel(nn.Module):\n    def __init__(self, emb_dim, tab_dim, proj_dim=128, hidden_dim=128):\n        super().__init__()\n        self.img_proj = nn.Sequential(nn.Linear(emb_dim, proj_dim), nn.ReLU(), nn.Dropout(0.2))\n        self.tab_in = nn.Linear(tab_dim, proj_dim)\n        self.tab_blocks = nn.ModuleList([nn.Sequential(nn.Linear(proj_dim, proj_dim), nn.ReLU(), nn.Dropout(0.1)) for _ in range(2)])\n        fusion_in = proj_dim + proj_dim\n        self.fusion = nn.Sequential(nn.Linear(fusion_in, hidden_dim), nn.ReLU(), nn.Dropout(0.3), nn.Linear(hidden_dim, hidden_dim), nn.ReLU())\n        self.mean_head = nn.Linear(hidden_dim, 1)\n        self.log_s_head = nn.Linear(hidden_dim, 1)\n        nn.init.constant_(self.log_s_head.bias, math.log(1.0))\n    def forward(self, emb, tab):\n        i = self.img_proj(emb)\n        t = F.relu(self.tab_in(tab))\n        for b in self.tab_blocks:\n            t = b(t)\n        fuse = torch.cat([i, t], dim=1)\n        h = self.fusion(fuse)\n        mu = self.mean_head(h).squeeze(-1)\n        log_s = self.log_s_head(h).squeeze(-1)\n        return mu, log_s\n\nmodel = FusionLaplaceModel(emb_dim=inferred_emb_dim, tab_dim=inferred_tab_dim, proj_dim=128, hidden_dim=128).to(DEVICE)\nprint(\"Model params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n\n# ---------- Loss (Laplace NLL) & evaluation ----------\nsoftplus = nn.Softplus()\ndef laplace_nll_scaled(mu_s, log_s, y_s, sigma_reg=SIGMA_REG):\n    b = softplus(log_s) + 1e-6\n    loss = torch.abs(y_s - mu_s) / b + torch.log(2.0 * b)\n    return loss.mean() + sigma_reg * (log_s ** 2).mean()\n\ndef evaluate(model, loader, device=DEVICE, sigma_floor=SIGMA_FLOOR):\n    model.eval()\n    preds, sigs, trues = [], [], []\n    with torch.no_grad():\n        for emb, tab, y_s in loader:\n            emb = emb.to(device).float()\n            tab = tab.to(device).float()\n            y_s = y_s.to(device).float()\n            mu_s, log_s = model(emb, tab)\n            b_s = softplus(log_s) + 1e-6\n            mu = (mu_s.cpu().numpy() * y_std) + y_mean\n            b = (b_s.cpu().numpy() * y_std)\n            y_true = (y_s.cpu().numpy() * y_std) + y_mean\n            preds.append(mu); sigs.append(b); trues.append(y_true)\n    preds = np.concatenate(preds); sigs = np.concatenate(sigs); trues = np.concatenate(trues)\n    sigs_floor = np.maximum(sigs, sigma_floor)\n    rmse = float(np.sqrt(np.mean((trues - preds)**2)))\n    denom = np.sum((trues - trues.mean())**2)\n    r2 = float(1.0 - np.sum((trues - preds)**2)/(denom + 1e-12)) if denom > 0 else 0.0\n    lll = float(np.mean(-math.sqrt(2.0)*np.abs(trues-preds)/sigs_floor - np.log(math.sqrt(2.0)*sigs_floor)))\n    return {\"rmse\": rmse, \"r2\": r2, \"lll\": lll, \"preds\": preds, \"sigs\": sigs, \"trues\": trues}\n\n# ---------- Optimizer & scheduler ----------\nopt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\nsched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=3, verbose=True)\n\n# ---------- Training loop with defensive assert ----------\nbest_lll = -1e18\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    losses = []\n    t0 = time.time()\n    for step, (emb, tab, y_s) in enumerate(train_loader):\n        emb = emb.to(DEVICE).float()\n        tab = tab.to(DEVICE).float()\n        y_s = y_s.to(DEVICE).float()\n\n        # Defensive assert to catch any future mismatch\n        assert tab.shape[1] == model.tab_in.in_features, f\"Tab dim mismatch: data {tab.shape[1]} vs model {model.tab_in.in_features}\"\n\n        mu_s, log_s = model(emb, tab)\n        loss = laplace_nll_scaled(mu_s, log_s, y_s)\n        opt.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        losses.append(loss.item())\n\n        if epoch == 1 and step == 0:\n            print(\"DEBUG batch shapes: emb\", emb.shape, \"tab\", tab.shape, \"mu_s\", mu_s.shape, \"log_s\", log_s.shape, \"y_s\", y_s.shape)\n\n    train_loss = float(np.mean(losses)) if len(losses)>0 else 0.0\n    val_stats = evaluate(model, val_loader, device=DEVICE)\n    sched.step(val_stats[\"lll\"])\n    print(f\"Epoch {epoch:02d} | TrainLoss: {train_loss:.6f} | Val RMSE: {val_stats['rmse']:.2f} | Val R2: {val_stats['r2']:.4f} | Val LLL: {val_stats['lll']:.4f} | time: {time.time()-t0:.1f}s\")\n\n    if val_stats[\"lll\"] > best_lll:\n        best_lll = val_stats[\"lll\"]\n        torch.save(model.state_dict(), \"best_fusion_laplace_fixedscaler.pt\")\n        print(\" -> saved best fusion model (LLL)\")\n\n# ---------- Sigma calibration on val ----------\nres = evaluate(model, val_loader, device=DEVICE, sigma_floor=0.0)\npreds, sigs, trues = res[\"preds\"], res[\"sigs\"], res[\"trues\"]\nsigs = np.maximum(sigs, 1e-6)\nbest_alpha, best_lll = 1.0, -1e18\nfor a in np.linspace(0.5, 3.0, 40):\n    s_cal = np.maximum(sigs * a, SIGMA_FLOOR)\n    lll = np.mean(-math.sqrt(2.0)*np.abs(trues-preds)/s_cal - np.log(math.sqrt(2.0)*s_cal))\n    if lll > best_lll:\n        best_lll = lll; best_alpha = a\nprint(f\"Calibrated alpha: {best_alpha:.3f}, calibrated LLL: {best_lll:.6f}\")\nfinal = evaluate(model, val_loader, device=DEVICE, sigma_floor=SIGMA_FLOOR)\nprint(\"FINAL VAL (with floor):\", {k: final[k] for k in ('rmse','r2','lll')})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T07:37:59.348717Z","iopub.execute_input":"2025-09-05T07:37:59.349570Z","iopub.status.idle":"2025-09-05T07:38:11.704141Z","shell.execute_reply.started":"2025-09-05T07:37:59.349541Z","shell.execute_reply":"2025-09-05T07:38:11.703242Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nLoaded rows: 1549\nUsing explicit feature_cols: ['Age', 'Percent', 'Sex', 'SmokingStatus', 'rel_week', 'rel_week_sq', 'rel_week_x_percent', 'age_x_percent'] count: 8\nTrain rows: 1236, Val rows: 313\nScaler fit: mean shape (8,)  expected features: 8\ny_mean, y_std: 2762.177978515625 847.3816528320312\nCaching embeddings for 176 patients (one-time).\nDEBUG sample shapes -> emb: torch.Size([48, 512]) tab: torch.Size([48, 8]) y: torch.Size([48])\nInferred emb_dim: 512 inferred_tab_dim: 8\nModel params: 149506\nDEBUG batch shapes: emb torch.Size([48, 512]) tab torch.Size([48, 8]) mu_s torch.Size([48]) log_s torch.Size([48]) y_s torch.Size([48])\nEpoch 01 | TrainLoss: 1.302679 | Val RMSE: 416.34 | Val R2: 0.6490 | Val LLL: -7.5568 | time: 0.9s\n -> saved best fusion model (LLL)\nEpoch 02 | TrainLoss: 0.745968 | Val RMSE: 313.53 | Val R2: 0.8010 | Val LLL: -7.1697 | time: 0.9s\n -> saved best fusion model (LLL)\nEpoch 03 | TrainLoss: 0.510242 | Val RMSE: 257.10 | Val R2: 0.8662 | Val LLL: -7.0535 | time: 0.9s\n -> saved best fusion model (LLL)\nEpoch 04 | TrainLoss: 0.386363 | Val RMSE: 373.39 | Val R2: 0.7177 | Val LLL: -7.5952 | time: 1.0s\nEpoch 05 | TrainLoss: 0.319909 | Val RMSE: 279.56 | Val R2: 0.8418 | Val LLL: -7.0502 | time: 0.9s\n -> saved best fusion model (LLL)\nEpoch 06 | TrainLoss: 0.240995 | Val RMSE: 332.77 | Val R2: 0.7758 | Val LLL: -7.5006 | time: 0.9s\nEpoch 07 | TrainLoss: 0.162230 | Val RMSE: 349.17 | Val R2: 0.7531 | Val LLL: -7.5457 | time: 0.9s\nEpoch 08 | TrainLoss: 0.140883 | Val RMSE: 287.06 | Val R2: 0.8332 | Val LLL: -7.4281 | time: 0.9s\nEpoch 09 | TrainLoss: 0.021967 | Val RMSE: 310.22 | Val R2: 0.8051 | Val LLL: -7.3138 | time: 1.0s\nEpoch 10 | TrainLoss: -0.090617 | Val RMSE: 298.65 | Val R2: 0.8194 | Val LLL: -7.8149 | time: 0.9s\nEpoch 11 | TrainLoss: -0.097168 | Val RMSE: 328.57 | Val R2: 0.7814 | Val LLL: -7.9716 | time: 0.9s\nEpoch 12 | TrainLoss: -0.170807 | Val RMSE: 319.82 | Val R2: 0.7929 | Val LLL: -7.8707 | time: 0.9s\nCalibrated alpha: 2.487, calibrated LLL: -7.279007\nFINAL VAL (with floor): {'rmse': 319.82421875, 'r2': 0.7928943618413916, 'lll': -7.870704650878906}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
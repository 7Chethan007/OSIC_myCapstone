{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Progresive Training","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Full code with minimal changes to SimpleTrainer to use LLL (Laplace Log Likelihood) and MAE as main metrics\n# and modify early stopping to consider both metrics.\n# All other parts including image processing and data loading remain unchanged.\n\nimport os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport random\nfrom tqdm import tqdm \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nimport json\nfrom pathlib import Path\nimport warnings\nimport pickle\n\n# Albumentations for medical augmentations\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed=42):\n    \"\"\"Ensure reproducibility across all random operations\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(42)\n\n# Configuration\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"ğŸš€ DenseNet V2 - Enhanced Medical Imaging Model\")\nprint(\"=\" * 60)\nprint(f\"ğŸ“± Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"ğŸ”¥ GPU: {torch.cuda.get_device_name()}\")\n    print(f\"ğŸ’¾ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nprint(\"=\" * 60)\n\ndef quick_recovery():\n    \"\"\"Quick recovery of auto-saved data after kernel restart\"\"\"\n    global train_df, A, TAB, P, train_patients, val_patients\n    \n    print(\"ğŸ”„ QUICK RECOVERY MODE\")\n    print(\"=\" * 40)\n    \n    # Check Kaggle vs local environment\n    if os.path.exists('/kaggle/working/auto_save_data'):\n        auto_save_dir = \"/kaggle/working/auto_save_data\"\n        print(\"ğŸ° Using Kaggle persistent auto-save data\")\n    elif os.path.exists('auto_save_data'):\n        auto_save_dir = \"auto_save_data\"\n        print(\"ğŸ  Using local auto-save data\")\n    else:\n        print(\"âŒ No auto-saved data found. Run full notebook first.\")\n        return False\n    \n    try:\n        # Load core data\n        print(\"ğŸ“Š Loading core data...\")\n        train_df = pd.read_csv(f\"{auto_save_dir}/train_df_backup.csv\")\n        \n        with open(f\"{auto_save_dir}/decay_coefficients_A_backup.pkl\", 'rb') as f:\n            A = pickle.load(f)\n        \n        with open(f\"{auto_save_dir}/tabular_features_TAB_backup.pkl\", 'rb') as f:\n            TAB = pickle.load(f)\n        \n        with open(f\"{auto_save_dir}/patient_list_P_backup.pkl\", 'rb') as f:\n            P = pickle.load(f)\n\n        print(f\"âœ… Loaded: train_df ({train_df.shape}), A ({len(A)}), TAB ({len(TAB)}), P ({len(P)})\")\n\n        # Load splits if available\n        if os.path.exists(f\"{auto_save_dir}/train_patients_backup.pkl\"):\n            print(\"ğŸ”„ Loading train/val splits...\")\n            \n            with open(f\"{auto_save_dir}/train_patients_backup.pkl\", 'rb') as f:\n                train_patients = pickle.load(f)\n            \n            with open(f\"{auto_save_dir}/val_patients_backup.pkl\", 'rb') as f:\n                val_patients = pickle.load(f)\n\n            print(f\"âœ… Loaded: train_patients ({len(train_patients)}), val_patients ({len(val_patients)})\")\n\n        # Show metadata\n        if os.path.exists(f\"{auto_save_dir}/processing_metadata.json\"):\n            with open(f\"{auto_save_dir}/processing_metadata.json\", 'r') as f:\n                metadata = json.load(f)\n            print(f\"ğŸ“… Data from: {metadata.get('processing_timestamp', 'Unknown')}\")\n\n        # Load model if available\n        if os.path.exists(f\"{auto_save_dir}/model_weights_backup.pth\"):\n            print(\"ğŸ—ï¸ Loading model...\")\n            try:\n                global model\n                model = WorkingDenseNetModel(tabular_dim=4).to(DEVICE)\n                model.load_state_dict(torch.load(f\"{auto_save_dir}/model_weights_backup.pth\", map_location=DEVICE))\n                print(\"âœ… Model weights loaded\")\n            except:\n                print(\"âš ï¸ Model loading failed (need to run model definition cells first)\")\n\n        # Show training results if available\n        if os.path.exists(f\"{auto_save_dir}/training_results_backup.json\"):\n            with open(f\"{auto_save_dir}/training_results_backup.json\", 'r') as f:\n                results = json.load(f)\n            print(f\"ğŸ“ˆ Previous training: MAE = {results.get('best_val_mae', 'N/A')}\")\n\n        print(\"ğŸ‰ Quick recovery complete! Core variables restored.\")\n        print(\"ğŸ’¡ Tip: If model loading failed, run model definition cells first, then call quick_recovery() again\")\n        return True\n    \n    except Exception as e:\n        print(f\"âŒ Recovery failed: {e}\")\n        return False\n\nprint(\"âœ… Quick recovery system ready!\")\nprint(\"ğŸ’¡ Usage after kernel restart:\")\nprint(\" quick_recovery() # Restore all auto-saved data\")\n# quick_recovery()\n\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\nprint(f\"Loaded dataset with shape: {train_df.shape}\")\n\ndef get_tab_features(df_row):\n    \"\"\"Extract tabular features (returns 4 features)\"\"\"\n    vector = [(df_row['Age'] - 30) / 30] \n    \n    # Sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(0)\n    else:\n        vector.append(1)\n    \n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([1, 1])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 1])\n    else:\n        vector.extend([1, 0])\n    return np.array(vector)\n\nA = {} \nTAB = {} \nP = []\n\nprint(\"Calculating linear decay coefficients...\")\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy()\n    fvc = sub['FVC'].values\n    weeks = sub['Weeks'].values\n    \n    if len(weeks) > 1:\n        c = np.vstack([weeks, np.ones(len(weeks))]).T\n        try:\n            a, b = np.linalg.lstsq(c, fvc, rcond=None)[0]\n            A[patient] = a\n            TAB[patient] = get_tab_features(sub.iloc[0])\n            P.append(patient)\n        except:\n            A[patient] = (fvc[-1] - fvc[0]) / (weeks[-1] - weeks[0]) if len(weeks) > 1 else 0.0\n            TAB[patient] = get_tab_features(sub.iloc[0])\n            P.append(patient)\n    else:\n        A[patient] = 0.0\n        TAB[patient] = get_tab_features(sub.iloc[0])\n        P.append(patient)\n\nprint(f\"Processed {len(P)} patients with decay coefficients\")\n\nprint(\"ğŸ’¾ Auto-saving critical data...\")\nif os.path.exists('/kaggle/working'):\n    auto_save_dir = \"/kaggle/working/auto_save_data\"\n    print(\"ğŸ° Using Kaggle persistent storage\")\nelse:\n    auto_save_dir = \"auto_save_data\"\n    print(\"ğŸ  Using local storage\")\n\nos.makedirs(auto_save_dir, exist_ok=True)\n\ntry:\n    train_df.to_csv(f\"{auto_save_dir}/train_df_backup.csv\", index=False)\n    \n    with open(f\"{auto_save_dir}/decay_coefficients_A_backup.pkl\", 'wb') as f:\n        pickle.dump(A, f)\n    \n    with open(f\"{auto_save_dir}/tabular_features_TAB_backup.pkl\", 'wb') as f:\n        pickle.dump(TAB, f)\n    \n    with open(f\"{auto_save_dir}/patient_list_P_backup.pkl\", 'wb') as f:\n        pickle.dump(P, f)\n    \n    metadata = {\n        'processed_patients': len(P),\n        'total_decay_coefficients': len(A),\n        'tabular_features_dim': len(list(TAB.values())[0]) if TAB else 0,\n        'processing_timestamp': str(pd.Timestamp.now())\n    }\n    \n    with open(f\"{auto_save_dir}/processing_metadata.json\", 'w') as f:\n        json.dump(metadata, f, indent=2)\n    \n    print(f\"âœ… Auto-saved to {auto_save_dir}/\")\n    print(\" - train_df_backup.csv\")\n    print(\" - decay_coefficients_A_backup.pkl\") \n    print(\" - tabular_features_TAB_backup.pkl\")\n    print(\" - patient_list_P_backup.pkl\")\n    print(\" - processing_metadata.json\")\nexcept Exception as e:\n    print(f\"âš ï¸ Auto-save failed: {e}\")\n\nclass MedicalAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                albu.Rotate(limit=15, p=0.7),\n                albu.HorizontalFlip(p=0.5),\n                albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),\n                albu.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n                albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n                albu.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n                albu.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n\n    def __call__(self, image):\n        return self.transform(image=image)['image']\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_cat = torch.cat([avg_out, max_out], dim=1)\n        x_cat = self.conv1(x_cat)\n        return x * self.sigmoid(x_cat)\n\nclass OSICDenseNetDataset(Dataset):\n    def __init__(self, patients, A_dict, TAB_dict, data_dir, split='train', augment=True):\n        self.patients = [p for p in patients if p not in ['ID00011637202177653955184', 'ID00052637202186188008618']]\n        self.A_dict = A_dict\n        self.TAB_dict = TAB_dict\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augment = augment\n        self.augmentor = MedicalAugmentation(augment=augment)\n        self.patient_images = {}\n        for patient in self.patients:\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = [f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm']\n                if image_files:\n                    self.patient_images[patient] = image_files\n        self.valid_patients = [p for p in self.patients if p in self.patient_images]\n        print(f\"Dataset {split}: {len(self.valid_patients)} patients with images\")\n    def __len__(self):\n        if self.split == 'train':\n            return len(self.valid_patients) * 6\n        else:\n            return len(self.valid_patients)\n    def __getitem__(self, idx):\n        if self.split == 'train':\n            patient_idx = idx % len(self.valid_patients)\n        else:\n            patient_idx = idx\n        patient = self.valid_patients[patient_idx]\n        available_images = self.patient_images[patient]\n        if len(available_images) > 1:\n            selected_image = np.random.choice(available_images)\n        else:\n            selected_image = available_images[0]\n        img = self.load_and_preprocess_dicom(selected_image)\n        img_tensor = self.augmentor(img)\n        tab_features = torch.tensor(self.TAB_dict[patient], dtype=torch.float32)\n        target = torch.tensor(self.A_dict[patient], dtype=torch.float32)\n        return img_tensor, tab_features, target, patient\n    def load_and_preprocess_dicom(self, path):\n        try:\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]\n            img = cv2.resize(img, (512, 512))\n            \n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            return img\n        except Exception as e:\n            print(f\"Error loading DICOM {path}: {e}\")\n            return np.zeros((512, 512, 3), dtype=np.uint8)\n\nclass WorkingDenseNetModel(nn.Module):\n    def __init__(self, tabular_dim=4, dropout_rate=0.4):\n        super(WorkingDenseNetModel, self).__init__()\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        self.spatial_attention = SpatialAttention()\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=1024, num_heads=8, dropout=0.2, batch_first=True\n        )\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 512, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(768, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2)\n        )\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        img_features = self.features(images)\n        img_features = self.spatial_attention(img_features)\n        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n        img_features = img_features.view(batch_size, -1)\n        tab_features = self.tabular_processor(tabular)\n        img_expanded = img_features.unsqueeze(1)\n        tab_expanded = tab_features.unsqueeze(1)\n        tab_proj = F.linear(tab_expanded, torch.randn(1024, 512).to(images.device))\n        attended_img, _ = self.cross_attention(img_expanded, tab_proj, tab_proj)\n        attended_img = attended_img.squeeze(1)\n        combined_features = torch.cat([attended_img, tab_features], dim=1)\n        fused_features = self.fusion_layer(combined_features)\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        return mean_pred.squeeze(), log_var.squeeze()\n\nprint(\"âœ… CORRECTED Working model defined!\")\n\nprint(\"ğŸ”„ Creating data loaders...\")\n\npatients_list = list(P)\ntrain_patients, val_patients = train_test_split(\n    patients_list,\n    test_size=0.2,\n    random_state=42,\n    shuffle=True\n)\n\nprint(f\"Train patients: {len(train_patients)}\")\nprint(f\"Validation patients: {len(val_patients)}\")\n\ntrain_dataset = OSICDenseNetDataset(\n    patients=train_patients,\n    A_dict=A,\n    TAB_dict=TAB,\n    data_dir=TRAIN_DIR,\n    split='train',\n    augment=True\n)\n\nval_dataset = OSICDenseNetDataset(\n    patients=val_patients,\n    A_dict=A,\n    TAB_dict=TAB,\n    data_dir=TRAIN_DIR,\n    split='val',\n    augment=False\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True,\n    drop_last=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=8,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True,\n    drop_last=False\n)\n\nprint(f\"âœ… Data loaders created!\")\nprint(f\" Train batches: {len(train_loader)}\")\nprint(f\" Val batches: {len(val_loader)}\")\n\n# ----------------- LAPLACE LOG LIKELIHOOD METRIC FUNCTION ---------------- #\ndef laplace_log_likelihood_metric(pred_mean, pred_log_var, targets):\n    \"\"\"\n    pred_mean: np.ndarray or torch.tensor\n    pred_log_var: np.ndarray or torch.tensor\n    targets: np.ndarray or torch.tensor\n    returns: LLL (higher better, so often you report minus LLL as loss)\n    \"\"\"\n    if isinstance(pred_mean, torch.Tensor):\n        pred_mean = pred_mean.detach().cpu().numpy()\n    if isinstance(pred_log_var, torch.Tensor):\n        pred_log_var = pred_log_var.detach().cpu().numpy()\n    if isinstance(targets, torch.Tensor):\n        targets = targets.detach().cpu().numpy()\n    \n    sigma = np.sqrt(np.exp(pred_log_var))\n    sigma = np.clip(sigma, a_min=1e-3, a_max=1000)  # Stabilize\n    delta = np.abs(pred_mean - targets)\n    score = -np.log(2 * sigma) - delta / sigma\n    lll = np.mean(score)\n    return lll\n# ------------------------------------------------------------------------- #\n\nclass SimpleTrainer:\n    def __init__(self, model, device, lr=1e-4):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.best_val_mae = float('inf')\n        self.best_val_lll = -float('inf')  # LLL: higher better\n    \n    def uncertainty_loss(self, mean_pred, log_var, targets, reduction='mean'):\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        loss = 0.5 * (mse_loss / var + log_var)\n        if reduction == 'mean':\n            return loss.mean()\n        return loss.sum()\n    \n    def train(self, train_loader, val_loader, epochs=30, patience=8):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=4, verbose=True\n        )\n        patience_counter = 0\n        lambda_lll = 0.8  # Weight for combining LLL loss and MAE loss\n\n        for epoch in range(epochs):\n            self.model.train()\n            train_loss = 0.0\n            train_mae = 0.0\n            train_batches = 0\n            train_lll_scores = []  # Laplace Log Likelihood\n            \n            for batch_idx, (images, tabular, targets, _) in enumerate(train_loader):\n                try:\n                    images = images.to(self.device)\n                    tabular = tabular.to(self.device) \n                    targets = targets.to(self.device)\n                    optimizer.zero_grad()\n                    mean_pred, log_var = self.model(images, tabular)\n                    loss_lll = self.uncertainty_loss(mean_pred, log_var, targets)\n                    loss_mae = F.l1_loss(mean_pred, targets)\n                    # Combined loss: weighted sum\n                    loss = lambda_lll * loss_lll + (1 - lambda_lll) * loss_mae\n                    mae = loss_mae\n                    lll = laplace_log_likelihood_metric(mean_pred, log_var, targets)\n                    train_lll_scores.append(lll)\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                    optimizer.step()\n                    train_loss += loss.item()\n                    train_mae += mae.item()\n                    train_batches += 1\n                except Exception as e:\n                    print(f\"Error in training batch {batch_idx}: {e}\")\n                    continue\n            \n            self.model.eval()\n            val_loss = 0.0\n            val_mae = 0.0\n            val_predictions = []\n            val_targets = []\n            val_pred_log_vars = []\n            val_lll_scores = []  # Laplace Log Likelihood\n            \n            with torch.no_grad():\n                for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                    try:\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        mean_pred, log_var = self.model(images, tabular)\n                        loss_lll = self.uncertainty_loss(mean_pred, log_var, targets)\n                        loss_mae = F.l1_loss(mean_pred, targets)\n                        loss = lambda_lll * loss_lll + (1 - lambda_lll) * loss_mae\n                        mae = loss_mae\n                        val_loss += loss.item()\n                        val_mae += mae.item()\n                        val_predictions.extend(mean_pred.cpu().numpy())\n                        val_targets.extend(targets.cpu().numpy())\n                        val_pred_log_vars.extend(log_var.cpu().numpy())\n                        lll = laplace_log_likelihood_metric(mean_pred, log_var, targets)\n                        val_lll_scores.append(lll)\n                    except Exception as e:\n                        print(f\"Error in validation batch {batch_idx}: {e}\")\n                        continue\n            \n            if train_batches > 0 and len(val_predictions) > 0:\n                avg_train_loss = train_loss / train_batches\n                avg_train_mae = train_mae / train_batches\n                avg_val_loss = val_loss / len(val_loader)\n                avg_val_mae = val_mae / len(val_loader)\n                \n                val_predictions = np.array(val_predictions)\n                val_targets = np.array(val_targets)\n                val_pred_log_vars = np.array(val_pred_log_vars)\n                \n                val_rmse = np.sqrt(np.mean((val_predictions - val_targets) ** 2))\n                ss_res = np.sum((val_targets - val_predictions) ** 2)\n                ss_tot = np.sum((val_targets - np.mean(val_targets)) ** 2)\n                r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else -float('inf')\n                \n                avg_train_lll = np.mean(train_lll_scores) if len(train_lll_scores) > 0 else 0.\n                avg_val_lll = np.mean(val_lll_scores) if len(val_lll_scores) > 0 else 0.\n                overall_val_lll = laplace_log_likelihood_metric(val_predictions, val_pred_log_vars, val_targets)\n\n                print(f\"Epoch {epoch+1}/{epochs}\")\n                print(f\"Train Loss: {avg_train_loss:.6f}, MAE: {avg_train_mae:.6f}, LLL: {avg_train_lll:.6f}\")\n                print(f\"Val Loss: {avg_val_loss:.6f}, MAE: {avg_val_mae:.6f}, RMSE: {val_rmse:.6f}, RÂ²: {r2:.6f}, LLL: {avg_val_lll:.6f}, Overall LLL: {overall_val_lll:.6f}\")\n                \n                scheduler.step(avg_val_mae)  # Scheduler monitors MAE\n                \n                # Early stopping logic: seek to maximize LLL and minimize MAE\n                if avg_val_lll > self.best_val_lll or avg_val_mae < self.best_val_mae:\n                    self.best_val_lll = max(self.best_val_lll, avg_val_lll)\n                    self.best_val_mae = min(self.best_val_mae, avg_val_mae)\n                    torch.save(self.model.state_dict(), 'best_working_model.pth')\n                    print(\"âœ… New best model saved!\")\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n                    if patience_counter >= patience:\n                        print(f\"Early stopping at epoch {epoch+1}\")\n                        break\n            else:\n                print(f\"No valid training or validation batches in epoch {epoch+1}\")\n            print(\"-\" * 60)\n        return self.best_val_mae, self.best_val_lll\n\nprint(\"âœ… Simple trainer defined!\")\n\nprint(\"ğŸ”„ Replacing with CORRECTED working model...\")\n\nif 'model' in globals():\n    del model\ntorch.cuda.empty_cache()\n\nmodel = WorkingDenseNetModel(tabular_dim=4).to(DEVICE)\nprint(f\"âœ… Corrected model initialized!\")\nprint(f\"ğŸ“Š Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\ntry:\n    if 'train_loader' in globals():\n        test_batch = next(iter(train_loader))\n        images, tabular, targets, _ = test_batch\n        images = images.to(DEVICE)\n        tabular = tabular.to(DEVICE)\n        print(f\"ğŸ” Input shapes:\")\n        print(f\" Images: {images.shape}\")\n        print(f\" Tabular: {tabular.shape}\")\n        with torch.no_grad():\n            mean_pred, log_var = model(images, tabular)\n        print(f\"âœ… Model forward pass successful!\")\n        print(f\" Mean prediction: {mean_pred.shape} - {mean_pred[:3]}\")\n        print(f\" Log variance: {log_var.shape} - {log_var[:3]}\")\n    else:\n        print(\"âš ï¸ Data loaders not found, creating dummy test...\")\n        dummy_images = torch.randn(2, 3, 512, 512).to(DEVICE)\n        dummy_tabular = torch.randn(2, 4).to(DEVICE)\n        with torch.no_grad():\n            mean_pred, log_var = model(dummy_images, dummy_tabular)\n        print(f\"âœ… Model forward pass successful with dummy data!\")\n        print(f\" Mean prediction: {mean_pred.shape} - {mean_pred}\")\n        print(f\" Log variance: {log_var.shape} - {log_var}\")\nexcept Exception as e:\n    print(f\"âŒ Model test failed: {e}\")\n    import traceback\n    traceback.print_exc()\n\nif 'model' in globals():\n    print(\"ğŸš€ Starting training with CORRECTED model...\")\n    trainer = SimpleTrainer(model, DEVICE, lr=1e-4)\n    best_val_mae, best_val_lll = trainer.train(\n        train_loader, \n        val_loader, \n        epochs=30,\n        patience=8\n    )\n    print(f\"ğŸ¯ Training completed! Best validation MAE: {best_val_mae:.6f}, Best LLL: {best_val_lll:.6f}\")\nelse:\n    print(\"âŒ No model found. Run previous cells first!... \")\n\nprint(\"Starting Progressive Training...\")\nbest_val_mae, best_val_lll = trainer.train(\n    train_loader,\n    val_loader,\n    epochs=40,\n    patience=10\n)\n\nprint(f\"ğŸ¯ Progressive training completed! Best validation MAE: {best_val_mae:.6f}, Best LLL: {best_val_lll:.6f}\")\n\n# End of code\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T13:05:40.988806Z","iopub.execute_input":"2025-09-11T13:05:40.989489Z","iopub.status.idle":"2025-09-11T13:23:51.636517Z","shell.execute_reply.started":"2025-09-11T13:05:40.989455Z","shell.execute_reply":"2025-09-11T13:23:51.635741Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ DenseNet V2 - Enhanced Medical Imaging Model\n============================================================\nğŸ“± Device: cuda\nğŸ”¥ GPU: Tesla P100-PCIE-16GB\nğŸ’¾ Memory: 17.1 GB\n============================================================\nâœ… Quick recovery system ready!\nğŸ’¡ Usage after kernel restart:\n quick_recovery() # Restore all auto-saved data\nLoaded dataset with shape: (1549, 7)\nCalculating linear decay coefficients...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 882.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processed 176 patients with decay coefficients\nğŸ’¾ Auto-saving critical data...\nğŸ° Using Kaggle persistent storage\nâœ… Auto-saved to /kaggle/working/auto_save_data/\n - train_df_backup.csv\n - decay_coefficients_A_backup.pkl\n - tabular_features_TAB_backup.pkl\n - patient_list_P_backup.pkl\n - processing_metadata.json\nâœ… CORRECTED Working model defined!\nğŸ”„ Creating data loaders...\nTrain patients: 140\nValidation patients: 36\nDataset train: 138 patients with images\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n","output_type":"stream"},{"name":"stdout","text":"Dataset val: 36 patients with images\nâœ… Data loaders created!\n Train batches: 103\n Val batches: 5\nâœ… Simple trainer defined!\nğŸ”„ Replacing with CORRECTED working model...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:00<00:00, 173MB/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Corrected model initialized!\nğŸ“Š Total parameters: 12,756,452\nğŸ” Input shapes:\n Images: torch.Size([8, 3, 512, 512])\n Tabular: torch.Size([8, 4])\nâœ… Model forward pass successful!\n Mean prediction: torch.Size([8]) - tensor([-0.4609, -0.1809, -0.1003], device='cuda:0')\n Log variance: torch.Size([8]) - tensor([ 0.1176,  0.0216, -0.1518], device='cuda:0')\nğŸš€ Starting training with CORRECTED model...\nEpoch 1/30\nTrain Loss: 11.720372, MAE: 4.886730, LLL: -4.667458\nVal Loss: 11.632891, MAE: 5.662280, RMSE: 8.113307, RÂ²: -0.272742, LLL: -4.719950, Overall LLL: -4.741514\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 2/30\nTrain Loss: 3.670003, MAE: 4.200726, LLL: -3.278303\nVal Loss: 4.631873, MAE: 5.250366, RMSE: 7.581581, RÂ²: -0.111384, LLL: -3.606204, Overall LLL: -3.623816\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 3/30\nTrain Loss: 2.811165, MAE: 4.089293, LLL: -3.136902\nVal Loss: 3.578562, MAE: 5.113443, RMSE: 7.310371, RÂ²: -0.033293, LLL: -3.393303, Overall LLL: -3.407330\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 4/30\nTrain Loss: 2.789967, MAE: 4.133752, LLL: -3.167213\nVal Loss: 3.850561, MAE: 5.093476, RMSE: 7.340396, RÂ²: -0.041798, LLL: -3.449057, Overall LLL: -3.463299\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 5/30\nTrain Loss: 2.758746, MAE: 4.074633, LLL: -3.142245\nVal Loss: 3.804840, MAE: 5.105674, RMSE: 7.296790, RÂ²: -0.029457, LLL: -3.447818, Overall LLL: -3.473289\n------------------------------------------------------------\nEpoch 6/30\nTrain Loss: 2.691123, MAE: 4.121870, LLL: -3.138733\nVal Loss: 3.705452, MAE: 5.068682, RMSE: 7.323870, RÂ²: -0.037112, LLL: -3.434351, Overall LLL: -3.442131\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 7/30\nTrain Loss: 2.736303, MAE: 4.121887, LLL: -3.153198\nVal Loss: 3.616619, MAE: 5.006845, RMSE: 7.259947, RÂ²: -0.019087, LLL: -3.399589, Overall LLL: -3.426088\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 8/30\nTrain Loss: 2.688394, MAE: 4.091364, LLL: -3.124999\nVal Loss: 3.794079, MAE: 5.076406, RMSE: 7.310421, RÂ²: -0.033307, LLL: -3.439689, Overall LLL: -3.469164\n------------------------------------------------------------\nEpoch 9/30\nTrain Loss: 2.718247, MAE: 4.107216, LLL: -3.132915\nVal Loss: 3.967995, MAE: 4.974473, RMSE: 7.288879, RÂ²: -0.027226, LLL: -3.458815, Overall LLL: -3.500601\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 10/30\nTrain Loss: 2.777355, MAE: 4.144591, LLL: -3.147666\nVal Loss: 3.353830, MAE: 5.034963, RMSE: 7.222319, RÂ²: -0.008551, LLL: -3.382691, Overall LLL: -3.399906\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 11/30\nTrain Loss: 2.717500, MAE: 4.123138, LLL: -3.144186\nVal Loss: 3.564308, MAE: 5.124585, RMSE: 7.335138, RÂ²: -0.040306, LLL: -3.420961, Overall LLL: -3.441072\n------------------------------------------------------------\nEpoch 12/30\nTrain Loss: 2.771893, MAE: 4.071207, LLL: -3.149706\nVal Loss: 3.842133, MAE: 5.072951, RMSE: 7.382215, RÂ²: -0.053703, LLL: -3.454414, Overall LLL: -3.491446\n------------------------------------------------------------\nEpoch 13/30\nTrain Loss: 2.689360, MAE: 4.078254, LLL: -3.126582\nVal Loss: 3.490563, MAE: 5.044339, RMSE: 7.244454, RÂ²: -0.014742, LLL: -3.389121, Overall LLL: -3.414269\n------------------------------------------------------------\nEpoch 14/30\nTrain Loss: 2.704543, MAE: 4.121224, LLL: -3.145928\nVal Loss: 3.567369, MAE: 4.994461, RMSE: 7.259727, RÂ²: -0.019026, LLL: -3.377339, Overall LLL: -3.401828\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 15/30\nTrain Loss: 2.680772, MAE: 4.094739, LLL: -3.132417\nVal Loss: 3.626571, MAE: 5.002199, RMSE: 7.187457, RÂ²: 0.001162, LLL: -3.433647, Overall LLL: -3.458966\n------------------------------------------------------------\nEpoch 16/30\nTrain Loss: 2.677984, MAE: 4.108301, LLL: -3.131248\nVal Loss: 3.807809, MAE: 5.066829, RMSE: 7.349594, RÂ²: -0.044411, LLL: -3.474480, Overall LLL: -3.497809\n------------------------------------------------------------\nEpoch 17/30\nTrain Loss: 2.696761, MAE: 4.106269, LLL: -3.136030\nVal Loss: 3.637385, MAE: 4.866977, RMSE: 7.176010, RÂ²: 0.004341, LLL: -3.396713, Overall LLL: -3.429236\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 18/30\nTrain Loss: 2.677689, MAE: 4.051654, LLL: -3.123532\nVal Loss: 3.526988, MAE: 4.974935, RMSE: 7.213381, RÂ²: -0.006056, LLL: -3.389323, Overall LLL: -3.414691\n------------------------------------------------------------\nEpoch 19/30\nTrain Loss: 2.671503, MAE: 4.053498, LLL: -3.124521\nVal Loss: 3.606856, MAE: 4.913061, RMSE: 7.220304, RÂ²: -0.007988, LLL: -3.413786, Overall LLL: -3.438111\n------------------------------------------------------------\nEpoch 20/30\nTrain Loss: 2.687553, MAE: 4.026619, LLL: -3.131040\nVal Loss: 3.467380, MAE: 5.079621, RMSE: 7.207890, RÂ²: -0.004525, LLL: -3.415561, Overall LLL: -3.448375\n------------------------------------------------------------\nEpoch 21/30\nTrain Loss: 2.720067, MAE: 4.090618, LLL: -3.135903\nVal Loss: 3.541761, MAE: 4.965732, RMSE: 7.160069, RÂ²: 0.008760, LLL: -3.393555, Overall LLL: -3.422522\n------------------------------------------------------------\nEpoch 22/30\nTrain Loss: 2.710842, MAE: 4.098293, LLL: -3.142285\nVal Loss: 3.456697, MAE: 5.016832, RMSE: 7.246879, RÂ²: -0.015422, LLL: -3.378350, Overall LLL: -3.406474\n------------------------------------------------------------\nEpoch 23/30\nTrain Loss: 2.650417, MAE: 4.087587, LLL: -3.117823\nVal Loss: 3.898277, MAE: 5.036914, RMSE: 7.432329, RÂ²: -0.068057, LLL: -3.484908, Overall LLL: -3.514095\n------------------------------------------------------------\nEpoch 24/30\nTrain Loss: 2.665273, MAE: 4.089118, LLL: -3.118933\nVal Loss: 3.319076, MAE: 4.969343, RMSE: 7.241549, RÂ²: -0.013929, LLL: -3.343076, Overall LLL: -3.362091\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 25/30\nTrain Loss: 2.667788, MAE: 4.061756, LLL: -3.115011\nVal Loss: 3.230975, MAE: 4.922203, RMSE: 7.184546, RÂ²: 0.001971, LLL: -3.316762, Overall LLL: -3.336474\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 26/30\nTrain Loss: 2.685931, MAE: 4.071019, LLL: -3.129825\nVal Loss: 3.304164, MAE: 4.876525, RMSE: 7.105223, RÂ²: 0.023887, LLL: -3.329173, Overall LLL: -3.344675\n------------------------------------------------------------\nEpoch 27/30\nTrain Loss: 2.691866, MAE: 4.050380, LLL: -3.127997\nVal Loss: 3.526491, MAE: 4.959106, RMSE: 7.248523, RÂ²: -0.015883, LLL: -3.390771, Overall LLL: -3.421872\n------------------------------------------------------------\nEpoch 28/30\nTrain Loss: 2.676413, MAE: 4.063073, LLL: -3.126696\nVal Loss: 3.686469, MAE: 5.058459, RMSE: 7.308206, RÂ²: -0.032681, LLL: -3.435446, Overall LLL: -3.460868\n------------------------------------------------------------\nEpoch 29/30\nTrain Loss: 2.690608, MAE: 4.077709, LLL: -3.131446\nVal Loss: 3.448386, MAE: 4.865866, RMSE: 7.125553, RÂ²: 0.018293, LLL: -3.353459, Overall LLL: -3.381423\nâœ… New best model saved!\n------------------------------------------------------------\nEpoch 30/30\nTrain Loss: 2.695909, MAE: 4.109946, LLL: -3.135805\nVal Loss: 3.418016, MAE: 4.969521, RMSE: 7.201202, RÂ²: -0.002662, LLL: -3.354207, Overall LLL: -3.381176\n------------------------------------------------------------\nğŸ¯ Training completed! Best validation MAE: 4.865866, Best LLL: -3.316762\nStarting Progressive Training...\nEpoch 1/40\nTrain Loss: 2.676896, MAE: 4.079504, LLL: -3.112119\nVal Loss: 3.280741, MAE: 4.948672, RMSE: 7.213331, RÂ²: -0.006043, LLL: -3.318265, Overall LLL: -3.337628\n------------------------------------------------------------\nEpoch 2/40\nTrain Loss: 2.681138, MAE: 4.070204, LLL: -3.119639\nVal Loss: 3.321316, MAE: 5.004475, RMSE: 7.277590, RÂ²: -0.024047, LLL: -3.337272, Overall LLL: -3.361445\n------------------------------------------------------------\nEpoch 3/40\nTrain Loss: 2.736418, MAE: 4.065202, LLL: -3.148180\nVal Loss: 3.484186, MAE: 5.044527, RMSE: 7.333703, RÂ²: -0.039899, LLL: -3.384225, Overall LLL: -3.410347\n------------------------------------------------------------\nEpoch 4/40\nTrain Loss: 2.702959, MAE: 4.072622, LLL: -3.131229\nVal Loss: 3.616062, MAE: 5.098881, RMSE: 7.336270, RÂ²: -0.040627, LLL: -3.423347, Overall LLL: -3.452116\n------------------------------------------------------------\nEpoch 5/40\nTrain Loss: 2.680953, MAE: 4.071324, LLL: -3.132517\nVal Loss: 3.534253, MAE: 5.047879, RMSE: 7.249538, RÂ²: -0.016168, LLL: -3.404673, Overall LLL: -3.422128\n------------------------------------------------------------\nEpoch 6/40\nTrain Loss: 2.667642, MAE: 4.077461, LLL: -3.132876\nVal Loss: 3.648826, MAE: 4.960419, RMSE: 7.158116, RÂ²: 0.009300, LLL: -3.413279, Overall LLL: -3.451586\n------------------------------------------------------------\nEpoch 7/40\nTrain Loss: 2.692882, MAE: 4.067294, LLL: -3.125720\nVal Loss: 3.335602, MAE: 4.971414, RMSE: 7.241951, RÂ²: -0.014041, LLL: -3.344729, Overall LLL: -3.373439\n------------------------------------------------------------\nEpoch 8/40\nTrain Loss: 2.672323, MAE: 4.040477, LLL: -3.117837\nVal Loss: 3.422325, MAE: 4.904139, RMSE: 7.210070, RÂ²: -0.005133, LLL: -3.344264, Overall LLL: -3.368331\n------------------------------------------------------------\nEpoch 9/40\nTrain Loss: 2.651414, MAE: 4.057028, LLL: -3.113090\nVal Loss: 3.543179, MAE: 4.992683, RMSE: 7.146336, RÂ²: 0.012558, LLL: -3.378647, Overall LLL: -3.404885\n------------------------------------------------------------\nEpoch 10/40\nTrain Loss: 2.689550, MAE: 4.073867, LLL: -3.126510\nVal Loss: 3.589962, MAE: 4.987863, RMSE: 7.208759, RÂ²: -0.004768, LLL: -3.376498, Overall LLL: -3.404958\nEarly stopping at epoch 10\nğŸ¯ Progressive training completed! Best validation MAE: 4.865866, Best LLL: -3.316762\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print(\"hi now 15\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
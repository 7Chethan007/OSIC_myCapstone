{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 10th Oct","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport random\nfrom tqdm import tqdm \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom PIL import Image\nimport json\nfrom pathlib import Path\nimport joblib\nimport warnings\nimport pickle\nfrom typing import Dict, List, Tuple, Optional\nfrom scipy import ndimage\nfrom scipy.ndimage import binary_fill_holes, generate_binary_structure\nfrom skimage import measure, morphology\nfrom skimage.transform import resize\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed=42):\n    \"\"\"Ensure reproducibility across all random operations\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    \nseed_everything(42)\n\n# Configuration\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\n\n# GPU Configuration for P100\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Enable optimizations for GPU training\nif torch.cuda.is_available():\n    torch.backends.cudnn.benchmark = True  # Auto-tune for best performance on P100\n    torch.cuda.empty_cache()  # Clear cache before starting\n\nprint(\"üöÄ Fixed OSIC Model - Complete Working Version\")\nprint(\"=\" * 60)\nprint(f\"üì± Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"üî• GPU: {torch.cuda.get_device_name()}\")\n    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    print(f\"‚ö° CUDA Version: {torch.version.cuda}\")\n    print(f\"üöÄ cuDNN Benchmark: Enabled (P100 optimized)\")\nprint(\"=\" * 60)\n\n# Load Data\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\nprint(f\"Loaded dataset with shape: {train_df.shape}\")\n\ndef get_tab_features(df_row):\n    \"\"\"Extract tabular features (returns 4 features)\"\"\"\n    vector = [(df_row['Age'] - 30) / 30] \n    \n    # Sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(0)\n    else:\n        vector.append(1)\n    \n    # Smoking status encoding\n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([1, 1])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 1])\n    else:\n        vector.extend([1, 0])\n    return np.array(vector)\n\n# Calculate linear decay coefficients for each patient\nA = {} \nTAB = {} \nP = [] \n\nprint(\"Calculating linear decay coefficients...\")\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy()\n    fvc = sub['FVC'].values\n    weeks = sub['Weeks'].values\n    \n    if len(weeks) > 1:\n        c = np.vstack([weeks, np.ones(len(weeks))]).T\n        try:\n            a, b = np.linalg.lstsq(c, fvc, rcond=None)[0]\n            A[patient] = a\n            TAB[patient] = get_tab_features(sub.iloc[0])\n            P.append(patient)\n        except:\n            A[patient] = (fvc[-1] - fvc[0]) / (weeks[-1] - weeks[0]) if len(weeks) > 1 else 0.0\n            TAB[patient] = get_tab_features(sub.iloc[0])\n            P.append(patient)\n    else:\n        A[patient] = 0.0\n        TAB[patient] = get_tab_features(sub.iloc[0])\n        P.append(patient)\n\nprint(f\"Processed {len(P)} patients with decay coefficients\")\n\nclass MedicalAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                albu.Rotate(limit=15, p=0.7),\n                albu.HorizontalFlip(p=0.5),\n                albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),\n                albu.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n                albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n                albu.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n                albu.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n    \n    def __call__(self, image):\n        return self.transform(image=image)['image']\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_cat = torch.cat([avg_out, max_out], dim=1)\n        x_cat = self.conv1(x_cat)\n        return x * self.sigmoid(x_cat)\n\nclass WorkingDenseNetModel(nn.Module):\n    \"\"\"\n    Working model with proper dimension matching\n    \"\"\"\n    \n    def __init__(self, tabular_dim=4, dropout_rate=0.4):\n        super(WorkingDenseNetModel, self).__init__()\n        \n        # DenseNet121 backbone\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        \n        # Spatial attention\n        self.spatial_attention = SpatialAttention()\n        \n        # Enhanced tabular processing\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        \n        # Cross-modal attention\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=1024, num_heads=8, dropout=0.2, batch_first=True\n        )\n        \n        # Initialize projection weight properly\n        self.tab_projection = nn.Linear(512, 1024)\n        \n        # Multi-modal fusion\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 512, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(768, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2)\n        )\n        \n        # Uncertainty quantification heads\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        \n        # Extract image features\n        img_features = self.features(images)\n        \n        # Apply spatial attention\n        img_features = self.spatial_attention(img_features)\n        \n        # Global average pooling\n        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n        img_features = img_features.view(batch_size, -1)\n        \n        # Process tabular data\n        tab_features = self.tabular_processor(tabular)\n        \n        # Cross-modal attention\n        img_expanded = img_features.unsqueeze(1)\n        tab_expanded = tab_features.unsqueeze(1)\n        \n        # Project tabular to same dimension for attention\n        tab_proj = self.tab_projection(tab_expanded)\n        \n        attended_img, _ = self.cross_attention(\n            img_expanded, tab_proj, tab_proj\n        )\n        attended_img = attended_img.squeeze(1)\n        \n        # Fusion\n        combined_features = torch.cat([attended_img, tab_features], dim=1)\n        fused_features = self.fusion_layer(combined_features)\n        \n        # Predict mean and log variance\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        \n        return mean_pred.squeeze(), log_var.squeeze()\n\nclass OSICDenseNetDataset(Dataset):\n    \"\"\"Enhanced dataset with medical augmentations and robust loading\"\"\"\n    \n    def __init__(self, patients, A_dict, TAB_dict, data_dir, split='train', augment=True):\n        # Filter out problematic patients\n        self.patients = [p for p in patients if p not in ['ID00011637202177653955184', 'ID00052637202186188008618']]\n        self.A_dict = A_dict\n        self.TAB_dict = TAB_dict\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augment = augment\n        self.augmentor = MedicalAugmentation(augment=augment)\n        \n        # Prepare image paths for each patient\n        self.patient_images = {}\n        for patient in self.patients:\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = [f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm']\n                if image_files:\n                    self.patient_images[patient] = image_files\n        \n        # Filter patients with available images\n        self.valid_patients = [p for p in self.patients if p in self.patient_images]\n        print(f\"Dataset {split}: {len(self.valid_patients)} patients with images\")\n    \n    def __len__(self):\n        if self.split == 'train':\n            return len(self.valid_patients) * 6\n        else:\n            return len(self.valid_patients)\n    \n    def __getitem__(self, idx):\n        if self.split == 'train':\n            patient_idx = idx % len(self.valid_patients)\n        else:\n            patient_idx = idx\n            \n        patient = self.valid_patients[patient_idx]\n        \n        # Get random image for this patient\n        available_images = self.patient_images[patient]\n        if len(available_images) > 1:\n            selected_image = np.random.choice(available_images)\n        else:\n            selected_image = available_images[0]\n        \n        # Load and preprocess image\n        img = self.load_and_preprocess_dicom(selected_image)\n        \n        # Apply augmentations\n        img_tensor = self.augmentor(img)\n        \n        # Get tabular features\n        tab_features = torch.tensor(self.TAB_dict[patient], dtype=torch.float32)\n        \n        # Get target (decay coefficient)\n        target = torch.tensor(self.A_dict[patient], dtype=torch.float32)\n        \n        return img_tensor, tab_features, target, patient\n    \n    def load_and_preprocess_dicom(self, path):\n        \"\"\"Enhanced DICOM loading with better preprocessing\"\"\"\n        try:\n            # Load DICOM\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            \n            # Handle different DICOM formats\n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]\n            \n            # Resize to target size\n            img = cv2.resize(img, (512, 512))\n            \n            # Normalize to 0-255 range\n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            \n            # Convert to 3-channel\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            \n            return img\n            \n        except Exception as e:\n            print(f\"Error loading DICOM {path}: {e}\")\n            return np.zeros((512, 512, 3), dtype=np.uint8)\n\nclass SimpleTrainer:\n    \"\"\"\n    Simple trainer that works with any model structure\n    \"\"\"\n    \n    def __init__(self, model, device, lr=1e-4):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.best_val_mae = float('inf')\n        self.best_laplace_ll = float('-inf')\n        \n    def uncertainty_loss(self, mean_pred, log_var, targets, reduction='mean'):\n        \"\"\"Uncertainty-aware loss function\"\"\"\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        loss = 0.5 * (mse_loss / var + log_var)\n        \n        if reduction == 'mean':\n            return loss.mean()\n        return loss.sum()\n    \n    def laplace_log_likelihood(self, mean_pred, log_var, targets):\n        \"\"\"\n        Calculate Laplace Log Likelihood (OSIC competition metric)\n        \n        üéØ CURRENTLY: Only used for monitoring/display\n        üìä TO USE FOR TRAINING: See comments in training loop (line ~430)\n        \n        Higher is better (closer to 0 from negative)\n        \n        Formula: -‚àö2 * |pred - actual| / œÉ - log(‚àö2 * œÉ)\n        where œÉ = sqrt(exp(log_var)), clipped to minimum 70\n        \n        Competition Rule: Minimum œÉ = 70mL (cannot be more confident than ¬±70mL)\n        \"\"\"\n        sigma = torch.sqrt(torch.exp(log_var))\n        sigma_clipped = torch.clamp(sigma, min=70)  # Competition rule: min confidence = 70\n        \n        delta = torch.abs(mean_pred - targets)\n        \n        # Laplace log likelihood\n        ll = -np.sqrt(2) * delta / sigma_clipped - torch.log(np.sqrt(2) * sigma_clipped)\n        \n        return ll.mean().item()\n    \n    def calculate_r2_score(self, predictions, targets):\n        \"\"\"Calculate R¬≤ score\"\"\"\n        predictions = np.array(predictions)\n        targets = np.array(targets)\n        ss_res = np.sum((targets - predictions) ** 2)\n        ss_tot = np.sum((targets - np.mean(targets)) ** 2)\n        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n        return r2\n        \n    def train(self, train_loader, val_loader, epochs=30, patience=8):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=4, verbose=True\n        )\n        \n        # Mixed precision training for P100 speedup\n        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n        use_amp = torch.cuda.is_available()\n        \n        if use_amp:\n            print(\"‚ö° Mixed Precision Training ENABLED for P100\")\n        \n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            # Training phase\n            self.model.train()\n            train_loss = 0.0\n            train_mae = 0.0\n            train_batches = 0\n            \n            for batch_idx, (images, tabular, targets, _) in enumerate(train_loader):\n                try:\n                    images = images.to(self.device)\n                    tabular = tabular.to(self.device) \n                    targets = targets.to(self.device)\n                    \n                    optimizer.zero_grad()\n                    \n                    # Mixed precision forward pass\n                    if use_amp:\n                        with torch.cuda.amp.autocast():\n                            mean_pred, log_var = self.model(images, tabular)\n                            \n                            # üîÑ LOSS FUNCTION - Currently using uncertainty_loss\n                            # To switch to Laplace LL (competition metric), uncomment line below and comment out current loss\n                            # loss = -self.laplace_log_likelihood(mean_pred, log_var, targets) * torch.ones(1, device=self.device)  # Negative for minimization\n                            loss = self.uncertainty_loss(mean_pred, log_var, targets)  # ‚Üê Current: uncertainty loss\n                            \n                            mae = F.l1_loss(mean_pred, targets)\n                    else:\n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        # üîÑ LOSS FUNCTION - Currently using uncertainty_loss\n                        # To switch to Laplace LL (competition metric), uncomment line below and comment out current loss\n                        # loss = -self.laplace_log_likelihood(mean_pred, log_var, targets) * torch.ones(1, device=self.device)  # Negative for minimization\n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)  # ‚Üê Current: uncertainty loss\n                        \n                        mae = F.l1_loss(mean_pred, targets)\n                    \n                    # Mixed precision backward pass\n                    if use_amp:\n                        scaler.scale(loss).backward()\n                        scaler.unscale_(optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        loss.backward()\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_mae += mae.item()\n                    train_batches += 1\n                    \n                except Exception as e:\n                    print(f\"Error in training batch {batch_idx}: {e}\")\n                    continue\n            \n            # Validation phase\n            self.model.eval()\n            val_loss = 0.0\n            val_mae = 0.0\n            val_predictions = []\n            val_targets = []\n            \n            with torch.no_grad():\n                for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                    try:\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        \n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        mae = F.l1_loss(mean_pred, targets)\n                        \n                        val_loss += loss.item()\n                        val_mae += mae.item()\n                        \n                        val_predictions.extend(mean_pred.cpu().numpy())\n                        val_targets.extend(targets.cpu().numpy())\n                        \n                    except Exception as e:\n                        print(f\"Error in validation batch {batch_idx}: {e}\")\n                        continue\n            \n            # Calculate metrics\n            if train_batches > 0 and len(val_predictions) > 0:\n                avg_train_loss = train_loss / train_batches\n                avg_train_mae = train_mae / train_batches\n                avg_val_loss = val_loss / len(val_loader)\n                avg_val_mae = val_mae / len(val_loader)\n                \n                # Calculate R¬≤ score\n                train_r2 = self.calculate_r2_score(\n                    [p.item() for p in self.model(images, tabular)[0][-8:]] if train_batches > 0 else [],\n                    [t.item() for t in targets[-8:]] if train_batches > 0 else []\n                ) if train_batches > 0 else 0\n                \n                val_r2 = self.calculate_r2_score(val_predictions, val_targets)\n                \n                # Calculate Laplace Log Likelihood for validation\n                val_laplace_ll = 0.0\n                with torch.no_grad():\n                    for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        mean_pred, log_var = self.model(images, tabular)\n                        val_laplace_ll += self.laplace_log_likelihood(mean_pred, log_var, targets)\n                \n                avg_val_laplace = val_laplace_ll / len(val_loader)\n                \n                # Calculate correlation\n                val_corr = np.corrcoef(val_predictions, val_targets)[0, 1] if len(val_predictions) > 1 else 0\n                \n                print(f\"Epoch {epoch+1}/{epochs}\")\n                print(f\"Train - Loss: {avg_train_loss:.6f} | MAE: {avg_train_mae:.6f}\")\n                print(f\"Val   - Loss: {avg_val_loss:.6f} | MAE: {avg_val_mae:.6f}\")\n                print(f\"Val   - R¬≤: {val_r2:.4f} | Correlation: {val_corr:.4f}\")\n                print(f\"Val   - Laplace LL: {avg_val_laplace:.6f} üéØ\")\n                \n                # Learning rate scheduling\n                scheduler.step(avg_val_mae)\n                \n                # Early stopping and model saving (based on Laplace LL)\n                if avg_val_laplace > self.best_laplace_ll:\n                    self.best_laplace_ll = avg_val_laplace\n                    self.best_val_mae = avg_val_mae\n                    torch.save(self.model.state_dict(), 'best_working_model.pth')\n                    print(\"‚úÖ New best model saved! (Best Laplace LL)\")\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n                    \n                if patience_counter >= patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n                    \n                print(\"-\" * 60)\n        \n        print(f\"\\nüèÜ Training Summary:\")\n        print(f\"   Best Validation MAE: {self.best_val_mae:.6f}\")\n        print(f\"   Best Laplace Log Likelihood: {self.best_laplace_ll:.6f}\")\n        \n        return self.best_val_mae, self.best_laplace_ll\n\n# Main execution\ndef main():\n    print(\"üîÑ Creating data loaders...\")\n    \n    # Split patients into train and validation\n    patients_list = list(P)\n    train_patients, val_patients = train_test_split(\n        patients_list, \n        test_size=0.2, \n        random_state=42,\n        shuffle=True\n    )\n    \n    print(f\"Train patients: {len(train_patients)}\")\n    print(f\"Validation patients: {len(val_patients)}\")\n    \n    # Create datasets\n    train_dataset = OSICDenseNetDataset(\n        patients=train_patients,\n        A_dict=A,\n        TAB_dict=TAB,\n        data_dir=TRAIN_DIR,\n        split='train',\n        augment=True\n    )\n    \n    val_dataset = OSICDenseNetDataset(\n        patients=val_patients,\n        A_dict=A,\n        TAB_dict=TAB,\n        data_dir=TRAIN_DIR,\n        split='val',\n        augment=False\n    )\n    \n    # Create data loaders optimized for P100\n    # P100 has 16GB memory - can handle larger batches\n    batch_size = 16 if torch.cuda.is_available() else 8\n    num_workers = 4 if torch.cuda.is_available() else 2  # P100 benefits from more workers\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=True,\n        persistent_workers=True if num_workers > 0 else False  # Keep workers alive\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=False,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    \n    print(f\"‚úÖ Data loaders created!\")\n    print(f\"   Batch size: {batch_size} (P100 optimized)\")\n    print(f\"   Train batches: {len(train_loader)}\")\n    print(f\"   Val batches: {len(val_loader)}\")\n    print(f\"   Workers: {num_workers}\")\n    \n    # Initialize model\n    print(\"üîÑ Initializing model...\")\n    model = WorkingDenseNetModel(tabular_dim=4).to(DEVICE)\n    print(f\"‚úÖ Model initialized!\")\n    print(f\"üìä Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    \n    # Test model with actual batch\n    try:\n        test_batch = next(iter(train_loader))\n        images, tabular, targets, _ = test_batch\n        images = images.to(DEVICE)\n        tabular = tabular.to(DEVICE)\n        \n        print(f\"üîç Testing model...\")\n        with torch.no_grad():\n            mean_pred, log_var = model(images, tabular)\n            print(f\"‚úÖ Model forward pass successful!\")\n            \n    except Exception as e:\n        print(f\"‚ùå Model test failed: {e}\")\n        return\n    \n    # Create trainer and start training\n    print(\"üöÄ Starting training...\")\n    trainer = SimpleTrainer(model, DEVICE, lr=1e-4)\n    \n    best_val_mae, best_laplace_ll = trainer.train(\n        train_loader, \n        val_loader, \n        epochs=30,\n        patience=8\n    )\n    \n    print(f\"\\nüéØ Training completed!\")\n    print(f\"   Best MAE: {best_val_mae:.6f}\")\n    print(f\"   Best Laplace LL: {best_laplace_ll:.6f}\")\n    \n    return model, train_loader, val_loader, best_val_mae, best_laplace_ll\n\nif __name__ == \"__main__\":\n    model, train_loader, val_loader, best_val_mae, best_laplace_ll = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T12:05:58.566724Z","iopub.execute_input":"2025-10-10T12:05:58.566993Z","iopub.status.idle":"2025-10-10T12:13:06.103827Z","shell.execute_reply.started":"2025-10-10T12:05:58.566973Z","shell.execute_reply":"2025-10-10T12:13:06.102589Z"}},"outputs":[{"name":"stdout","text":"üöÄ Fixed OSIC Model - Complete Working Version\n============================================================\nüì± Device: cuda\nüî• GPU: Tesla P100-PCIE-16GB\nüíæ Memory: 17.1 GB\n‚ö° CUDA Version: 12.4\nüöÄ cuDNN Benchmark: Enabled (P100 optimized)\n============================================================\nLoaded dataset with shape: (1549, 7)\nCalculating linear decay coefficients...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 1183.37it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 176 patients with decay coefficients\nüîÑ Creating data loaders...\nTrain patients: 140\nValidation patients: 36\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Dataset train: 138 patients with images\nDataset val: 36 patients with images\n‚úÖ Data loaders created!\n   Batch size: 16 (P100 optimized)\n   Train batches: 51\n   Val batches: 3\n   Workers: 4\nüîÑ Initializing model...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30.8M/30.8M [00:00<00:00, 106MB/s] \n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Model initialized!\nüìä Total parameters: 13,281,764\nüîç Testing model...\n‚úÖ Model forward pass successful!\nüöÄ Starting training...\n‚ö° Mixed Precision Training ENABLED for P100\nEpoch 1/30\nTrain - Loss: 18.252004 | MAE: 5.250605\nVal   - Loss: 18.423107 | MAE: 6.043770\nVal   - R¬≤: -0.3828 | Correlation: -0.0151\nVal   - Laplace LL: -4.717172 üéØ\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 2/30\nTrain - Loss: 6.952286 | MAE: 4.837205\nVal   - Loss: 7.893726 | MAE: 5.599412\nVal   - R¬≤: -0.2397 | Correlation: 0.1352\nVal   - Laplace LL: -4.708194 üéØ\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 3/30\nTrain - Loss: 3.295451 | MAE: 4.283583\nVal   - Loss: 4.469790 | MAE: 5.126448\nVal   - R¬≤: -0.0891 | Correlation: 0.1142\nVal   - Laplace LL: -4.698639 üéØ\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 4/30\nTrain - Loss: 2.380236 | MAE: 4.101167\nVal   - Loss: 2.867719 | MAE: 4.765947\nVal   - R¬≤: -0.0085 | Correlation: 0.1583\nVal   - Laplace LL: -4.691356 üéØ\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 5/30\nTrain - Loss: 2.288978 | MAE: 4.116466\nVal   - Loss: 3.116507 | MAE: 4.766642\nVal   - R¬≤: -0.0150 | Correlation: 0.0862\nVal   - Laplace LL: -4.691370 üéØ\n------------------------------------------------------------\nEpoch 6/30\nTrain - Loss: 2.272310 | MAE: 4.034109\nVal   - Loss: 2.644123 | MAE: 4.677203\nVal   - R¬≤: -0.0092 | Correlation: 0.0413\nVal   - Laplace LL: -4.689563 üéØ\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 7/30\nTrain - Loss: 2.271169 | MAE: 3.993834\nVal   - Loss: 2.836113 | MAE: 4.779516\nVal   - R¬≤: -0.0274 | Correlation: -0.0309\nVal   - Laplace LL: -4.691630 üéØ\n------------------------------------------------------------\nEpoch 8/30\nTrain - Loss: 2.267831 | MAE: 3.984971\nVal   - Loss: 2.866511 | MAE: 4.772835\nVal   - R¬≤: -0.0334 | Correlation: -0.0208\nVal   - Laplace LL: -4.691495 üéØ\n------------------------------------------------------------\nEpoch 9/30\nTrain - Loss: 2.206494 | MAE: 3.971472\nVal   - Loss: 2.928870 | MAE: 4.806456\nVal   - R¬≤: -0.0893 | Correlation: -0.1516\nVal   - Laplace LL: -4.692174 üéØ\n------------------------------------------------------------\nEpoch 10/30\nTrain - Loss: 2.276254 | MAE: 4.062802\nVal   - Loss: 2.744226 | MAE: 4.648862\nVal   - R¬≤: 0.0001 | Correlation: 0.1005\nVal   - Laplace LL: -4.688990 üéØ\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 11/30\nTrain - Loss: 2.212688 | MAE: 3.973184\nVal   - Loss: 2.684038 | MAE: 4.727852\nVal   - R¬≤: -0.0247 | Correlation: -0.0096\nVal   - Laplace LL: -4.690586 üéØ\n------------------------------------------------------------\nEpoch 12/30\nTrain - Loss: 2.255037 | MAE: 4.000742\nVal   - Loss: 2.840925 | MAE: 4.829493\nVal   - R¬≤: -0.0417 | Correlation: -0.0530\nVal   - Laplace LL: -4.692640 üéØ\n------------------------------------------------------------\nEpoch 13/30\nTrain - Loss: 2.292290 | MAE: 3.941856\nVal   - Loss: 3.351510 | MAE: 4.762070\nVal   - R¬≤: -0.0403 | Correlation: -0.0447\nVal   - Laplace LL: -4.691277 üéØ\n------------------------------------------------------------\nEpoch 14/30\nTrain - Loss: 2.258447 | MAE: 4.003523\nVal   - Loss: 3.026923 | MAE: 4.756672\nVal   - R¬≤: -0.0530 | Correlation: -0.0752\nVal   - Laplace LL: -4.691168 üéØ\n------------------------------------------------------------\nEpoch 15/30\nTrain - Loss: 2.215632 | MAE: 4.088374\nVal   - Loss: 2.977164 | MAE: 4.686942\nVal   - R¬≤: -0.0162 | Correlation: 0.0035\nVal   - Laplace LL: -4.689759 üéØ\n------------------------------------------------------------\nEpoch 16/30\nTrain - Loss: 2.213505 | MAE: 4.004746\nVal   - Loss: 3.098679 | MAE: 4.801943\nVal   - R¬≤: -0.0382 | Correlation: -0.0630\nVal   - Laplace LL: -4.692083 üéØ\n------------------------------------------------------------\nEpoch 17/30\nTrain - Loss: 2.254976 | MAE: 3.963187\nVal   - Loss: 2.945350 | MAE: 4.807427\nVal   - R¬≤: -0.0565 | Correlation: -0.0984\nVal   - Laplace LL: -4.692194 üéØ\n------------------------------------------------------------\nEpoch 18/30\nTrain - Loss: 2.160658 | MAE: 3.975427\nVal   - Loss: 2.852111 | MAE: 4.807505\nVal   - R¬≤: -0.0434 | Correlation: -0.0602\nVal   - Laplace LL: -4.692195 üéØ\nEarly stopping at epoch 18\n\nüèÜ Training Summary:\n   Best Validation MAE: 4.648862\n   Best Laplace Log Likelihood: -4.688990\n\nüéØ Training completed!\n   Best MAE: 4.648862\n   Best Laplace LL: -4.688990\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"‚úÖ IMPLEMENTATION COMPLETE!\nüéØ What I Fixed:\n‚úÖ Changed Target Variable\n\nFROM: One decay slope per patient (-3.5 mL/week)\nTO: Actual FVC at each visit (2500 mL, 2300 mL, 2100 mL...)\n‚úÖ Added Temporal Features\n\nWeeksFromBaseline: How many weeks since first visit\nBaselineFVC: Patient's starting FVC\nBaselinePercent: Baseline FVC % predicted\nModel can now learn: \"Given baseline + time ‚Üí predict current FVC\"\n‚úÖ Visit-Level Dataset\n\n176 patients √ó <del>4 visits = **</del>700 training samples** (was 176)\nEach CT scan paired with its temporal context\nNo more \"same target for different timepoints\" problem\n‚úÖ Patient-Level Splitting\n\nAll visits from same patient stay together (no data leakage!)\nProper generalization testing\n‚úÖ Updated Model\n\nInput: 7 features (was 4)\nOutput: FVC in mL (was slope in mL/week)\nSame architecture, better task!\n‚úÖ Better Metrics\n\nMAE now in mL (clinically meaningful)\nRMSE added\nR¬≤ measures explained variance in FVC\n\n\n\nüöÄ Expected Results:\nBefore (Broken)\tAfter (Fixed)\nMAE: 4.6 (meaningless)\tMAE: 150-250 mL ‚úÖ\nR¬≤: 0.0 (no learning)\tR¬≤: 0.4-0.6 ‚úÖ\nCorrelation: 0.0\tCorrelation: 0.6-0.8 ‚úÖ\nLaplace LL: -4.69 (terrible)\tLaplace LL: -3.5 to -3.0 ‚úÖ\nüìù Next Steps:\nRun the notebook on Kaggle with GPU P100\nCheck new training output - should see actual improvement now!\nIf MAE < 200mL and R¬≤ > 0.4: Switch to LLL training for fine-tuning\nIf still poor: Add radiomic features (Phase 2 of your plan)\nüí° Why This Aligns with Your Plan:\n‚úÖ Matches OSIC constraints: Single baseline CT, longitudinal FVC data\n‚úÖ Visit-level prediction: Exactly what you described in your plan\n‚úÖ Temporal features: Weeks, baseline context added\n‚úÖ Proper validation: Patient-level split prevents leakage\n‚úÖ Scalable: Ready for radiomics + ensemble later","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport random\nfrom tqdm import tqdm \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom PIL import Image\nimport json\nfrom pathlib import Path\nimport joblib\nimport warnings\nimport pickle\nfrom typing import Dict, List, Tuple, Optional\nfrom scipy import ndimage\nfrom scipy.ndimage import binary_fill_holes, generate_binary_structure\nfrom skimage import measure, morphology\nfrom skimage.transform import resize\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed=42):\n    \"\"\"Ensure reproducibility across all random operations\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    \nseed_everything(42)\n\n# Configuration\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\n\n# GPU Configuration for P100\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Enable optimizations for GPU training\nif torch.cuda.is_available():\n    torch.backends.cudnn.benchmark = True  # Auto-tune for best performance on P100\n    torch.cuda.empty_cache()  # Clear cache before starting\n\nprint(\"üöÄ Fixed OSIC Model - Complete Working Version\")\nprint(\"=\" * 60)\nprint(f\"üì± Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"üî• GPU: {torch.cuda.get_device_name()}\")\n    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    print(f\"‚ö° CUDA Version: {torch.version.cuda}\")\n    print(f\"üöÄ cuDNN Benchmark: Enabled (P100 optimized)\")\nprint(\"=\" * 60)\n\n# Load Data\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\nprint(f\"Loaded dataset with shape: {train_df.shape}\")\n\ndef get_tab_features(df_row):\n    \"\"\"Extract tabular features (returns 4 features)\"\"\"\n    vector = [(df_row['Age'] - 30) / 30] \n    \n    # Sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(0)\n    else:\n        vector.append(1)\n    \n    # Smoking status encoding\n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([1, 1])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 1])\n    else:\n        vector.extend([1, 0])\n    return np.array(vector)\n\n# üîÑ NEW APPROACH: Visit-level FVC prediction\n# Instead of predicting one slope per patient, predict actual FVC at each visit\nprint(\"=\" * 60)\nprint(\"üìä Creating Visit-Level Dataset\")\nprint(\"=\" * 60)\n\nvisit_data = []\npatient_baselines = {}\n\n# First pass: collect baseline information for each patient\nfor patient in train_df['Patient'].unique():\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    if len(sub) > 0:\n        # Get baseline (first measurement)\n        baseline_fvc = sub.iloc[0]['FVC']\n        baseline_percent = sub.iloc[0]['Percent']\n        baseline_week = sub.iloc[0]['Weeks']\n        \n        patient_baselines[patient] = {\n            'baseline_fvc': baseline_fvc,\n            'baseline_percent': baseline_percent,\n            'baseline_week': baseline_week,\n            'tabular': get_tab_features(sub.iloc[0])\n        }\n\n# Second pass: create visit-level samples\nprint(\"Creating visit-level samples...\")\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    \n    if patient not in patient_baselines:\n        continue\n    \n    baseline_info = patient_baselines[patient]\n    \n    # Create one sample for each visit\n    for idx, row in sub.iterrows():\n        visit_data.append({\n            'Patient': patient,\n            'Week': row['Weeks'],\n            'FVC': row['FVC'],  # Target: actual FVC at this visit\n            'Percent': row['Percent'],\n            'Age': row['Age'],\n            'Sex': row['Sex'],\n            'SmokingStatus': row['SmokingStatus'],\n            \n            # Temporal features (NEW!)\n            'WeeksFromBaseline': row['Weeks'] - baseline_info['baseline_week'],\n            'BaselineFVC': baseline_info['baseline_fvc'],\n            'BaselinePercent': baseline_info['baseline_percent'],\n            \n            # Tabular features\n            'tabular_features': baseline_info['tabular']\n        })\n\nvisit_df = pd.DataFrame(visit_data)\n\nprint(f\"\\n‚úÖ Dataset created:\")\nprint(f\"   Total visits: {len(visit_df)}\")\nprint(f\"   Unique patients: {visit_df['Patient'].nunique()}\")\nprint(f\"   Avg visits per patient: {len(visit_df) / visit_df['Patient'].nunique():.1f}\")\nprint(f\"   FVC range: [{visit_df['FVC'].min():.0f}, {visit_df['FVC'].max():.0f}] mL\")\nprint(f\"   Weeks range: [{visit_df['WeeksFromBaseline'].min():.0f}, {visit_df['WeeksFromBaseline'].max():.0f}]\")\n\nclass MedicalAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                albu.Rotate(limit=15, p=0.7),\n                albu.HorizontalFlip(p=0.5),\n                albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),\n                albu.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n                albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n                albu.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n                albu.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n    \n    def __call__(self, image):\n        return self.transform(image=image)['image']\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_cat = torch.cat([avg_out, max_out], dim=1)\n        x_cat = self.conv1(x_cat)\n        return x * self.sigmoid(x_cat)\n\nclass WorkingDenseNetModel(nn.Module):\n    \"\"\"\n    üîÑ UPDATED: Now predicts absolute FVC values (not slopes)\n    \n    Input:\n    - CT scan: 3 x 512 x 512\n    - Tabular: 7 features (Age, Sex, Smoking, WeeksFromBaseline, BaselineFVC, BaselinePercent)\n    \n    Output:\n    - FVC prediction (mL)\n    - Uncertainty (log variance)\n    \"\"\"\n    \n    def __init__(self, tabular_dim=7, dropout_rate=0.4):  # Changed from 4 to 7\n        super(WorkingDenseNetModel, self).__init__()\n        \n        # DenseNet121 backbone\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        \n        # Spatial attention\n        self.spatial_attention = SpatialAttention()\n        \n        # Enhanced tabular processing\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        \n        # Cross-modal attention\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=1024, num_heads=8, dropout=0.2, batch_first=True\n        )\n        \n        # Initialize projection weight properly\n        self.tab_projection = nn.Linear(512, 1024)\n        \n        # Multi-modal fusion\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 512, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(768, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2)\n        )\n        \n        # Uncertainty quantification heads\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        \n        # Extract image features\n        img_features = self.features(images)\n        \n        # Apply spatial attention\n        img_features = self.spatial_attention(img_features)\n        \n        # Global average pooling\n        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n        img_features = img_features.view(batch_size, -1)\n        \n        # Process tabular data\n        tab_features = self.tabular_processor(tabular)\n        \n        # Cross-modal attention\n        img_expanded = img_features.unsqueeze(1)\n        tab_expanded = tab_features.unsqueeze(1)\n        \n        # Project tabular to same dimension for attention\n        tab_proj = self.tab_projection(tab_expanded)\n        \n        attended_img, _ = self.cross_attention(\n            img_expanded, tab_proj, tab_proj\n        )\n        attended_img = attended_img.squeeze(1)\n        \n        # Fusion\n        combined_features = torch.cat([attended_img, tab_features], dim=1)\n        fused_features = self.fusion_layer(combined_features)\n        \n        # Predict mean and log variance\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        \n        return mean_pred.squeeze(), log_var.squeeze()\n\nclass OSICVisitLevelDataset(Dataset):\n    \"\"\"\n    üîÑ NEW: Visit-level dataset for FVC prediction\n    \n    Each sample represents ONE visit (patient at specific timepoint):\n    - Input: CT scan + tabular + temporal features\n    - Target: FVC value at that visit\n    \"\"\"\n    \n    def __init__(self, visit_dataframe, data_dir, split='train', augment=True):\n        self.visit_df = visit_dataframe.reset_index(drop=True)\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augment = augment\n        self.augmentor = MedicalAugmentation(augment=augment)\n        \n        # Filter out problematic patients\n        problematic = ['ID00011637202177653955184', 'ID00052637202186188008618']\n        self.visit_df = self.visit_df[~self.visit_df['Patient'].isin(problematic)]\n        \n        # Prepare image paths for each patient (one CT per patient, used for all visits)\n        # üîÑ IMPROVEMENT: Store ALL slices, will select based on visit context\n        self.patient_images = {}\n        for patient in self.visit_df['Patient'].unique():\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = sorted([f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm'])\n                if image_files:\n                    # Store ALL slices instead of just middle one\n                    self.patient_images[patient] = image_files\n        \n        # Filter visits with available images\n        self.visit_df = self.visit_df[self.visit_df['Patient'].isin(self.patient_images.keys())]\n        \n        print(f\"Dataset {split}: {len(self.visit_df)} visits from {self.visit_df['Patient'].nunique()} patients\")\n    \n    def __len__(self):\n        return len(self.visit_df)\n    \n    def __getitem__(self, idx):\n        row = self.visit_df.iloc[idx]\n        patient = row['Patient']\n        \n        # üîÑ IMPROVED: Select slice based on temporal context\n        # Later visits might show more severe disease ‚Üí use different slices\n        image_files = self.patient_images[patient]\n        \n        if self.augment:\n            # Training: Add variety by randomly selecting from middle 60% of slices\n            start_idx = len(image_files) // 5\n            end_idx = len(image_files) * 4 // 5\n            selected_image = image_files[np.random.randint(start_idx, max(start_idx + 1, end_idx))]\n        else:\n            # Validation: Use consistent middle slice\n            selected_image = image_files[len(image_files) // 2]\n        \n        # Load and preprocess image\n        img = self.load_and_preprocess_dicom(selected_image)\n        \n        # Apply augmentations\n        img_tensor = self.augmentor(img)\n        \n        # üîÑ NEW: Enhanced tabular features with temporal information\n        tab_features = np.concatenate([\n            row['tabular_features'],  # Age, Sex, Smoking (4 features)\n            [(row['WeeksFromBaseline'] + 12) / 52],  # Normalized weeks (1 feature)\n            [row['BaselineFVC'] / 1000],  # Normalized baseline FVC (1 feature)\n            [row['BaselinePercent'] / 100]  # Baseline FVC % (1 feature)\n        ])  # Total: 7 features (was 4)\n        \n        tab_features = torch.tensor(tab_features, dtype=torch.float32)\n        \n        # üéØ NEW TARGET: Actual FVC value (not slope)\n        target_fvc = torch.tensor(row['FVC'], dtype=torch.float32)\n        \n        return img_tensor, tab_features, target_fvc, patient\n    \n    def load_and_preprocess_dicom(self, path):\n        \"\"\"Enhanced DICOM loading with better preprocessing\"\"\"\n        try:\n            # Load DICOM\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            \n            # Handle different DICOM formats\n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]\n            \n            # Resize to target size\n            img = cv2.resize(img, (512, 512))\n            \n            # Normalize to 0-255 range\n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            \n            # Convert to 3-channel\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            \n            return img\n            \n        except Exception as e:\n            print(f\"Error loading DICOM {path}: {e}\")\n            return np.zeros((512, 512, 3), dtype=np.uint8)\n\nclass SimpleTrainer:\n    \"\"\"\n    Simple trainer that works with any model structure\n    \"\"\"\n    \n    def __init__(self, model, device, lr=1e-4):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.best_val_mae = float('inf')\n        self.best_laplace_ll = float('-inf')\n        \n    def uncertainty_loss(self, mean_pred, log_var, targets, reduction='mean'):\n        \"\"\"Uncertainty-aware loss function\"\"\"\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        loss = 0.5 * (mse_loss / var + log_var)\n        \n        if reduction == 'mean':\n            return loss.mean()\n        return loss.sum()\n    \n    def laplace_log_likelihood(self, mean_pred, log_var, targets):\n        \"\"\"\n        Calculate Laplace Log Likelihood (OSIC competition metric)\n        \n        üéØ CURRENTLY: Only used for monitoring/display\n        üìä TO USE FOR TRAINING: See comments in training loop (line ~430)\n        \n        Higher is better (closer to 0 from negative)\n        \n        Formula: -‚àö2 * |pred - actual| / œÉ - log(‚àö2 * œÉ)\n        where œÉ = sqrt(exp(log_var)), clipped to minimum 70\n        \n        Competition Rule: Minimum œÉ = 70mL (cannot be more confident than ¬±70mL)\n        \"\"\"\n        sigma = torch.sqrt(torch.exp(log_var))\n        sigma_clipped = torch.clamp(sigma, min=70)  # Competition rule: min confidence = 70\n        \n        delta = torch.abs(mean_pred - targets)\n        \n        # Laplace log likelihood\n        ll = -np.sqrt(2) * delta / sigma_clipped - torch.log(np.sqrt(2) * sigma_clipped)\n        \n        return ll.mean().item()\n    \n    def calculate_r2_score(self, predictions, targets):\n        \"\"\"Calculate R¬≤ score\"\"\"\n        predictions = np.array(predictions)\n        targets = np.array(targets)\n        ss_res = np.sum((targets - predictions) ** 2)\n        ss_tot = np.sum((targets - np.mean(targets)) ** 2)\n        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n        return r2\n        \n    def train(self, train_loader, val_loader, epochs=30, patience=8):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=4, verbose=True\n        )\n        \n        # Mixed precision training for P100 speedup\n        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n        use_amp = torch.cuda.is_available()\n        \n        if use_amp:\n            print(\"‚ö° Mixed Precision Training ENABLED for P100\")\n        \n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            # Training phase\n            self.model.train()\n            train_loss = 0.0\n            train_mae = 0.0\n            train_batches = 0\n            \n            for batch_idx, (images, tabular, targets, _) in enumerate(train_loader):\n                try:\n                    images = images.to(self.device)\n                    tabular = tabular.to(self.device) \n                    targets = targets.to(self.device)\n                    \n                    optimizer.zero_grad()\n                    \n                    # Mixed precision forward pass\n                    if use_amp:\n                        with torch.cuda.amp.autocast():\n                            mean_pred, log_var = self.model(images, tabular)\n                            \n                            # üîÑ LOSS FUNCTION - Currently using uncertainty_loss\n                            # To switch to Laplace LL (competition metric), uncomment line below and comment out current loss\n                            # loss = -self.laplace_log_likelihood(mean_pred, log_var, targets) * torch.ones(1, device=self.device)  # Negative for minimization\n                            loss = self.uncertainty_loss(mean_pred, log_var, targets)  # ‚Üê Current: uncertainty loss\n                            \n                            mae = F.l1_loss(mean_pred, targets)\n                    else:\n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        # üîÑ LOSS FUNCTION - Currently using uncertainty_loss\n                        # To switch to Laplace LL (competition metric), uncomment line below and comment out current loss\n                        # loss = -self.laplace_log_likelihood(mean_pred, log_var, targets) * torch.ones(1, device=self.device)  # Negative for minimization\n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)  # ‚Üê Current: uncertainty loss\n                        \n                        mae = F.l1_loss(mean_pred, targets)\n                    \n                    # Mixed precision backward pass\n                    if use_amp:\n                        scaler.scale(loss).backward()\n                        scaler.unscale_(optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        loss.backward()\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_mae += mae.item()\n                    train_batches += 1\n                    \n                except Exception as e:\n                    print(f\"Error in training batch {batch_idx}: {e}\")\n                    continue\n            \n            # Validation phase\n            self.model.eval()\n            val_loss = 0.0\n            val_mae = 0.0\n            val_predictions = []\n            val_targets = []\n            \n            with torch.no_grad():\n                for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                    try:\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        \n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        mae = F.l1_loss(mean_pred, targets)\n                        \n                        val_loss += loss.item()\n                        val_mae += mae.item()\n                        \n                        val_predictions.extend(mean_pred.cpu().numpy())\n                        val_targets.extend(targets.cpu().numpy())\n                        \n                    except Exception as e:\n                        print(f\"Error in validation batch {batch_idx}: {e}\")\n                        continue\n            \n            # Calculate metrics\n            if train_batches > 0 and len(val_predictions) > 0:\n                avg_train_loss = train_loss / train_batches\n                avg_train_mae = train_mae / train_batches\n                avg_val_loss = val_loss / len(val_loader)\n                avg_val_mae = val_mae / len(val_loader)\n                \n                # Calculate R¬≤ score\n                train_r2 = self.calculate_r2_score(\n                    [p.item() for p in self.model(images, tabular)[0][-8:]] if train_batches > 0 else [],\n                    [t.item() for t in targets[-8:]] if train_batches > 0 else []\n                ) if train_batches > 0 else 0\n                \n                val_r2 = self.calculate_r2_score(val_predictions, val_targets)\n                \n                # Calculate Laplace Log Likelihood for validation\n                val_laplace_ll = 0.0\n                with torch.no_grad():\n                    for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        mean_pred, log_var = self.model(images, tabular)\n                        val_laplace_ll += self.laplace_log_likelihood(mean_pred, log_var, targets)\n                \n                avg_val_laplace = val_laplace_ll / len(val_loader)\n                \n                # Calculate correlation\n                val_corr = np.corrcoef(val_predictions, val_targets)[0, 1] if len(val_predictions) > 1 else 0\n                \n                print(f\"Epoch {epoch+1}/{epochs}\")\n                print(f\"Train - Loss: {avg_train_loss:.6f} | MAE: {avg_train_mae:.1f} mL\")\n                print(f\"Val   - Loss: {avg_val_loss:.6f} | MAE: {avg_val_mae:.1f} mL\")\n                print(f\"Val   - R¬≤: {val_r2:.4f} | Correlation: {val_corr:.4f}\")\n                print(f\"Val   - Laplace LL: {avg_val_laplace:.6f} üéØ\")\n                print(f\"Val   - RMSE: {np.sqrt(mean_squared_error(val_targets, val_predictions)):.1f} mL\")\n                \n                # Learning rate scheduling\n                scheduler.step(avg_val_mae)\n                \n                # Early stopping and model saving (based on Laplace LL)\n                if avg_val_laplace > self.best_laplace_ll:\n                    self.best_laplace_ll = avg_val_laplace\n                    self.best_val_mae = avg_val_mae\n                    torch.save(self.model.state_dict(), 'best_working_model.pth')\n                    print(\"‚úÖ New best model saved! (Best Laplace LL)\")\n                    patience_counter = 0\n                else:\n                    patience_counter += 1\n                    \n                if patience_counter >= patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n                    \n                print(\"-\" * 60)\n        \n        print(f\"\\nüèÜ Training Summary:\")\n        print(f\"   Best Validation MAE: {self.best_val_mae:.6f}\")\n        print(f\"   Best Laplace Log Likelihood: {self.best_laplace_ll:.6f}\")\n        \n        return self.best_val_mae, self.best_laplace_ll\n\n# Main execution\ndef main():\n    print(\"üîÑ Creating data loaders...\")\n    print(\"=\" * 60)\n    \n    # üéØ PATIENT-LEVEL SPLIT (prevents data leakage!)\n    # All visits from same patient stay together\n    unique_patients = visit_df['Patient'].unique()\n    train_patients, val_patients = train_test_split(\n        unique_patients, \n        test_size=0.2, \n        random_state=42,\n        shuffle=True\n    )\n    \n    # Split visits by patient\n    train_visits = visit_df[visit_df['Patient'].isin(train_patients)]\n    val_visits = visit_df[visit_df['Patient'].isin(val_patients)]\n    \n    print(f\"üìä Data Split:\")\n    print(f\"   Train: {len(train_patients)} patients, {len(train_visits)} visits\")\n    print(f\"   Val:   {len(val_patients)} patients, {len(val_visits)} visits\")\n    print(f\"   Train FVC: {train_visits['FVC'].mean():.0f} ¬± {train_visits['FVC'].std():.0f} mL\")\n    print(f\"   Val FVC:   {val_visits['FVC'].mean():.0f} ¬± {val_visits['FVC'].std():.0f} mL\")\n    print(\"=\" * 60)\n    \n    # Create datasets\n    train_dataset = OSICVisitLevelDataset(\n        visit_dataframe=train_visits,\n        data_dir=TRAIN_DIR,\n        split='train',\n        augment=True\n    )\n    \n    val_dataset = OSICVisitLevelDataset(\n        visit_dataframe=val_visits,\n        data_dir=TRAIN_DIR,\n        split='val',\n        augment=False\n    )\n    \n    # Create data loaders optimized for P100\n    # P100 has 16GB memory - can handle larger batches\n    batch_size = 16 if torch.cuda.is_available() else 8\n    num_workers = 4 if torch.cuda.is_available() else 2  # P100 benefits from more workers\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=True,\n        persistent_workers=True if num_workers > 0 else False  # Keep workers alive\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=False,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    \n    print(f\"‚úÖ Data loaders created!\")\n    print(f\"   Batch size: {batch_size} (P100 optimized)\")\n    print(f\"   Train batches: {len(train_loader)}\")\n    print(f\"   Val batches: {len(val_loader)}\")\n    print(f\"   Workers: {num_workers}\")\n    \n    # Initialize model\n    print(\"üîÑ Initializing model...\")\n    model = WorkingDenseNetModel(tabular_dim=7).to(DEVICE)  # 7 features now\n    print(f\"‚úÖ Model initialized!\")\n    print(f\"üìä Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    print(f\"üìä Output: FVC value (mL) + uncertainty\")\n    \n    # Test model with actual batch\n    try:\n        test_batch = next(iter(train_loader))\n        images, tabular, targets, _ = test_batch\n        images = images.to(DEVICE)\n        tabular = tabular.to(DEVICE)\n        \n        print(f\"üîç Testing model...\")\n        with torch.no_grad():\n            mean_pred, log_var = model(images, tabular)\n            print(f\"‚úÖ Model forward pass successful!\")\n            \n    except Exception as e:\n        print(f\"‚ùå Model test failed: {e}\")\n        return\n    \n    # Create trainer and start training\n    print(\"üöÄ Starting training...\")\n    trainer = SimpleTrainer(model, DEVICE, lr=1e-4)\n    \n    best_val_mae, best_laplace_ll = trainer.train(\n        train_loader, \n        val_loader, \n        epochs=30,\n        patience=8\n    )\n    \n    print(f\"\\nüéØ Training completed!\")\n    print(f\"   Best MAE: {best_val_mae:.6f}\")\n    print(f\"   Best Laplace LL: {best_laplace_ll:.6f}\")\n    \n    return model, train_loader, val_loader, best_val_mae, best_laplace_ll\n\nif __name__ == \"__main__\":\n    model, train_loader, val_loader, best_val_mae, best_laplace_ll = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T12:40:53.921923Z","iopub.execute_input":"2025-10-10T12:40:53.922787Z","iopub.status.idle":"2025-10-10T12:59:58.237066Z","shell.execute_reply.started":"2025-10-10T12:40:53.922748Z","shell.execute_reply":"2025-10-10T12:59:58.236161Z"}},"outputs":[{"name":"stdout","text":"üöÄ Fixed OSIC Model - Complete Working Version\n============================================================\nüì± Device: cuda\nüî• GPU: Tesla P100-PCIE-16GB\nüíæ Memory: 17.1 GB\n‚ö° CUDA Version: 12.4\nüöÄ cuDNN Benchmark: Enabled (P100 optimized)\n============================================================\nLoaded dataset with shape: (1549, 7)\n============================================================\nüìä Creating Visit-Level Dataset\n============================================================\nCreating visit-level samples...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 912.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Dataset created:\n   Total visits: 1549\n   Unique patients: 176\n   Avg visits per patient: 8.8\n   FVC range: [827, 6399] mL\n   Weeks range: [0, 63]\nüîÑ Creating data loaders...\n============================================================\nüìä Data Split:\n   Train: 140 patients, 1233 visits\n   Val:   36 patients, 316 visits\n   Train FVC: 2744 ¬± 836 mL\n   Val FVC:   2480 ¬± 788 mL\n============================================================\nDataset train: 1217 visits from 138 patients\nDataset val: 316 visits from 36 patients\n‚úÖ Data loaders created!\n   Batch size: 16 (P100 optimized)\n   Train batches: 76\n   Val batches: 20\n   Workers: 4\nüîÑ Initializing model...\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30.8M/30.8M [00:02<00:00, 11.7MB/s]","output_type":"stream"},{"name":"stdout","text":"‚úÖ Model initialized!\nüìä Total parameters: 13,282,148\nüìä Output: FVC value (mL) + uncertainty\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"üîç Testing model...\n‚úÖ Model forward pass successful!\nüöÄ Starting training...\n‚ö° Mixed Precision Training ENABLED for P100\nEpoch 1/30\nTrain - Loss: 3183998.843750 | MAE: 2742.3 mL\nVal   - Loss: 1634427.425000 | MAE: 2481.2 mL\nVal   - R¬≤: -9.9408 | Correlation: 0.0776\nVal   - Laplace LL: -54.723586 üéØ\nVal   - RMSE: 2601.3 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 2/30\nTrain - Loss: 593483.791118 | MAE: 2739.9 mL\nVal   - Loss: 272487.904297 | MAE: 2477.0 mL\nVal   - R¬≤: -9.9064 | Correlation: 0.1708\nVal   - Laplace LL: -54.637395 üéØ\nVal   - RMSE: 2597.2 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 3/30\nTrain - Loss: 79457.173597 | MAE: 2731.0 mL\nVal   - Loss: 36110.401953 | MAE: 2465.5 mL\nVal   - R¬≤: -9.8137 | Correlation: 0.3049\nVal   - Laplace LL: -54.404741 üéØ\nVal   - RMSE: 2586.1 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 4/30\nTrain - Loss: 9373.033033 | MAE: 2711.1 mL\nVal   - Loss: 3724.724884 | MAE: 2441.4 mL\nVal   - R¬≤: -9.6228 | Correlation: 0.1691\nVal   - Laplace LL: -53.770244 üéØ\nVal   - RMSE: 2563.2 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 5/30\nTrain - Loss: 963.786462 | MAE: 2674.7 mL\nVal   - Loss: 163.350028 | MAE: 2395.4 mL\nVal   - R¬≤: -9.2730 | Correlation: -0.7992\nVal   - Laplace LL: -29.561902 üéØ\nVal   - RMSE: 2520.6 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 6/30\nTrain - Loss: 86.094361 | MAE: 2621.1 mL\nVal   - Loss: 20.045151 | MAE: 2336.3 mL\nVal   - R¬≤: -8.8092 | Correlation: 0.3508\nVal   - Laplace LL: -13.742822 üéØ\nVal   - RMSE: 2463.1 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 7/30\nTrain - Loss: 14.119582 | MAE: 2538.7 mL\nVal   - Loss: 8.643306 | MAE: 2243.9 mL\nVal   - R¬≤: -8.1395 | Correlation: -0.2626\nVal   - Laplace LL: -9.789242 üéØ\nVal   - RMSE: 2377.5 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 8/30\nTrain - Loss: 9.449272 | MAE: 2426.6 mL\nVal   - Loss: 8.230248 | MAE: 2128.4 mL\nVal   - R¬≤: -7.3071 | Correlation: 0.1151\nVal   - Laplace LL: -9.440137 üéØ\nVal   - RMSE: 2266.7 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 9/30\nTrain - Loss: 9.391480 | MAE: 2280.3 mL\nVal   - Loss: 8.223007 | MAE: 1966.3 mL\nVal   - R¬≤: -6.2887 | Correlation: -0.5028\nVal   - Laplace LL: -9.341562 üéØ\nVal   - RMSE: 2123.2 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 10/30\nTrain - Loss: 9.199685 | MAE: 2101.8 mL\nVal   - Loss: 8.093060 | MAE: 1798.5 mL\nVal   - R¬≤: -5.1860 | Correlation: 0.4057\nVal   - Laplace LL: -9.341042 üéØ\nVal   - RMSE: 1956.0 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 11/30\nTrain - Loss: 9.121422 | MAE: 1853.1 mL\nVal   - Loss: 7.799899 | MAE: 1534.2 mL\nVal   - R¬≤: -3.7643 | Correlation: 0.4628\nVal   - Laplace LL: -9.026866 üéØ\nVal   - RMSE: 1716.6 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 12/30\nTrain - Loss: 8.758810 | MAE: 1526.3 mL\nVal   - Loss: 7.632978 | MAE: 1191.5 mL\nVal   - R¬≤: -2.1888 | Correlation: 0.4509\nVal   - Laplace LL: -8.757050 üéØ\nVal   - RMSE: 1404.4 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 13/30\nTrain - Loss: 8.317267 | MAE: 1126.7 mL\nVal   - Loss: 7.127071 | MAE: 807.7 mL\nVal   - R¬≤: -0.8890 | Correlation: 0.2517\nVal   - Laplace LL: -8.185665 üéØ\nVal   - RMSE: 1080.9 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 14/30\nTrain - Loss: 8.095383 | MAE: 804.0 mL\nVal   - Loss: 6.884507 | MAE: 608.3 mL\nVal   - R¬≤: -0.0908 | Correlation: 0.7968\nVal   - Laplace LL: -7.949955 üéØ\nVal   - RMSE: 821.4 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 15/30\nTrain - Loss: 7.969329 | MAE: 637.8 mL\nVal   - Loss: 6.761545 | MAE: 478.6 mL\nVal   - R¬≤: 0.2983 | Correlation: 0.8669\nVal   - Laplace LL: -7.790924 üéØ\nVal   - RMSE: 658.8 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 16/30\nTrain - Loss: 7.899698 | MAE: 498.0 mL\nVal   - Loss: 6.714815 | MAE: 401.7 mL\nVal   - R¬≤: 0.4574 | Correlation: 0.8714\nVal   - Laplace LL: -7.639302 üéØ\nVal   - RMSE: 579.3 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 17/30\nTrain - Loss: 7.750191 | MAE: 441.8 mL\nVal   - Loss: 6.886021 | MAE: 360.5 mL\nVal   - R¬≤: 0.6217 | Correlation: 0.9088\nVal   - Laplace LL: -7.720009 üéØ\nVal   - RMSE: 483.7 mL\n------------------------------------------------------------\nEpoch 18/30\nTrain - Loss: 7.622718 | MAE: 392.9 mL\nVal   - Loss: 6.817686 | MAE: 359.9 mL\nVal   - R¬≤: 0.6898 | Correlation: 0.9446\nVal   - Laplace LL: -7.761696 üéØ\nVal   - RMSE: 438.0 mL\n------------------------------------------------------------\nEpoch 19/30\nTrain - Loss: 7.559010 | MAE: 387.8 mL\nVal   - Loss: 6.779141 | MAE: 342.9 mL\nVal   - R¬≤: 0.6575 | Correlation: 0.8969\nVal   - Laplace LL: -7.657681 üéØ\nVal   - RMSE: 460.3 mL\n------------------------------------------------------------\nEpoch 20/30\nTrain - Loss: 7.450092 | MAE: 381.8 mL\nVal   - Loss: 6.400335 | MAE: 267.3 mL\nVal   - R¬≤: 0.8155 | Correlation: 0.9415\nVal   - Laplace LL: -7.320960 üéØ\nVal   - RMSE: 337.8 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 21/30\nTrain - Loss: 7.451907 | MAE: 369.6 mL\nVal   - Loss: 6.538450 | MAE: 290.4 mL\nVal   - R¬≤: 0.7959 | Correlation: 0.9463\nVal   - Laplace LL: -7.458961 üéØ\nVal   - RMSE: 355.3 mL\n------------------------------------------------------------\nEpoch 22/30\nTrain - Loss: 7.732823 | MAE: 376.5 mL\nVal   - Loss: 6.538032 | MAE: 292.9 mL\nVal   - R¬≤: 0.7906 | Correlation: 0.9457\nVal   - Laplace LL: -7.465319 üéØ\nVal   - RMSE: 359.9 mL\n------------------------------------------------------------\nEpoch 23/30\nTrain - Loss: 7.435363 | MAE: 369.5 mL\nVal   - Loss: 6.330201 | MAE: 242.2 mL\nVal   - R¬≤: 0.8420 | Correlation: 0.9427\nVal   - Laplace LL: -7.224372 üéØ\nVal   - RMSE: 312.6 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 24/30\nTrain - Loss: 7.187570 | MAE: 378.3 mL\nVal   - Loss: 6.772543 | MAE: 288.5 mL\nVal   - R¬≤: 0.7851 | Correlation: 0.9277\nVal   - Laplace LL: -7.554183 üéØ\nVal   - RMSE: 364.5 mL\n------------------------------------------------------------\nEpoch 25/30\nTrain - Loss: 7.295136 | MAE: 356.7 mL\nVal   - Loss: 6.386492 | MAE: 259.7 mL\nVal   - R¬≤: 0.8092 | Correlation: 0.9440\nVal   - Laplace LL: -7.267075 üéØ\nVal   - RMSE: 343.5 mL\n------------------------------------------------------------\nEpoch 26/30\nTrain - Loss: 7.447204 | MAE: 354.1 mL\nVal   - Loss: 6.440166 | MAE: 254.9 mL\nVal   - R¬≤: 0.8200 | Correlation: 0.9306\nVal   - Laplace LL: -7.297576 üéØ\nVal   - RMSE: 333.7 mL\n------------------------------------------------------------\nEpoch 27/30\nTrain - Loss: 7.390135 | MAE: 353.7 mL\nVal   - Loss: 6.319900 | MAE: 263.4 mL\nVal   - R¬≤: 0.8147 | Correlation: 0.9402\nVal   - Laplace LL: -7.268272 üéØ\nVal   - RMSE: 338.6 mL\n------------------------------------------------------------\nEpoch 28/30\nTrain - Loss: 7.361809 | MAE: 358.5 mL\nVal   - Loss: 6.359122 | MAE: 261.8 mL\nVal   - R¬≤: 0.7992 | Correlation: 0.9399\nVal   - Laplace LL: -7.250670 üéØ\nVal   - RMSE: 352.4 mL\n------------------------------------------------------------\nEpoch 29/30\nTrain - Loss: 7.267698 | MAE: 360.1 mL\nVal   - Loss: 6.194027 | MAE: 215.3 mL\nVal   - R¬≤: 0.8498 | Correlation: 0.9377\nVal   - Laplace LL: -7.039012 üéØ\nVal   - RMSE: 304.8 mL\n‚úÖ New best model saved! (Best Laplace LL)\n------------------------------------------------------------\nEpoch 30/30\nTrain - Loss: 7.465452 | MAE: 357.8 mL\nVal   - Loss: 6.364793 | MAE: 271.4 mL\nVal   - R¬≤: 0.7968 | Correlation: 0.9170\nVal   - Laplace LL: -7.300376 üéØ\nVal   - RMSE: 354.5 mL\n------------------------------------------------------------\n\nüèÜ Training Summary:\n   Best Validation MAE: 215.329227\n   Best Laplace Log Likelihood: -7.039012\n\nüéØ Training completed!\n   Best MAE: 215.329227\n   Best Laplace LL: -7.039012\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"üéØ Key Changes:\nModel Saving Now Based on MAE (Research Standard)\n\nPrimary: Saves best MAE model (best_working_model_mae.pth)\nSecondary: Also saves best Laplace LL model (best_working_model_laplace.pth)\nBoth models available for comparison\nEasy Toggle Between Training Approaches\n\nSingle flag: USE_LAPLACE_LOSS = False or True (line ~650)\nNo more commenting/uncommenting multiple lines\nJust change one variable and re-run\nComprehensive Monitoring\n\nAll metrics tracked every epoch: MAE, RMSE, R¬≤, Correlation, Laplace LL\nClear printouts showing which model was saved\nLaplace LL always monitored (regardless of training loss)\nResearch Paper Ready\n\nMAE-based training (clinical interpretability)\nAll standard regression metrics reported\nLaplace LL included for competitive comparison\nEasy ablation study: compare MAE vs LLL training\n\n\n\nüî¨ How to Run Comparison Experiment:\nExperiment 1 (Current - Recommended):\n```\nUSE_LAPLACE_LOSS = False  # MAE-based training\n```\nRun ‚Üí Save results ‚Üí Note: MAE = X, Laplace LL = Y\n\nExperiment 2 (For Comparison):\n```\nUSE_LAPLACE_LOSS = True  # LLL-based training\n```\n\nRun ‚Üí Compare results ‚Üí Create comparison table\n\nüìä What You'll Get:\nBoth models saved every run:\n\nbest_working_model_mae.pth ‚Üê Use this for paper (primary)\nbest_working_model_laplace.pth ‚Üê For comparison (secondary)\nAll metrics reported:\n\nMAE (primary for papers)\nRMSE, R¬≤, Correlation (standard regression metrics)\nLaplace LL (competitive benchmark)\nPerfect for research papers: Clinically meaningful (MAE in mL) + competitively comparable (Laplace LL)! üéì","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport random\nfrom tqdm import tqdm \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom PIL import Image\nimport json\nfrom pathlib import Path\nimport joblib\nimport warnings\nimport pickle\nfrom typing import Dict, List, Tuple, Optional\nfrom scipy import ndimage\nfrom scipy.ndimage import binary_fill_holes, generate_binary_structure\nfrom skimage import measure, morphology\nfrom skimage.transform import resize\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed=42):\n    \"\"\"Ensure reproducibility across all random operations\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    \nseed_everything(42)\n\n# Configuration\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\n\n# GPU Configuration for P100\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Enable optimizations for GPU training\nif torch.cuda.is_available():\n    torch.backends.cudnn.benchmark = True  # Auto-tune for best performance on P100\n    torch.cuda.empty_cache()  # Clear cache before starting\n\nprint(\"üöÄ Fixed OSIC Model - Complete Working Version\")\nprint(\"=\" * 60)\nprint(f\"üì± Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"üî• GPU: {torch.cuda.get_device_name()}\")\n    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    print(f\"‚ö° CUDA Version: {torch.version.cuda}\")\n    print(f\"üöÄ cuDNN Benchmark: Enabled (P100 optimized)\")\nprint(\"=\" * 60)\n\n# Load Data\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\nprint(f\"Loaded dataset with shape: {train_df.shape}\")\n\ndef get_tab_features(df_row):\n    \"\"\"Extract tabular features (returns 4 features)\"\"\"\n    vector = [(df_row['Age'] - 30) / 30] \n    \n    # Sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(0)\n    else:\n        vector.append(1)\n    \n    # Smoking status encoding\n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([1, 1])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 1])\n    else:\n        vector.extend([1, 0])\n    return np.array(vector)\n\n# üîÑ NEW APPROACH: Visit-level FVC prediction\n# Instead of predicting one slope per patient, predict actual FVC at each visit\nprint(\"=\" * 60)\nprint(\"üìä Creating Visit-Level Dataset\")\nprint(\"=\" * 60)\n\nvisit_data = []\npatient_baselines = {}\n\n# First pass: collect baseline information for each patient\nfor patient in train_df['Patient'].unique():\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    if len(sub) > 0:\n        # Get baseline (first measurement)\n        baseline_fvc = sub.iloc[0]['FVC']\n        baseline_percent = sub.iloc[0]['Percent']\n        baseline_week = sub.iloc[0]['Weeks']\n        \n        patient_baselines[patient] = {\n            'baseline_fvc': baseline_fvc,\n            'baseline_percent': baseline_percent,\n            'baseline_week': baseline_week,\n            'tabular': get_tab_features(sub.iloc[0])\n        }\n\n# Second pass: create visit-level samples\nprint(\"Creating visit-level samples...\")\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    \n    if patient not in patient_baselines:\n        continue\n    \n    baseline_info = patient_baselines[patient]\n    \n    # Create one sample for each visit\n    for idx, row in sub.iterrows():\n        visit_data.append({\n            'Patient': patient,\n            'Week': row['Weeks'],\n            'FVC': row['FVC'],  # Target: actual FVC at this visit\n            'Percent': row['Percent'],\n            'Age': row['Age'],\n            'Sex': row['Sex'],\n            'SmokingStatus': row['SmokingStatus'],\n            \n            # Temporal features (NEW!)\n            'WeeksFromBaseline': row['Weeks'] - baseline_info['baseline_week'],\n            'BaselineFVC': baseline_info['baseline_fvc'],\n            'BaselinePercent': baseline_info['baseline_percent'],\n            \n            # Tabular features\n            'tabular_features': baseline_info['tabular']\n        })\n\nvisit_df = pd.DataFrame(visit_data)\n\nprint(f\"\\n‚úÖ Dataset created:\")\nprint(f\"   Total visits: {len(visit_df)}\")\nprint(f\"   Unique patients: {visit_df['Patient'].nunique()}\")\nprint(f\"   Avg visits per patient: {len(visit_df) / visit_df['Patient'].nunique():.1f}\")\nprint(f\"   FVC range: [{visit_df['FVC'].min():.0f}, {visit_df['FVC'].max():.0f}] mL\")\nprint(f\"   Weeks range: [{visit_df['WeeksFromBaseline'].min():.0f}, {visit_df['WeeksFromBaseline'].max():.0f}]\")\n\nclass MedicalAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                albu.Rotate(limit=15, p=0.7),\n                albu.HorizontalFlip(p=0.5),\n                albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),\n                albu.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n                albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n                albu.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n                albu.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n    \n    def __call__(self, image):\n        return self.transform(image=image)['image']\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_cat = torch.cat([avg_out, max_out], dim=1)\n        x_cat = self.conv1(x_cat)\n        return x * self.sigmoid(x_cat)\n\nclass WorkingDenseNetModel(nn.Module):\n    \"\"\"\n    üîÑ UPDATED: Now predicts absolute FVC values (not slopes)\n    \n    Input:\n    - CT scan: 3 x 512 x 512\n    - Tabular: 7 features (Age, Sex, Smoking, WeeksFromBaseline, BaselineFVC, BaselinePercent)\n    \n    Output:\n    - FVC prediction (mL)\n    - Uncertainty (log variance)\n    \"\"\"\n    \n    def __init__(self, tabular_dim=7, dropout_rate=0.4):  # Changed from 4 to 7\n        super(WorkingDenseNetModel, self).__init__()\n        \n        # DenseNet121 backbone\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        \n        # Spatial attention\n        self.spatial_attention = SpatialAttention()\n        \n        # Enhanced tabular processing\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        \n        # Cross-modal attention\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=1024, num_heads=8, dropout=0.2, batch_first=True\n        )\n        \n        # Initialize projection weight properly\n        self.tab_projection = nn.Linear(512, 1024)\n        \n        # Multi-modal fusion\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 512, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(768, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2)\n        )\n        \n        # Uncertainty quantification heads\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        \n        # Extract image features\n        img_features = self.features(images)\n        \n        # Apply spatial attention\n        img_features = self.spatial_attention(img_features)\n        \n        # Global average pooling\n        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n        img_features = img_features.view(batch_size, -1)\n        \n        # Process tabular data\n        tab_features = self.tabular_processor(tabular)\n        \n        # Cross-modal attention\n        img_expanded = img_features.unsqueeze(1)\n        tab_expanded = tab_features.unsqueeze(1)\n        \n        # Project tabular to same dimension for attention\n        tab_proj = self.tab_projection(tab_expanded)\n        \n        attended_img, _ = self.cross_attention(\n            img_expanded, tab_proj, tab_proj\n        )\n        attended_img = attended_img.squeeze(1)\n        \n        # Fusion\n        combined_features = torch.cat([attended_img, tab_features], dim=1)\n        fused_features = self.fusion_layer(combined_features)\n        \n        # Predict mean and log variance\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        \n        return mean_pred.squeeze(), log_var.squeeze()\n\nclass OSICVisitLevelDataset(Dataset):\n    \"\"\"\n    üîÑ NEW: Visit-level dataset for FVC prediction\n    \n    Each sample represents ONE visit (patient at specific timepoint):\n    - Input: CT scan + tabular + temporal features\n    - Target: FVC value at that visit\n    \"\"\"\n    \n    def __init__(self, visit_dataframe, data_dir, split='train', augment=True):\n        self.visit_df = visit_dataframe.reset_index(drop=True)\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augment = augment\n        self.augmentor = MedicalAugmentation(augment=augment)\n        \n        # Filter out problematic patients\n        problematic = ['ID00011637202177653955184', 'ID00052637202186188008618']\n        self.visit_df = self.visit_df[~self.visit_df['Patient'].isin(problematic)]\n        \n        # Prepare image paths for each patient (one CT per patient, used for all visits)\n        # üîÑ IMPROVEMENT: Store ALL slices, will select based on visit context\n        self.patient_images = {}\n        for patient in self.visit_df['Patient'].unique():\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = sorted([f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm'])\n                if image_files:\n                    # Store ALL slices instead of just middle one\n                    self.patient_images[patient] = image_files\n        \n        # Filter visits with available images\n        self.visit_df = self.visit_df[self.visit_df['Patient'].isin(self.patient_images.keys())]\n        \n        print(f\"Dataset {split}: {len(self.visit_df)} visits from {self.visit_df['Patient'].nunique()} patients\")\n    \n    def __len__(self):\n        return len(self.visit_df)\n    \n    def __getitem__(self, idx):\n        row = self.visit_df.iloc[idx]\n        patient = row['Patient']\n        \n        # üîÑ IMPROVED: Select slice based on temporal context\n        # Later visits might show more severe disease ‚Üí use different slices\n        image_files = self.patient_images[patient]\n        \n        if self.augment:\n            # Training: Add variety by randomly selecting from middle 60% of slices\n            start_idx = len(image_files) // 5\n            end_idx = len(image_files) * 4 // 5\n            selected_image = image_files[np.random.randint(start_idx, max(start_idx + 1, end_idx))]\n        else:\n            # Validation: Use consistent middle slice\n            selected_image = image_files[len(image_files) // 2]\n        \n        # Load and preprocess image\n        img = self.load_and_preprocess_dicom(selected_image)\n        \n        # Apply augmentations\n        img_tensor = self.augmentor(img)\n        \n        # üîÑ NEW: Enhanced tabular features with temporal information\n        tab_features = np.concatenate([\n            row['tabular_features'],  # Age, Sex, Smoking (4 features)\n            [(row['WeeksFromBaseline'] + 12) / 52],  # Normalized weeks (1 feature)\n            [row['BaselineFVC'] / 1000],  # Normalized baseline FVC (1 feature)\n            [row['BaselinePercent'] / 100]  # Baseline FVC % (1 feature)\n        ])  # Total: 7 features (was 4)\n        \n        tab_features = torch.tensor(tab_features, dtype=torch.float32)\n        \n        # üéØ NEW TARGET: Actual FVC value (not slope)\n        target_fvc = torch.tensor(row['FVC'], dtype=torch.float32)\n        \n        return img_tensor, tab_features, target_fvc, patient\n    \n    def load_and_preprocess_dicom(self, path):\n        \"\"\"Enhanced DICOM loading with better preprocessing\"\"\"\n        try:\n            # Load DICOM\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            \n            # Handle different DICOM formats\n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]\n            \n            # Resize to target size\n            img = cv2.resize(img, (512, 512))\n            \n            # Normalize to 0-255 range\n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            \n            # Convert to 3-channel\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            \n            return img\n            \n        except Exception as e:\n            print(f\"Error loading DICOM {path}: {e}\")\n            return np.zeros((512, 512, 3), dtype=np.uint8)\n\nclass SimpleTrainer:\n    \"\"\"\n    Simple trainer that works with any model structure\n    \n    üéØ RESEARCH PAPER CONFIGURATION:\n    - Primary metric: MAE (Mean Absolute Error) - standard for regression papers\n    - Secondary metric: Laplace LL (Log Likelihood) - for competitive comparison\n    - Model saving: Best MAE (recommended for publication)\n    \n    üìä TO TOGGLE TRAINING LOSS:\n    Set use_laplace_loss=True to train with Laplace LL instead of uncertainty loss\n    \"\"\"\n    \n    def __init__(self, model, device, lr=1e-4, use_laplace_loss=False):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.use_laplace_loss = use_laplace_loss  # üéØ Toggle between MAE and LLL training\n        self.best_val_mae = float('inf')\n        self.best_laplace_ll = float('-inf')\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"üéØ TRAINER CONFIGURATION\")\n        print(f\"{'='*60}\")\n        print(f\"Training Loss: {'Laplace Log Likelihood' if use_laplace_loss else 'Uncertainty Loss (MAE-based)'}\")\n        print(f\"Model Saving: Best MAE (Research Paper Standard)\")\n        print(f\"Monitoring: MAE, RMSE, R¬≤, Correlation, Laplace LL\")\n        print(f\"{'='*60}\\n\")\n        \n    def uncertainty_loss(self, mean_pred, log_var, targets, reduction='mean'):\n        \"\"\"Uncertainty-aware loss function\"\"\"\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        loss = 0.5 * (mse_loss / var + log_var)\n        \n        if reduction == 'mean':\n            return loss.mean()\n        return loss.sum()\n    \n    def laplace_log_likelihood(self, mean_pred, log_var, targets, return_tensor=False):\n        \"\"\"\n        Calculate Laplace Log Likelihood (OSIC competition metric)\n        \n        üéØ DUAL USE:\n        - Monitoring: return_tensor=False (default) ‚Üí returns scalar for logging\n        - Training: return_tensor=True ‚Üí returns tensor for backprop\n        \n        Higher is better (closer to 0 from negative)\n        \n        Formula: -‚àö2 * |pred - actual| / œÉ - log(‚àö2 * œÉ)\n        where œÉ = sqrt(exp(log_var)), clipped to minimum 70\n        \n        Competition Rule: Minimum œÉ = 70mL (cannot be more confident than ¬±70mL)\n        \"\"\"\n        sigma = torch.sqrt(torch.exp(log_var))\n        sigma_clipped = torch.clamp(sigma, min=70)  # Competition rule: min confidence = 70\n        \n        delta = torch.abs(mean_pred - targets)\n        \n        # Laplace log likelihood\n        ll = -np.sqrt(2) * delta / sigma_clipped - torch.log(np.sqrt(2) * sigma_clipped)\n        \n        if return_tensor:\n            return ll.mean()  # Return tensor for backprop\n        else:\n            return ll.mean().item()  # Return scalar for logging\n    \n    def calculate_r2_score(self, predictions, targets):\n        \"\"\"Calculate R¬≤ score\"\"\"\n        predictions = np.array(predictions)\n        targets = np.array(targets)\n        ss_res = np.sum((targets - predictions) ** 2)\n        ss_tot = np.sum((targets - np.mean(targets)) ** 2)\n        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n        return r2\n        \n    def train(self, train_loader, val_loader, epochs=30, patience=8):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=4, verbose=True\n        )\n        \n        # Mixed precision training for P100 speedup\n        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n        use_amp = torch.cuda.is_available()\n        \n        if use_amp:\n            print(\"‚ö° Mixed Precision Training ENABLED for P100\")\n        \n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            # Training phase\n            self.model.train()\n            train_loss = 0.0\n            train_mae = 0.0\n            train_batches = 0\n            \n            for batch_idx, (images, tabular, targets, _) in enumerate(train_loader):\n                try:\n                    images = images.to(self.device)\n                    tabular = tabular.to(self.device) \n                    targets = targets.to(self.device)\n                    \n                    optimizer.zero_grad()\n                    \n                    # Mixed precision forward pass\n                    if use_amp:\n                        with torch.cuda.amp.autocast():\n                            mean_pred, log_var = self.model(images, tabular)\n                            \n                            # üéØ AUTOMATIC LOSS SELECTION based on initialization flag\n                            if self.use_laplace_loss:\n                                # Option A: Train with Laplace LL (competition metric)\n                                loss = -self.laplace_log_likelihood(mean_pred, log_var, targets, return_tensor=True)\n                            else:\n                                # Option B: Train with Uncertainty Loss (MAE-based, research standard)\n                                loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                            \n                            mae = F.l1_loss(mean_pred, targets)\n                    else:\n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        # üéØ AUTOMATIC LOSS SELECTION based on initialization flag\n                        if self.use_laplace_loss:\n                            # Option A: Train with Laplace LL (competition metric)\n                            loss = -self.laplace_log_likelihood(mean_pred, log_var, targets, return_tensor=True)\n                        else:\n                            # Option B: Train with Uncertainty Loss (MAE-based, research standard)\n                            loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        \n                        mae = F.l1_loss(mean_pred, targets)\n                    \n                    # Mixed precision backward pass\n                    if use_amp:\n                        scaler.scale(loss).backward()\n                        scaler.unscale_(optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        loss.backward()\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_mae += mae.item()\n                    train_batches += 1\n                    \n                except Exception as e:\n                    print(f\"Error in training batch {batch_idx}: {e}\")\n                    continue\n            \n            # Validation phase\n            self.model.eval()\n            val_loss = 0.0\n            val_mae = 0.0\n            val_predictions = []\n            val_targets = []\n            \n            with torch.no_grad():\n                for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                    try:\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        \n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        mae = F.l1_loss(mean_pred, targets)\n                        \n                        val_loss += loss.item()\n                        val_mae += mae.item()\n                        \n                        val_predictions.extend(mean_pred.cpu().numpy())\n                        val_targets.extend(targets.cpu().numpy())\n                        \n                    except Exception as e:\n                        print(f\"Error in validation batch {batch_idx}: {e}\")\n                        continue\n            \n            # Calculate metrics\n            if train_batches > 0 and len(val_predictions) > 0:\n                avg_train_loss = train_loss / train_batches\n                avg_train_mae = train_mae / train_batches\n                avg_val_loss = val_loss / len(val_loader)\n                avg_val_mae = val_mae / len(val_loader)\n                \n                # Calculate R¬≤ score\n                train_r2 = self.calculate_r2_score(\n                    [p.item() for p in self.model(images, tabular)[0][-8:]] if train_batches > 0 else [],\n                    [t.item() for t in targets[-8:]] if train_batches > 0 else []\n                ) if train_batches > 0 else 0\n                \n                val_r2 = self.calculate_r2_score(val_predictions, val_targets)\n                \n                # Calculate Laplace Log Likelihood for validation\n                val_laplace_ll = 0.0\n                with torch.no_grad():\n                    for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        mean_pred, log_var = self.model(images, tabular)\n                        val_laplace_ll += self.laplace_log_likelihood(mean_pred, log_var, targets)\n                \n                avg_val_laplace = val_laplace_ll / len(val_loader)\n                \n                # Calculate correlation\n                val_corr = np.corrcoef(val_predictions, val_targets)[0, 1] if len(val_predictions) > 1 else 0\n                \n                print(f\"Epoch {epoch+1}/{epochs}\")\n                print(f\"Train - Loss: {avg_train_loss:.6f} | MAE: {avg_train_mae:.1f} mL\")\n                print(f\"Val   - Loss: {avg_val_loss:.6f} | MAE: {avg_val_mae:.1f} mL\")\n                print(f\"Val   - R¬≤: {val_r2:.4f} | Correlation: {val_corr:.4f}\")\n                print(f\"Val   - Laplace LL: {avg_val_laplace:.6f}\")\n                print(f\"Val   - RMSE: {np.sqrt(mean_squared_error(val_targets, val_predictions)):.1f} mL\")\n                \n                # Learning rate scheduling\n                scheduler.step(avg_val_mae)\n                \n                # üéØ RESEARCH PAPER APPROACH: Save based on MAE (primary metric)\n                # Also track Laplace LL for competitive comparison\n                \n                improved = False\n                \n                # Primary: Save best MAE model (research paper standard)\n                if avg_val_mae < self.best_val_mae:\n                    self.best_val_mae = avg_val_mae\n                    torch.save(self.model.state_dict(), 'best_working_model_mae.pth')\n                    print(f\"‚úÖ NEW BEST MAE! Model saved: {avg_val_mae:.1f} mL (Laplace LL: {avg_val_laplace:.4f})\")\n                    improved = True\n                    patience_counter = 0\n                \n                # Secondary: Also save best Laplace LL model (for comparison)\n                if avg_val_laplace > self.best_laplace_ll:\n                    self.best_laplace_ll = avg_val_laplace\n                    torch.save(self.model.state_dict(), 'best_working_model_laplace.pth')\n                    print(f\"üíæ Best Laplace LL model saved: {avg_val_laplace:.4f} (MAE: {avg_val_mae:.1f} mL)\")\n                    if not improved:\n                        patience_counter = 0\n                \n                if not improved and avg_val_laplace <= self.best_laplace_ll:\n                    patience_counter += 1\n                    \n                if patience_counter >= patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n                    \n                print(\"-\" * 60)\n        \n        print(f\"\\nüèÜ Training Summary:\")\n        print(f\"   Best Validation MAE: {self.best_val_mae:.6f}\")\n        print(f\"   Best Laplace Log Likelihood: {self.best_laplace_ll:.6f}\")\n        \n        return self.best_val_mae, self.best_laplace_ll\n\n# Main execution\ndef main():\n    print(\"üîÑ Creating data loaders...\")\n    print(\"=\" * 60)\n    \n    # üéØ PATIENT-LEVEL SPLIT (prevents data leakage!)\n    # All visits from same patient stay together\n    unique_patients = visit_df['Patient'].unique()\n    train_patients, val_patients = train_test_split(\n        unique_patients, \n        test_size=0.2, \n        random_state=42,\n        shuffle=True\n    )\n    \n    # Split visits by patient\n    train_visits = visit_df[visit_df['Patient'].isin(train_patients)]\n    val_visits = visit_df[visit_df['Patient'].isin(val_patients)]\n    \n    print(f\"üìä Data Split:\")\n    print(f\"   Train: {len(train_patients)} patients, {len(train_visits)} visits\")\n    print(f\"   Val:   {len(val_patients)} patients, {len(val_visits)} visits\")\n    print(f\"   Train FVC: {train_visits['FVC'].mean():.0f} ¬± {train_visits['FVC'].std():.0f} mL\")\n    print(f\"   Val FVC:   {val_visits['FVC'].mean():.0f} ¬± {val_visits['FVC'].std():.0f} mL\")\n    print(\"=\" * 60)\n    \n    # Create datasets\n    train_dataset = OSICVisitLevelDataset(\n        visit_dataframe=train_visits,\n        data_dir=TRAIN_DIR,\n        split='train',\n        augment=True\n    )\n    \n    val_dataset = OSICVisitLevelDataset(\n        visit_dataframe=val_visits,\n        data_dir=TRAIN_DIR,\n        split='val',\n        augment=False\n    )\n    \n    # Create data loaders optimized for P100\n    # P100 has 16GB memory - can handle larger batches\n    batch_size = 16 if torch.cuda.is_available() else 8\n    num_workers = 4 if torch.cuda.is_available() else 2  # P100 benefits from more workers\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=True,\n        persistent_workers=True if num_workers > 0 else False  # Keep workers alive\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=False,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    \n    print(f\"‚úÖ Data loaders created!\")\n    print(f\"   Batch size: {batch_size} (P100 optimized)\")\n    print(f\"   Train batches: {len(train_loader)}\")\n    print(f\"   Val batches: {len(val_loader)}\")\n    print(f\"   Workers: {num_workers}\")\n    \n    # Initialize model\n    print(\"üîÑ Initializing model...\")\n    model = WorkingDenseNetModel(tabular_dim=7).to(DEVICE)  # 7 features now\n    print(f\"‚úÖ Model initialized!\")\n    print(f\"üìä Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    print(f\"üìä Output: FVC value (mL) + uncertainty\")\n    \n    # Test model with actual batch\n    try:\n        test_batch = next(iter(train_loader))\n        images, tabular, targets, _ = test_batch\n        images = images.to(DEVICE)\n        tabular = tabular.to(DEVICE)\n        \n        print(f\"üîç Testing model...\")\n        with torch.no_grad():\n            mean_pred, log_var = model(images, tabular)\n            print(f\"‚úÖ Model forward pass successful!\")\n            \n    except Exception as e:\n        print(f\"‚ùå Model test failed: {e}\")\n        return\n    \n    # üéØ TRAINING CONFIGURATION\n    # Toggle between MAE-based (uncertainty_loss) and LLL-based training\n    \n    # ============================================================\n    # üìä OPTION 1: MAE-Based Training (RECOMMENDED FOR PAPERS)\n    # ============================================================\n    USE_LAPLACE_LOSS = False  # ‚Üê Set to True to train with Laplace LL instead\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"üéØ TRAINING CONFIGURATION FOR RESEARCH PAPER\")\n    print(\"=\"*60)\n    print(f\"Training Loss: {'Laplace Log Likelihood' if USE_LAPLACE_LOSS else 'Uncertainty Loss (MAE-based)'}\")\n    print(f\"Model Saving: Best MAE (primary) + Best Laplace LL (secondary)\")\n    print(f\"Monitoring: All metrics (MAE, RMSE, R¬≤, Correlation, Laplace LL)\")\n    print(\"=\"*60 + \"\\n\")\n    \n    # Create trainer and start training\n    print(\"üöÄ Starting training...\")\n    trainer = SimpleTrainer(model, DEVICE, lr=1e-4, use_laplace_loss=USE_LAPLACE_LOSS)\n    \n    best_val_mae, best_laplace_ll = trainer.train(\n        train_loader, \n        val_loader, \n        epochs=30,\n        patience=8\n    )\n    \n    print(f\"\\nüéØ Training completed!\")\n    print(f\"   Best MAE: {best_val_mae:.6f}\")\n    print(f\"   Best Laplace LL: {best_laplace_ll:.6f}\")\n    \n    return model, train_loader, val_loader, best_val_mae, best_laplace_ll\n\nif __name__ == \"__main__\":\n    model, train_loader, val_loader, best_val_mae, best_laplace_ll = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T13:28:44.411330Z","iopub.execute_input":"2025-10-10T13:28:44.411962Z","iopub.status.idle":"2025-10-10T13:47:01.790766Z","shell.execute_reply.started":"2025-10-10T13:28:44.411934Z","shell.execute_reply":"2025-10-10T13:47:01.789983Z"}},"outputs":[{"name":"stdout","text":"üöÄ Fixed OSIC Model - Complete Working Version\n============================================================\nüì± Device: cuda\nüî• GPU: Tesla P100-PCIE-16GB\nüíæ Memory: 17.1 GB\n‚ö° CUDA Version: 12.4\nüöÄ cuDNN Benchmark: Enabled (P100 optimized)\n============================================================\nLoaded dataset with shape: (1549, 7)\n============================================================\nüìä Creating Visit-Level Dataset\n============================================================\nCreating visit-level samples...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 968.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Dataset created:\n   Total visits: 1549\n   Unique patients: 176\n   Avg visits per patient: 8.8\n   FVC range: [827, 6399] mL\n   Weeks range: [0, 63]\nüîÑ Creating data loaders...\n============================================================\nüìä Data Split:\n   Train: 140 patients, 1233 visits\n   Val:   36 patients, 316 visits\n   Train FVC: 2744 ¬± 836 mL\n   Val FVC:   2480 ¬± 788 mL\n============================================================\nDataset train: 1217 visits from 138 patients\nDataset val: 316 visits from 36 patients\n‚úÖ Data loaders created!\n   Batch size: 16 (P100 optimized)\n   Train batches: 76\n   Val batches: 20\n   Workers: 4\nüîÑ Initializing model...\n‚úÖ Model initialized!\nüìä Total parameters: 13,282,148\nüìä Output: FVC value (mL) + uncertainty\nüîç Testing model...\n‚úÖ Model forward pass successful!\n\n============================================================\nüéØ TRAINING CONFIGURATION FOR RESEARCH PAPER\n============================================================\nTraining Loss: Uncertainty Loss (MAE-based)\nModel Saving: Best MAE (primary) + Best Laplace LL (secondary)\nMonitoring: All metrics (MAE, RMSE, R¬≤, Correlation, Laplace LL)\n============================================================\n\nüöÄ Starting training...\n\n============================================================\nüéØ TRAINER CONFIGURATION\n============================================================\nTraining Loss: Uncertainty Loss (MAE-based)\nModel Saving: Best MAE (Research Paper Standard)\nMonitoring: MAE, RMSE, R¬≤, Correlation, Laplace LL\n============================================================\n\n‚ö° Mixed Precision Training ENABLED for P100\nEpoch 1/30\nTrain - Loss: 3183998.843750 | MAE: 2742.3 mL\nVal   - Loss: 1634427.425000 | MAE: 2481.2 mL\nVal   - R¬≤: -9.9408 | Correlation: 0.0776\nVal   - Laplace LL: -54.723586\nVal   - RMSE: 2601.3 mL\n‚úÖ NEW BEST MAE! Model saved: 2481.2 mL (Laplace LL: -54.7236)\nüíæ Best Laplace LL model saved: -54.7236 (MAE: 2481.2 mL)\n------------------------------------------------------------\nEpoch 2/30\nTrain - Loss: 593483.791118 | MAE: 2739.9 mL\nVal   - Loss: 272487.904297 | MAE: 2477.0 mL\nVal   - R¬≤: -9.9064 | Correlation: 0.1708\nVal   - Laplace LL: -54.637395\nVal   - RMSE: 2597.2 mL\n‚úÖ NEW BEST MAE! Model saved: 2477.0 mL (Laplace LL: -54.6374)\nüíæ Best Laplace LL model saved: -54.6374 (MAE: 2477.0 mL)\n------------------------------------------------------------\nEpoch 3/30\nTrain - Loss: 79457.173597 | MAE: 2731.0 mL\nVal   - Loss: 36110.401953 | MAE: 2465.5 mL\nVal   - R¬≤: -9.8137 | Correlation: 0.3049\nVal   - Laplace LL: -54.404741\nVal   - RMSE: 2586.1 mL\n‚úÖ NEW BEST MAE! Model saved: 2465.5 mL (Laplace LL: -54.4047)\nüíæ Best Laplace LL model saved: -54.4047 (MAE: 2465.5 mL)\n------------------------------------------------------------\nEpoch 4/30\nTrain - Loss: 9373.033033 | MAE: 2711.1 mL\nVal   - Loss: 3724.724884 | MAE: 2441.4 mL\nVal   - R¬≤: -9.6228 | Correlation: 0.1691\nVal   - Laplace LL: -53.770244\nVal   - RMSE: 2563.2 mL\n‚úÖ NEW BEST MAE! Model saved: 2441.4 mL (Laplace LL: -53.7702)\nüíæ Best Laplace LL model saved: -53.7702 (MAE: 2441.4 mL)\n------------------------------------------------------------\nEpoch 5/30\nTrain - Loss: 963.786462 | MAE: 2674.7 mL\nVal   - Loss: 163.350028 | MAE: 2395.4 mL\nVal   - R¬≤: -9.2730 | Correlation: -0.7992\nVal   - Laplace LL: -29.561902\nVal   - RMSE: 2520.6 mL\n‚úÖ NEW BEST MAE! Model saved: 2395.4 mL (Laplace LL: -29.5619)\nüíæ Best Laplace LL model saved: -29.5619 (MAE: 2395.4 mL)\n------------------------------------------------------------\nEpoch 6/30\nTrain - Loss: 86.094361 | MAE: 2621.1 mL\nVal   - Loss: 20.045151 | MAE: 2336.3 mL\nVal   - R¬≤: -8.8092 | Correlation: 0.3508\nVal   - Laplace LL: -13.742822\nVal   - RMSE: 2463.1 mL\n‚úÖ NEW BEST MAE! Model saved: 2336.3 mL (Laplace LL: -13.7428)\nüíæ Best Laplace LL model saved: -13.7428 (MAE: 2336.3 mL)\n------------------------------------------------------------\nEpoch 7/30\nTrain - Loss: 14.119582 | MAE: 2538.7 mL\nVal   - Loss: 8.643306 | MAE: 2243.9 mL\nVal   - R¬≤: -8.1395 | Correlation: -0.2626\nVal   - Laplace LL: -9.789242\nVal   - RMSE: 2377.5 mL\n‚úÖ NEW BEST MAE! Model saved: 2243.9 mL (Laplace LL: -9.7892)\nüíæ Best Laplace LL model saved: -9.7892 (MAE: 2243.9 mL)\n------------------------------------------------------------\nEpoch 8/30\nTrain - Loss: 9.449272 | MAE: 2426.6 mL\nVal   - Loss: 8.230248 | MAE: 2128.4 mL\nVal   - R¬≤: -7.3071 | Correlation: 0.1151\nVal   - Laplace LL: -9.440137\nVal   - RMSE: 2266.7 mL\n‚úÖ NEW BEST MAE! Model saved: 2128.4 mL (Laplace LL: -9.4401)\nüíæ Best Laplace LL model saved: -9.4401 (MAE: 2128.4 mL)\n------------------------------------------------------------\nEpoch 9/30\nTrain - Loss: 9.391480 | MAE: 2280.3 mL\nVal   - Loss: 8.223007 | MAE: 1966.3 mL\nVal   - R¬≤: -6.2887 | Correlation: -0.5028\nVal   - Laplace LL: -9.341562\nVal   - RMSE: 2123.2 mL\n‚úÖ NEW BEST MAE! Model saved: 1966.3 mL (Laplace LL: -9.3416)\nüíæ Best Laplace LL model saved: -9.3416 (MAE: 1966.3 mL)\n------------------------------------------------------------\nEpoch 10/30\nTrain - Loss: 9.199685 | MAE: 2101.8 mL\nVal   - Loss: 8.093060 | MAE: 1798.5 mL\nVal   - R¬≤: -5.1860 | Correlation: 0.4057\nVal   - Laplace LL: -9.341042\nVal   - RMSE: 1956.0 mL\n‚úÖ NEW BEST MAE! Model saved: 1798.5 mL (Laplace LL: -9.3410)\nüíæ Best Laplace LL model saved: -9.3410 (MAE: 1798.5 mL)\n------------------------------------------------------------\nEpoch 11/30\nTrain - Loss: 9.121422 | MAE: 1853.1 mL\nVal   - Loss: 7.799899 | MAE: 1534.2 mL\nVal   - R¬≤: -3.7643 | Correlation: 0.4628\nVal   - Laplace LL: -9.026866\nVal   - RMSE: 1716.6 mL\n‚úÖ NEW BEST MAE! Model saved: 1534.2 mL (Laplace LL: -9.0269)\nüíæ Best Laplace LL model saved: -9.0269 (MAE: 1534.2 mL)\n------------------------------------------------------------\nEpoch 12/30\nTrain - Loss: 8.758810 | MAE: 1526.3 mL\nVal   - Loss: 7.632978 | MAE: 1191.5 mL\nVal   - R¬≤: -2.1888 | Correlation: 0.4509\nVal   - Laplace LL: -8.757050\nVal   - RMSE: 1404.4 mL\n‚úÖ NEW BEST MAE! Model saved: 1191.5 mL (Laplace LL: -8.7571)\nüíæ Best Laplace LL model saved: -8.7571 (MAE: 1191.5 mL)\n------------------------------------------------------------\nEpoch 13/30\nTrain - Loss: 8.317267 | MAE: 1126.7 mL\nVal   - Loss: 7.127071 | MAE: 807.7 mL\nVal   - R¬≤: -0.8890 | Correlation: 0.2517\nVal   - Laplace LL: -8.185665\nVal   - RMSE: 1080.9 mL\n‚úÖ NEW BEST MAE! Model saved: 807.7 mL (Laplace LL: -8.1857)\nüíæ Best Laplace LL model saved: -8.1857 (MAE: 807.7 mL)\n------------------------------------------------------------\nEpoch 14/30\nTrain - Loss: 8.095383 | MAE: 804.0 mL\nVal   - Loss: 6.884507 | MAE: 608.3 mL\nVal   - R¬≤: -0.0908 | Correlation: 0.7968\nVal   - Laplace LL: -7.949955\nVal   - RMSE: 821.4 mL\n‚úÖ NEW BEST MAE! Model saved: 608.3 mL (Laplace LL: -7.9500)\nüíæ Best Laplace LL model saved: -7.9500 (MAE: 608.3 mL)\n------------------------------------------------------------\nEpoch 15/30\nTrain - Loss: 7.969329 | MAE: 637.8 mL\nVal   - Loss: 6.761545 | MAE: 478.6 mL\nVal   - R¬≤: 0.2983 | Correlation: 0.8669\nVal   - Laplace LL: -7.790924\nVal   - RMSE: 658.8 mL\n‚úÖ NEW BEST MAE! Model saved: 478.6 mL (Laplace LL: -7.7909)\nüíæ Best Laplace LL model saved: -7.7909 (MAE: 478.6 mL)\n------------------------------------------------------------\nEpoch 16/30\nTrain - Loss: 7.899698 | MAE: 498.0 mL\nVal   - Loss: 6.714815 | MAE: 401.7 mL\nVal   - R¬≤: 0.4574 | Correlation: 0.8714\nVal   - Laplace LL: -7.639302\nVal   - RMSE: 579.3 mL\n‚úÖ NEW BEST MAE! Model saved: 401.7 mL (Laplace LL: -7.6393)\nüíæ Best Laplace LL model saved: -7.6393 (MAE: 401.7 mL)\n------------------------------------------------------------\nEpoch 17/30\nTrain - Loss: 7.750191 | MAE: 441.8 mL\nVal   - Loss: 6.886021 | MAE: 360.5 mL\nVal   - R¬≤: 0.6217 | Correlation: 0.9088\nVal   - Laplace LL: -7.720009\nVal   - RMSE: 483.7 mL\n‚úÖ NEW BEST MAE! Model saved: 360.5 mL (Laplace LL: -7.7200)\n------------------------------------------------------------\nEpoch 18/30\nTrain - Loss: 7.622718 | MAE: 392.9 mL\nVal   - Loss: 6.817686 | MAE: 359.9 mL\nVal   - R¬≤: 0.6898 | Correlation: 0.9446\nVal   - Laplace LL: -7.761696\nVal   - RMSE: 438.0 mL\n‚úÖ NEW BEST MAE! Model saved: 359.9 mL (Laplace LL: -7.7617)\n------------------------------------------------------------\nEpoch 19/30\nTrain - Loss: 7.559010 | MAE: 387.8 mL\nVal   - Loss: 6.779141 | MAE: 342.9 mL\nVal   - R¬≤: 0.6575 | Correlation: 0.8969\nVal   - Laplace LL: -7.657681\nVal   - RMSE: 460.3 mL\n‚úÖ NEW BEST MAE! Model saved: 342.9 mL (Laplace LL: -7.6577)\n------------------------------------------------------------\nEpoch 20/30\nTrain - Loss: 7.450092 | MAE: 381.8 mL\nVal   - Loss: 6.400335 | MAE: 267.3 mL\nVal   - R¬≤: 0.8155 | Correlation: 0.9415\nVal   - Laplace LL: -7.320960\nVal   - RMSE: 337.8 mL\n‚úÖ NEW BEST MAE! Model saved: 267.3 mL (Laplace LL: -7.3210)\nüíæ Best Laplace LL model saved: -7.3210 (MAE: 267.3 mL)\n------------------------------------------------------------\nEpoch 21/30\nTrain - Loss: 7.451907 | MAE: 369.6 mL\nVal   - Loss: 6.538450 | MAE: 290.4 mL\nVal   - R¬≤: 0.7959 | Correlation: 0.9463\nVal   - Laplace LL: -7.458961\nVal   - RMSE: 355.3 mL\n------------------------------------------------------------\nEpoch 22/30\nTrain - Loss: 7.732823 | MAE: 376.5 mL\nVal   - Loss: 6.538032 | MAE: 292.9 mL\nVal   - R¬≤: 0.7906 | Correlation: 0.9457\nVal   - Laplace LL: -7.465319\nVal   - RMSE: 359.9 mL\n------------------------------------------------------------\nEpoch 23/30\nTrain - Loss: 7.435363 | MAE: 369.5 mL\nVal   - Loss: 6.330201 | MAE: 242.2 mL\nVal   - R¬≤: 0.8420 | Correlation: 0.9427\nVal   - Laplace LL: -7.224372\nVal   - RMSE: 312.6 mL\n‚úÖ NEW BEST MAE! Model saved: 242.2 mL (Laplace LL: -7.2244)\nüíæ Best Laplace LL model saved: -7.2244 (MAE: 242.2 mL)\n------------------------------------------------------------\nEpoch 24/30\nTrain - Loss: 7.187570 | MAE: 378.3 mL\nVal   - Loss: 6.772543 | MAE: 288.5 mL\nVal   - R¬≤: 0.7851 | Correlation: 0.9277\nVal   - Laplace LL: -7.554183\nVal   - RMSE: 364.5 mL\n------------------------------------------------------------\nEpoch 25/30\nTrain - Loss: 7.295136 | MAE: 356.7 mL\nVal   - Loss: 6.386492 | MAE: 259.7 mL\nVal   - R¬≤: 0.8092 | Correlation: 0.9440\nVal   - Laplace LL: -7.267075\nVal   - RMSE: 343.5 mL\n------------------------------------------------------------\nEpoch 26/30\nTrain - Loss: 7.447204 | MAE: 354.1 mL\nVal   - Loss: 6.440166 | MAE: 254.9 mL\nVal   - R¬≤: 0.8200 | Correlation: 0.9306\nVal   - Laplace LL: -7.297576\nVal   - RMSE: 333.7 mL\n------------------------------------------------------------\nEpoch 27/30\nTrain - Loss: 7.390135 | MAE: 353.7 mL\nVal   - Loss: 6.319900 | MAE: 263.4 mL\nVal   - R¬≤: 0.8147 | Correlation: 0.9402\nVal   - Laplace LL: -7.268272\nVal   - RMSE: 338.6 mL\n------------------------------------------------------------\nEpoch 28/30\nTrain - Loss: 7.361809 | MAE: 358.5 mL\nVal   - Loss: 6.359122 | MAE: 261.8 mL\nVal   - R¬≤: 0.7992 | Correlation: 0.9399\nVal   - Laplace LL: -7.250670\nVal   - RMSE: 352.4 mL\n------------------------------------------------------------\nEpoch 29/30\nTrain - Loss: 7.267698 | MAE: 360.1 mL\nVal   - Loss: 6.194027 | MAE: 215.3 mL\nVal   - R¬≤: 0.8498 | Correlation: 0.9377\nVal   - Laplace LL: -7.039012\nVal   - RMSE: 304.8 mL\n‚úÖ NEW BEST MAE! Model saved: 215.3 mL (Laplace LL: -7.0390)\nüíæ Best Laplace LL model saved: -7.0390 (MAE: 215.3 mL)\n------------------------------------------------------------\nEpoch 30/30\nTrain - Loss: 7.465452 | MAE: 357.8 mL\nVal   - Loss: 6.364793 | MAE: 271.4 mL\nVal   - R¬≤: 0.7968 | Correlation: 0.9170\nVal   - Laplace LL: -7.300376\nVal   - RMSE: 354.5 mL\n------------------------------------------------------------\n\nüèÜ Training Summary:\n   Best Validation MAE: 215.329227\n   Best Laplace Log Likelihood: -7.039012\n\nüéØ Training completed!\n   Best MAE: 215.329227\n   Best Laplace LL: -7.039012\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"now using LLL","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport pydicom\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport random\nfrom tqdm import tqdm \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom PIL import Image\nimport json\nfrom pathlib import Path\nimport joblib\nimport warnings\nimport pickle\nfrom typing import Dict, List, Tuple, Optional\nfrom scipy import ndimage\nfrom scipy.ndimage import binary_fill_holes, generate_binary_structure\nfrom skimage import measure, morphology\nfrom skimage.transform import resize\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nwarnings.filterwarnings('ignore')\n\ndef seed_everything(seed=42):\n    \"\"\"Ensure reproducibility across all random operations\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    \nseed_everything(42)\n\n# Configuration\nDATA_DIR = Path(\"../input/osic-pulmonary-fibrosis-progression\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\n\n# GPU Configuration for P100\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Enable optimizations for GPU training\nif torch.cuda.is_available():\n    torch.backends.cudnn.benchmark = True  # Auto-tune for best performance on P100\n    torch.cuda.empty_cache()  # Clear cache before starting\n\nprint(\"üöÄ Fixed OSIC Model - Complete Working Version\")\nprint(\"=\" * 60)\nprint(f\"üì± Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"üî• GPU: {torch.cuda.get_device_name()}\")\n    print(f\"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    print(f\"‚ö° CUDA Version: {torch.version.cuda}\")\n    print(f\"üöÄ cuDNN Benchmark: Enabled (P100 optimized)\")\nprint(\"=\" * 60)\n\n# Load Data\ntrain_df = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\nprint(f\"Loaded dataset with shape: {train_df.shape}\")\n\ndef get_tab_features(df_row):\n    \"\"\"Extract tabular features (returns 4 features)\"\"\"\n    vector = [(df_row['Age'] - 30) / 30] \n    \n    # Sex encoding\n    if df_row['Sex'] == 'Male':\n        vector.append(0)\n    else:\n        vector.append(1)\n    \n    # Smoking status encoding\n    smoking_status = df_row['SmokingStatus']\n    if smoking_status == 'Never smoked':\n        vector.extend([0, 0])\n    elif smoking_status == 'Ex-smoker':\n        vector.extend([1, 1])\n    elif smoking_status == 'Currently smokes':\n        vector.extend([0, 1])\n    else:\n        vector.extend([1, 0])\n    return np.array(vector)\n\n# üîÑ NEW APPROACH: Visit-level FVC prediction\n# Instead of predicting one slope per patient, predict actual FVC at each visit\nprint(\"=\" * 60)\nprint(\"üìä Creating Visit-Level Dataset\")\nprint(\"=\" * 60)\n\nvisit_data = []\npatient_baselines = {}\n\n# First pass: collect baseline information for each patient\nfor patient in train_df['Patient'].unique():\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    if len(sub) > 0:\n        # Get baseline (first measurement)\n        baseline_fvc = sub.iloc[0]['FVC']\n        baseline_percent = sub.iloc[0]['Percent']\n        baseline_week = sub.iloc[0]['Weeks']\n        \n        patient_baselines[patient] = {\n            'baseline_fvc': baseline_fvc,\n            'baseline_percent': baseline_percent,\n            'baseline_week': baseline_week,\n            'tabular': get_tab_features(sub.iloc[0])\n        }\n\n# Second pass: create visit-level samples\nprint(\"Creating visit-level samples...\")\nfor patient in tqdm(train_df['Patient'].unique()):\n    sub = train_df[train_df['Patient'] == patient].copy().sort_values('Weeks')\n    \n    if patient not in patient_baselines:\n        continue\n    \n    baseline_info = patient_baselines[patient]\n    \n    # Create one sample for each visit\n    for idx, row in sub.iterrows():\n        visit_data.append({\n            'Patient': patient,\n            'Week': row['Weeks'],\n            'FVC': row['FVC'],  # Target: actual FVC at this visit\n            'Percent': row['Percent'],\n            'Age': row['Age'],\n            'Sex': row['Sex'],\n            'SmokingStatus': row['SmokingStatus'],\n            \n            # Temporal features (NEW!)\n            'WeeksFromBaseline': row['Weeks'] - baseline_info['baseline_week'],\n            'BaselineFVC': baseline_info['baseline_fvc'],\n            'BaselinePercent': baseline_info['baseline_percent'],\n            \n            # Tabular features\n            'tabular_features': baseline_info['tabular']\n        })\n\nvisit_df = pd.DataFrame(visit_data)\n\nprint(f\"\\n‚úÖ Dataset created:\")\nprint(f\"   Total visits: {len(visit_df)}\")\nprint(f\"   Unique patients: {visit_df['Patient'].nunique()}\")\nprint(f\"   Avg visits per patient: {len(visit_df) / visit_df['Patient'].nunique():.1f}\")\nprint(f\"   FVC range: [{visit_df['FVC'].min():.0f}, {visit_df['FVC'].max():.0f}] mL\")\nprint(f\"   Weeks range: [{visit_df['WeeksFromBaseline'].min():.0f}, {visit_df['WeeksFromBaseline'].max():.0f}]\")\n\nclass MedicalAugmentation:\n    def __init__(self, augment=True):\n        if augment:\n            self.transform = albu.Compose([\n                albu.Rotate(limit=15, p=0.7),\n                albu.HorizontalFlip(p=0.5),\n                albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.7),\n                albu.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n                albu.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n                albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n                albu.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n                albu.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n        else:\n            self.transform = albu.Compose([\n                albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                ToTensorV2()\n            ])\n    \n    def __call__(self, image):\n        return self.transform(image=image)['image']\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_cat = torch.cat([avg_out, max_out], dim=1)\n        x_cat = self.conv1(x_cat)\n        return x * self.sigmoid(x_cat)\n\nclass WorkingDenseNetModel(nn.Module):\n    \"\"\"\n    üîÑ UPDATED: Now predicts absolute FVC values (not slopes)\n    \n    Input:\n    - CT scan: 3 x 512 x 512\n    - Tabular: 7 features (Age, Sex, Smoking, WeeksFromBaseline, BaselineFVC, BaselinePercent)\n    \n    Output:\n    - FVC prediction (mL)\n    - Uncertainty (log variance)\n    \"\"\"\n    \n    def __init__(self, tabular_dim=7, dropout_rate=0.4):  # Changed from 4 to 7\n        super(WorkingDenseNetModel, self).__init__()\n        \n        # DenseNet121 backbone\n        densenet = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n        self.features = densenet.features\n        \n        # Spatial attention\n        self.spatial_attention = SpatialAttention()\n        \n        # Enhanced tabular processing\n        self.tabular_processor = nn.Sequential(\n            nn.Linear(tabular_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU()\n        )\n        \n        # Cross-modal attention\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=1024, num_heads=8, dropout=0.2, batch_first=True\n        )\n        \n        # Initialize projection weight properly\n        self.tab_projection = nn.Linear(512, 1024)\n        \n        # Multi-modal fusion\n        self.fusion_layer = nn.Sequential(\n            nn.Linear(1024 + 512, 768),\n            nn.BatchNorm1d(768),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(768, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate/2)\n        )\n        \n        # Uncertainty quantification heads\n        self.mean_head = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n        self.log_var_head = nn.Sequential(\n            nn.Linear(256, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, images, tabular):\n        batch_size = images.size(0)\n        \n        # Extract image features\n        img_features = self.features(images)\n        \n        # Apply spatial attention\n        img_features = self.spatial_attention(img_features)\n        \n        # Global average pooling\n        img_features = F.adaptive_avg_pool2d(img_features, (1, 1))\n        img_features = img_features.view(batch_size, -1)\n        \n        # Process tabular data\n        tab_features = self.tabular_processor(tabular)\n        \n        # Cross-modal attention\n        img_expanded = img_features.unsqueeze(1)\n        tab_expanded = tab_features.unsqueeze(1)\n        \n        # Project tabular to same dimension for attention\n        tab_proj = self.tab_projection(tab_expanded)\n        \n        attended_img, _ = self.cross_attention(\n            img_expanded, tab_proj, tab_proj\n        )\n        attended_img = attended_img.squeeze(1)\n        \n        # Fusion\n        combined_features = torch.cat([attended_img, tab_features], dim=1)\n        fused_features = self.fusion_layer(combined_features)\n        \n        # Predict mean and log variance\n        mean_pred = self.mean_head(fused_features)\n        log_var = self.log_var_head(fused_features)\n        \n        return mean_pred.squeeze(), log_var.squeeze()\n\nclass OSICVisitLevelDataset(Dataset):\n    \"\"\"\n    üîÑ NEW: Visit-level dataset for FVC prediction\n    \n    Each sample represents ONE visit (patient at specific timepoint):\n    - Input: CT scan + tabular + temporal features\n    - Target: FVC value at that visit\n    \"\"\"\n    \n    def __init__(self, visit_dataframe, data_dir, split='train', augment=True):\n        self.visit_df = visit_dataframe.reset_index(drop=True)\n        self.data_dir = Path(data_dir)\n        self.split = split\n        self.augment = augment\n        self.augmentor = MedicalAugmentation(augment=augment)\n        \n        # Filter out problematic patients\n        problematic = ['ID00011637202177653955184', 'ID00052637202186188008618']\n        self.visit_df = self.visit_df[~self.visit_df['Patient'].isin(problematic)]\n        \n        # Prepare image paths for each patient (one CT per patient, used for all visits)\n        # üîÑ IMPROVEMENT: Store ALL slices, will select based on visit context\n        self.patient_images = {}\n        for patient in self.visit_df['Patient'].unique():\n            patient_dir = self.data_dir / patient\n            if patient_dir.exists():\n                image_files = sorted([f for f in patient_dir.iterdir() if f.suffix.lower() == '.dcm'])\n                if image_files:\n                    # Store ALL slices instead of just middle one\n                    self.patient_images[patient] = image_files\n        \n        # Filter visits with available images\n        self.visit_df = self.visit_df[self.visit_df['Patient'].isin(self.patient_images.keys())]\n        \n        print(f\"Dataset {split}: {len(self.visit_df)} visits from {self.visit_df['Patient'].nunique()} patients\")\n    \n    def __len__(self):\n        return len(self.visit_df)\n    \n    def __getitem__(self, idx):\n        row = self.visit_df.iloc[idx]\n        patient = row['Patient']\n        \n        # üîÑ IMPROVED: Select slice based on temporal context\n        # Later visits might show more severe disease ‚Üí use different slices\n        image_files = self.patient_images[patient]\n        \n        if self.augment:\n            # Training: Add variety by randomly selecting from middle 60% of slices\n            start_idx = len(image_files) // 5\n            end_idx = len(image_files) * 4 // 5\n            selected_image = image_files[np.random.randint(start_idx, max(start_idx + 1, end_idx))]\n        else:\n            # Validation: Use consistent middle slice\n            selected_image = image_files[len(image_files) // 2]\n        \n        # Load and preprocess image\n        img = self.load_and_preprocess_dicom(selected_image)\n        \n        # Apply augmentations\n        img_tensor = self.augmentor(img)\n        \n        # üîÑ NEW: Enhanced tabular features with temporal information\n        tab_features = np.concatenate([\n            row['tabular_features'],  # Age, Sex, Smoking (4 features)\n            [(row['WeeksFromBaseline'] + 12) / 52],  # Normalized weeks (1 feature)\n            [row['BaselineFVC'] / 1000],  # Normalized baseline FVC (1 feature)\n            [row['BaselinePercent'] / 100]  # Baseline FVC % (1 feature)\n        ])  # Total: 7 features (was 4)\n        \n        tab_features = torch.tensor(tab_features, dtype=torch.float32)\n        \n        # üéØ NEW TARGET: Actual FVC value (not slope)\n        target_fvc = torch.tensor(row['FVC'], dtype=torch.float32)\n        \n        return img_tensor, tab_features, target_fvc, patient\n    \n    def load_and_preprocess_dicom(self, path):\n        \"\"\"Enhanced DICOM loading with better preprocessing\"\"\"\n        try:\n            # Load DICOM\n            dcm = pydicom.dcmread(str(path))\n            img = dcm.pixel_array.astype(np.float32)\n            \n            # Handle different DICOM formats\n            if len(img.shape) == 3:\n                img = img[img.shape[0]//2]\n            \n            # Resize to target size\n            img = cv2.resize(img, (512, 512))\n            \n            # Normalize to 0-255 range\n            img_min, img_max = img.min(), img.max()\n            if img_max > img_min:\n                img = (img - img_min) / (img_max - img_min) * 255\n            else:\n                img = np.zeros_like(img)\n            \n            # Convert to 3-channel\n            img = np.stack([img, img, img], axis=2).astype(np.uint8)\n            \n            return img\n            \n        except Exception as e:\n            print(f\"Error loading DICOM {path}: {e}\")\n            return np.zeros((512, 512, 3), dtype=np.uint8)\n\nclass SimpleTrainer:\n    \"\"\"\n    Simple trainer that works with any model structure\n    \n    üéØ RESEARCH PAPER CONFIGURATION:\n    - Primary metric: MAE (Mean Absolute Error) - standard for regression papers\n    - Secondary metric: Laplace LL (Log Likelihood) - for competitive comparison\n    - Model saving: Best MAE (recommended for publication)\n    \n    üìä TO TOGGLE TRAINING LOSS:\n    Set use_laplace_loss=True to train with Laplace LL instead of uncertainty loss\n    \"\"\"\n    \n    def __init__(self, model, device, lr=1e-4, use_laplace_loss=True):\n        self.model = model\n        self.device = device\n        self.lr = lr\n        self.use_laplace_loss = use_laplace_loss  # üéØ Toggle between MAE and LLL training\n        self.best_val_mae = float('inf')\n        self.best_laplace_ll = float('-inf')\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"üéØ TRAINER CONFIGURATION\")\n        print(f\"{'='*60}\")\n        print(f\"Training Loss: {'Laplace Log Likelihood' if use_laplace_loss else 'Uncertainty Loss (MAE-based)'}\")\n        print(f\"Model Saving: Best MAE (Research Paper Standard)\")\n        print(f\"Monitoring: MAE, RMSE, R¬≤, Correlation, Laplace LL\")\n        print(f\"{'='*60}\\n\")\n        \n    def uncertainty_loss(self, mean_pred, log_var, targets, reduction='mean'):\n        \"\"\"Uncertainty-aware loss function\"\"\"\n        var = torch.exp(log_var)\n        mse_loss = (mean_pred - targets) ** 2\n        loss = 0.5 * (mse_loss / var + log_var)\n        \n        if reduction == 'mean':\n            return loss.mean()\n        return loss.sum()\n    \n    def laplace_log_likelihood(self, mean_pred, log_var, targets, return_tensor=False):\n        \"\"\"\n        Calculate Laplace Log Likelihood (OSIC competition metric)\n        \n        üéØ DUAL USE:\n        - Monitoring: return_tensor=False (default) ‚Üí returns scalar for logging\n        - Training: return_tensor=True ‚Üí returns tensor for backprop\n        \n        Higher is better (closer to 0 from negative)\n        \n        Formula: -‚àö2 * |pred - actual| / œÉ - log(‚àö2 * œÉ)\n        where œÉ = sqrt(exp(log_var)), clipped to minimum 70\n        \n        Competition Rule: Minimum œÉ = 70mL (cannot be more confident than ¬±70mL)\n        \"\"\"\n        sigma = torch.sqrt(torch.exp(log_var))\n        sigma_clipped = torch.clamp(sigma, min=70)  # Competition rule: min confidence = 70\n        \n        delta = torch.abs(mean_pred - targets)\n        \n        # Laplace log likelihood\n        ll = -np.sqrt(2) * delta / sigma_clipped - torch.log(np.sqrt(2) * sigma_clipped)\n        \n        if return_tensor:\n            return ll.mean()  # Return tensor for backprop\n        else:\n            return ll.mean().item()  # Return scalar for logging\n    \n    def calculate_r2_score(self, predictions, targets):\n        \"\"\"Calculate R¬≤ score\"\"\"\n        predictions = np.array(predictions)\n        targets = np.array(targets)\n        ss_res = np.sum((targets - predictions) ** 2)\n        ss_tot = np.sum((targets - np.mean(targets)) ** 2)\n        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n        return r2\n        \n    def train(self, train_loader, val_loader, epochs=30, patience=8):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=1e-4)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=4, verbose=True\n        )\n        \n        # Mixed precision training for P100 speedup\n        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n        use_amp = torch.cuda.is_available()\n        \n        if use_amp:\n            print(\"‚ö° Mixed Precision Training ENABLED for P100\")\n        \n        patience_counter = 0\n        \n        for epoch in range(epochs):\n            # Training phase\n            self.model.train()\n            train_loss = 0.0\n            train_mae = 0.0\n            train_batches = 0\n            \n            for batch_idx, (images, tabular, targets, _) in enumerate(train_loader):\n                try:\n                    images = images.to(self.device)\n                    tabular = tabular.to(self.device) \n                    targets = targets.to(self.device)\n                    \n                    optimizer.zero_grad()\n                    \n                    # Mixed precision forward pass\n                    if use_amp:\n                        with torch.cuda.amp.autocast():\n                            mean_pred, log_var = self.model(images, tabular)\n                            \n                            # üéØ AUTOMATIC LOSS SELECTION based on initialization flag\n                            if self.use_laplace_loss:\n                                # Option A: Train with Laplace LL (competition metric)\n                                loss = -self.laplace_log_likelihood(mean_pred, log_var, targets, return_tensor=True)\n                            else:\n                                # Option B: Train with Uncertainty Loss (MAE-based, research standard)\n                                loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                            \n                            mae = F.l1_loss(mean_pred, targets)\n                    else:\n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        # üéØ AUTOMATIC LOSS SELECTION based on initialization flag\n                        if self.use_laplace_loss:\n                            # Option A: Train with Laplace LL (competition metric)\n                            loss = -self.laplace_log_likelihood(mean_pred, log_var, targets, return_tensor=True)\n                        else:\n                            # Option B: Train with Uncertainty Loss (MAE-based, research standard)\n                            loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        \n                        mae = F.l1_loss(mean_pred, targets)\n                    \n                    # Mixed precision backward pass\n                    if use_amp:\n                        scaler.scale(loss).backward()\n                        scaler.unscale_(optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        scaler.step(optimizer)\n                        scaler.update()\n                    else:\n                        loss.backward()\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                        optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_mae += mae.item()\n                    train_batches += 1\n                    \n                except Exception as e:\n                    print(f\"Error in training batch {batch_idx}: {e}\")\n                    continue\n            \n            # Validation phase\n            self.model.eval()\n            val_loss = 0.0\n            val_mae = 0.0\n            val_predictions = []\n            val_targets = []\n            \n            with torch.no_grad():\n                for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                    try:\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        \n                        mean_pred, log_var = self.model(images, tabular)\n                        \n                        loss = self.uncertainty_loss(mean_pred, log_var, targets)\n                        mae = F.l1_loss(mean_pred, targets)\n                        \n                        val_loss += loss.item()\n                        val_mae += mae.item()\n                        \n                        val_predictions.extend(mean_pred.cpu().numpy())\n                        val_targets.extend(targets.cpu().numpy())\n                        \n                    except Exception as e:\n                        print(f\"Error in validation batch {batch_idx}: {e}\")\n                        continue\n            \n            # Calculate metrics\n            if train_batches > 0 and len(val_predictions) > 0:\n                avg_train_loss = train_loss / train_batches\n                avg_train_mae = train_mae / train_batches\n                avg_val_loss = val_loss / len(val_loader)\n                avg_val_mae = val_mae / len(val_loader)\n                \n                # Calculate R¬≤ score\n                train_r2 = self.calculate_r2_score(\n                    [p.item() for p in self.model(images, tabular)[0][-8:]] if train_batches > 0 else [],\n                    [t.item() for t in targets[-8:]] if train_batches > 0 else []\n                ) if train_batches > 0 else 0\n                \n                val_r2 = self.calculate_r2_score(val_predictions, val_targets)\n                \n                # Calculate Laplace Log Likelihood for validation\n                val_laplace_ll = 0.0\n                with torch.no_grad():\n                    for batch_idx, (images, tabular, targets, _) in enumerate(val_loader):\n                        images = images.to(self.device)\n                        tabular = tabular.to(self.device)\n                        targets = targets.to(self.device)\n                        mean_pred, log_var = self.model(images, tabular)\n                        val_laplace_ll += self.laplace_log_likelihood(mean_pred, log_var, targets)\n                \n                avg_val_laplace = val_laplace_ll / len(val_loader)\n                \n                # Calculate correlation\n                val_corr = np.corrcoef(val_predictions, val_targets)[0, 1] if len(val_predictions) > 1 else 0\n                \n                print(f\"Epoch {epoch+1}/{epochs}\")\n                print(f\"Train - Loss: {avg_train_loss:.6f} | MAE: {avg_train_mae:.1f} mL\")\n                print(f\"Val   - Loss: {avg_val_loss:.6f} | MAE: {avg_val_mae:.1f} mL\")\n                print(f\"Val   - R¬≤: {val_r2:.4f} | Correlation: {val_corr:.4f}\")\n                print(f\"Val   - Laplace LL: {avg_val_laplace:.6f}\")\n                print(f\"Val   - RMSE: {np.sqrt(mean_squared_error(val_targets, val_predictions)):.1f} mL\")\n                \n                # Learning rate scheduling\n                scheduler.step(avg_val_mae)\n                \n                # üéØ RESEARCH PAPER APPROACH: Save based on MAE (primary metric)\n                # Also track Laplace LL for competitive comparison\n                \n                improved = False\n                \n                # Primary: Save best MAE model (research paper standard)\n                if avg_val_mae < self.best_val_mae:\n                    self.best_val_mae = avg_val_mae\n                    torch.save(self.model.state_dict(), 'best_working_model_mae.pth')\n                    print(f\"‚úÖ NEW BEST MAE! Model saved: {avg_val_mae:.1f} mL (Laplace LL: {avg_val_laplace:.4f})\")\n                    improved = True\n                    patience_counter = 0\n                \n                # Secondary: Also save best Laplace LL model (for comparison)\n                if avg_val_laplace > self.best_laplace_ll:\n                    self.best_laplace_ll = avg_val_laplace\n                    torch.save(self.model.state_dict(), 'best_working_model_laplace.pth')\n                    print(f\"üíæ Best Laplace LL model saved: {avg_val_laplace:.4f} (MAE: {avg_val_mae:.1f} mL)\")\n                    if not improved:\n                        patience_counter = 0\n                \n                if not improved and avg_val_laplace <= self.best_laplace_ll:\n                    patience_counter += 1\n                    \n                if patience_counter >= patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n                    \n                print(\"-\" * 60)\n        \n        print(f\"\\nüèÜ Training Summary:\")\n        print(f\"   Best Validation MAE: {self.best_val_mae:.6f}\")\n        print(f\"   Best Laplace Log Likelihood: {self.best_laplace_ll:.6f}\")\n        \n        return self.best_val_mae, self.best_laplace_ll\n\n# Main execution\ndef main():\n    print(\"üîÑ Creating data loaders...\")\n    print(\"=\" * 60)\n    \n    # üéØ PATIENT-LEVEL SPLIT (prevents data leakage!)\n    # All visits from same patient stay together\n    unique_patients = visit_df['Patient'].unique()\n    train_patients, val_patients = train_test_split(\n        unique_patients, \n        test_size=0.2, \n        random_state=42,\n        shuffle=True\n    )\n    \n    # Split visits by patient\n    train_visits = visit_df[visit_df['Patient'].isin(train_patients)]\n    val_visits = visit_df[visit_df['Patient'].isin(val_patients)]\n    \n    print(f\"üìä Data Split:\")\n    print(f\"   Train: {len(train_patients)} patients, {len(train_visits)} visits\")\n    print(f\"   Val:   {len(val_patients)} patients, {len(val_visits)} visits\")\n    print(f\"   Train FVC: {train_visits['FVC'].mean():.0f} ¬± {train_visits['FVC'].std():.0f} mL\")\n    print(f\"   Val FVC:   {val_visits['FVC'].mean():.0f} ¬± {val_visits['FVC'].std():.0f} mL\")\n    print(\"=\" * 60)\n    \n    # Create datasets\n    train_dataset = OSICVisitLevelDataset(\n        visit_dataframe=train_visits,\n        data_dir=TRAIN_DIR,\n        split='train',\n        augment=True\n    )\n    \n    val_dataset = OSICVisitLevelDataset(\n        visit_dataframe=val_visits,\n        data_dir=TRAIN_DIR,\n        split='val',\n        augment=False\n    )\n    \n    # Create data loaders optimized for P100\n    # P100 has 16GB memory - can handle larger batches\n    batch_size = 16 if torch.cuda.is_available() else 8\n    num_workers = 4 if torch.cuda.is_available() else 2  # P100 benefits from more workers\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=True,\n        persistent_workers=True if num_workers > 0 else False  # Keep workers alive\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available() else False,\n        drop_last=False,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    \n    print(f\"‚úÖ Data loaders created!\")\n    print(f\"   Batch size: {batch_size} (P100 optimized)\")\n    print(f\"   Train batches: {len(train_loader)}\")\n    print(f\"   Val batches: {len(val_loader)}\")\n    print(f\"   Workers: {num_workers}\")\n    \n    # Initialize model\n    print(\"üîÑ Initializing model...\")\n    model = WorkingDenseNetModel(tabular_dim=7).to(DEVICE)  # 7 features now\n    print(f\"‚úÖ Model initialized!\")\n    print(f\"üìä Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    print(f\"üìä Output: FVC value (mL) + uncertainty\")\n    \n    # Test model with actual batch\n    try:\n        test_batch = next(iter(train_loader))\n        images, tabular, targets, _ = test_batch\n        images = images.to(DEVICE)\n        tabular = tabular.to(DEVICE)\n        \n        print(f\"üîç Testing model...\")\n        with torch.no_grad():\n            mean_pred, log_var = model(images, tabular)\n            print(f\"‚úÖ Model forward pass successful!\")\n            \n    except Exception as e:\n        print(f\"‚ùå Model test failed: {e}\")\n        return\n    \n    # üéØ TRAINING CONFIGURATION\n    # Toggle between MAE-based (uncertainty_loss) and LLL-based training\n    \n    # ============================================================\n    # üìä OPTION 1: MAE-Based Training (RECOMMENDED FOR PAPERS)\n    # ============================================================\n    USE_LAPLACE_LOSS = False  # ‚Üê Set to True to train with Laplace LL instead\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"üéØ TRAINING CONFIGURATION FOR RESEARCH PAPER\")\n    print(\"=\"*60)\n    print(f\"Training Loss: {'Laplace Log Likelihood' if USE_LAPLACE_LOSS else 'Uncertainty Loss (MAE-based)'}\")\n    print(f\"Model Saving: Best MAE (primary) + Best Laplace LL (secondary)\")\n    print(f\"Monitoring: All metrics (MAE, RMSE, R¬≤, Correlation, Laplace LL)\")\n    print(\"=\"*60 + \"\\n\")\n    \n    # Create trainer and start training\n    print(\"üöÄ Starting training...\")\n    trainer = SimpleTrainer(model, DEVICE, lr=1e-4, use_laplace_loss=USE_LAPLACE_LOSS)\n    \n    best_val_mae, best_laplace_ll = trainer.train(\n        train_loader, \n        val_loader, \n        epochs=30,\n        patience=8\n    )\n    \n    print(f\"\\nüéØ Training completed!\")\n    print(f\"   Best MAE: {best_val_mae:.6f}\")\n    print(f\"   Best Laplace LL: {best_laplace_ll:.6f}\")\n    \n    return model, train_loader, val_loader, best_val_mae, best_laplace_ll\n\nif __name__ == \"__main__\":\n    model, train_loader, val_loader, best_val_mae, best_laplace_ll = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-10T13:47:01.793212Z","iopub.execute_input":"2025-10-10T13:47:01.793448Z","iopub.status.idle":"2025-10-10T14:05:23.220491Z","shell.execute_reply.started":"2025-10-10T13:47:01.793417Z","shell.execute_reply":"2025-10-10T14:05:23.219719Z"}},"outputs":[{"name":"stdout","text":"üöÄ Fixed OSIC Model - Complete Working Version\n============================================================\nüì± Device: cuda\nüî• GPU: Tesla P100-PCIE-16GB\nüíæ Memory: 17.1 GB\n‚ö° CUDA Version: 12.4\nüöÄ cuDNN Benchmark: Enabled (P100 optimized)\n============================================================\nLoaded dataset with shape: (1549, 7)\n============================================================\nüìä Creating Visit-Level Dataset\n============================================================\nCreating visit-level samples...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:00<00:00, 868.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Dataset created:\n   Total visits: 1549\n   Unique patients: 176\n   Avg visits per patient: 8.8\n   FVC range: [827, 6399] mL\n   Weeks range: [0, 63]\nüîÑ Creating data loaders...\n============================================================\nüìä Data Split:\n   Train: 140 patients, 1233 visits\n   Val:   36 patients, 316 visits\n   Train FVC: 2744 ¬± 836 mL\n   Val FVC:   2480 ¬± 788 mL\n============================================================\nDataset train: 1217 visits from 138 patients\nDataset val: 316 visits from 36 patients\n‚úÖ Data loaders created!\n   Batch size: 16 (P100 optimized)\n   Train batches: 76\n   Val batches: 20\n   Workers: 4\nüîÑ Initializing model...\n‚úÖ Model initialized!\nüìä Total parameters: 13,282,148\nüìä Output: FVC value (mL) + uncertainty\nüîç Testing model...\n‚úÖ Model forward pass successful!\n\n============================================================\nüéØ TRAINING CONFIGURATION FOR RESEARCH PAPER\n============================================================\nTraining Loss: Uncertainty Loss (MAE-based)\nModel Saving: Best MAE (primary) + Best Laplace LL (secondary)\nMonitoring: All metrics (MAE, RMSE, R¬≤, Correlation, Laplace LL)\n============================================================\n\nüöÄ Starting training...\n\n============================================================\nüéØ TRAINER CONFIGURATION\n============================================================\nTraining Loss: Uncertainty Loss (MAE-based)\nModel Saving: Best MAE (Research Paper Standard)\nMonitoring: MAE, RMSE, R¬≤, Correlation, Laplace LL\n============================================================\n\n‚ö° Mixed Precision Training ENABLED for P100\nEpoch 1/30\nTrain - Loss: 3183998.843750 | MAE: 2742.3 mL\nVal   - Loss: 1634427.425000 | MAE: 2481.2 mL\nVal   - R¬≤: -9.9408 | Correlation: 0.0776\nVal   - Laplace LL: -54.723586\nVal   - RMSE: 2601.3 mL\n‚úÖ NEW BEST MAE! Model saved: 2481.2 mL (Laplace LL: -54.7236)\nüíæ Best Laplace LL model saved: -54.7236 (MAE: 2481.2 mL)\n------------------------------------------------------------\nEpoch 2/30\nTrain - Loss: 593483.791118 | MAE: 2739.9 mL\nVal   - Loss: 272487.904297 | MAE: 2477.0 mL\nVal   - R¬≤: -9.9064 | Correlation: 0.1708\nVal   - Laplace LL: -54.637395\nVal   - RMSE: 2597.2 mL\n‚úÖ NEW BEST MAE! Model saved: 2477.0 mL (Laplace LL: -54.6374)\nüíæ Best Laplace LL model saved: -54.6374 (MAE: 2477.0 mL)\n------------------------------------------------------------\nEpoch 3/30\nTrain - Loss: 79457.173597 | MAE: 2731.0 mL\nVal   - Loss: 36110.401953 | MAE: 2465.5 mL\nVal   - R¬≤: -9.8137 | Correlation: 0.3049\nVal   - Laplace LL: -54.404741\nVal   - RMSE: 2586.1 mL\n‚úÖ NEW BEST MAE! Model saved: 2465.5 mL (Laplace LL: -54.4047)\nüíæ Best Laplace LL model saved: -54.4047 (MAE: 2465.5 mL)\n------------------------------------------------------------\nEpoch 4/30\nTrain - Loss: 9373.033033 | MAE: 2711.1 mL\nVal   - Loss: 3724.724884 | MAE: 2441.4 mL\nVal   - R¬≤: -9.6228 | Correlation: 0.1691\nVal   - Laplace LL: -53.770244\nVal   - RMSE: 2563.2 mL\n‚úÖ NEW BEST MAE! Model saved: 2441.4 mL (Laplace LL: -53.7702)\nüíæ Best Laplace LL model saved: -53.7702 (MAE: 2441.4 mL)\n------------------------------------------------------------\nEpoch 5/30\nTrain - Loss: 963.786462 | MAE: 2674.7 mL\nVal   - Loss: 163.350028 | MAE: 2395.4 mL\nVal   - R¬≤: -9.2730 | Correlation: -0.7992\nVal   - Laplace LL: -29.561902\nVal   - RMSE: 2520.6 mL\n‚úÖ NEW BEST MAE! Model saved: 2395.4 mL (Laplace LL: -29.5619)\nüíæ Best Laplace LL model saved: -29.5619 (MAE: 2395.4 mL)\n------------------------------------------------------------\nEpoch 6/30\nTrain - Loss: 86.094361 | MAE: 2621.1 mL\nVal   - Loss: 20.045151 | MAE: 2336.3 mL\nVal   - R¬≤: -8.8092 | Correlation: 0.3508\nVal   - Laplace LL: -13.742822\nVal   - RMSE: 2463.1 mL\n‚úÖ NEW BEST MAE! Model saved: 2336.3 mL (Laplace LL: -13.7428)\nüíæ Best Laplace LL model saved: -13.7428 (MAE: 2336.3 mL)\n------------------------------------------------------------\nEpoch 7/30\nTrain - Loss: 14.119582 | MAE: 2538.7 mL\nVal   - Loss: 8.643306 | MAE: 2243.9 mL\nVal   - R¬≤: -8.1395 | Correlation: -0.2626\nVal   - Laplace LL: -9.789242\nVal   - RMSE: 2377.5 mL\n‚úÖ NEW BEST MAE! Model saved: 2243.9 mL (Laplace LL: -9.7892)\nüíæ Best Laplace LL model saved: -9.7892 (MAE: 2243.9 mL)\n------------------------------------------------------------\nEpoch 8/30\nTrain - Loss: 9.449272 | MAE: 2426.6 mL\nVal   - Loss: 8.230248 | MAE: 2128.4 mL\nVal   - R¬≤: -7.3071 | Correlation: 0.1151\nVal   - Laplace LL: -9.440137\nVal   - RMSE: 2266.7 mL\n‚úÖ NEW BEST MAE! Model saved: 2128.4 mL (Laplace LL: -9.4401)\nüíæ Best Laplace LL model saved: -9.4401 (MAE: 2128.4 mL)\n------------------------------------------------------------\nEpoch 9/30\nTrain - Loss: 9.391480 | MAE: 2280.3 mL\nVal   - Loss: 8.223007 | MAE: 1966.3 mL\nVal   - R¬≤: -6.2887 | Correlation: -0.5028\nVal   - Laplace LL: -9.341562\nVal   - RMSE: 2123.2 mL\n‚úÖ NEW BEST MAE! Model saved: 1966.3 mL (Laplace LL: -9.3416)\nüíæ Best Laplace LL model saved: -9.3416 (MAE: 1966.3 mL)\n------------------------------------------------------------\nEpoch 10/30\nTrain - Loss: 9.199685 | MAE: 2101.8 mL\nVal   - Loss: 8.093060 | MAE: 1798.5 mL\nVal   - R¬≤: -5.1860 | Correlation: 0.4057\nVal   - Laplace LL: -9.341042\nVal   - RMSE: 1956.0 mL\n‚úÖ NEW BEST MAE! Model saved: 1798.5 mL (Laplace LL: -9.3410)\nüíæ Best Laplace LL model saved: -9.3410 (MAE: 1798.5 mL)\n------------------------------------------------------------\nEpoch 11/30\nTrain - Loss: 9.121422 | MAE: 1853.1 mL\nVal   - Loss: 7.799899 | MAE: 1534.2 mL\nVal   - R¬≤: -3.7643 | Correlation: 0.4628\nVal   - Laplace LL: -9.026866\nVal   - RMSE: 1716.6 mL\n‚úÖ NEW BEST MAE! Model saved: 1534.2 mL (Laplace LL: -9.0269)\nüíæ Best Laplace LL model saved: -9.0269 (MAE: 1534.2 mL)\n------------------------------------------------------------\nEpoch 12/30\nTrain - Loss: 8.758810 | MAE: 1526.3 mL\nVal   - Loss: 7.632978 | MAE: 1191.5 mL\nVal   - R¬≤: -2.1888 | Correlation: 0.4509\nVal   - Laplace LL: -8.757050\nVal   - RMSE: 1404.4 mL\n‚úÖ NEW BEST MAE! Model saved: 1191.5 mL (Laplace LL: -8.7571)\nüíæ Best Laplace LL model saved: -8.7571 (MAE: 1191.5 mL)\n------------------------------------------------------------\nEpoch 13/30\nTrain - Loss: 8.317267 | MAE: 1126.7 mL\nVal   - Loss: 7.127071 | MAE: 807.7 mL\nVal   - R¬≤: -0.8890 | Correlation: 0.2517\nVal   - Laplace LL: -8.185665\nVal   - RMSE: 1080.9 mL\n‚úÖ NEW BEST MAE! Model saved: 807.7 mL (Laplace LL: -8.1857)\nüíæ Best Laplace LL model saved: -8.1857 (MAE: 807.7 mL)\n------------------------------------------------------------\nEpoch 14/30\nTrain - Loss: 8.095383 | MAE: 804.0 mL\nVal   - Loss: 6.884507 | MAE: 608.3 mL\nVal   - R¬≤: -0.0908 | Correlation: 0.7968\nVal   - Laplace LL: -7.949955\nVal   - RMSE: 821.4 mL\n‚úÖ NEW BEST MAE! Model saved: 608.3 mL (Laplace LL: -7.9500)\nüíæ Best Laplace LL model saved: -7.9500 (MAE: 608.3 mL)\n------------------------------------------------------------\nEpoch 15/30\nTrain - Loss: 7.969329 | MAE: 637.8 mL\nVal   - Loss: 6.761545 | MAE: 478.6 mL\nVal   - R¬≤: 0.2983 | Correlation: 0.8669\nVal   - Laplace LL: -7.790924\nVal   - RMSE: 658.8 mL\n‚úÖ NEW BEST MAE! Model saved: 478.6 mL (Laplace LL: -7.7909)\nüíæ Best Laplace LL model saved: -7.7909 (MAE: 478.6 mL)\n------------------------------------------------------------\nEpoch 16/30\nTrain - Loss: 7.899698 | MAE: 498.0 mL\nVal   - Loss: 6.714815 | MAE: 401.7 mL\nVal   - R¬≤: 0.4574 | Correlation: 0.8714\nVal   - Laplace LL: -7.639302\nVal   - RMSE: 579.3 mL\n‚úÖ NEW BEST MAE! Model saved: 401.7 mL (Laplace LL: -7.6393)\nüíæ Best Laplace LL model saved: -7.6393 (MAE: 401.7 mL)\n------------------------------------------------------------\nEpoch 17/30\nTrain - Loss: 7.750191 | MAE: 441.8 mL\nVal   - Loss: 6.886021 | MAE: 360.5 mL\nVal   - R¬≤: 0.6217 | Correlation: 0.9088\nVal   - Laplace LL: -7.720009\nVal   - RMSE: 483.7 mL\n‚úÖ NEW BEST MAE! Model saved: 360.5 mL (Laplace LL: -7.7200)\n------------------------------------------------------------\nEpoch 18/30\nTrain - Loss: 7.622718 | MAE: 392.9 mL\nVal   - Loss: 6.817686 | MAE: 359.9 mL\nVal   - R¬≤: 0.6898 | Correlation: 0.9446\nVal   - Laplace LL: -7.761696\nVal   - RMSE: 438.0 mL\n‚úÖ NEW BEST MAE! Model saved: 359.9 mL (Laplace LL: -7.7617)\n------------------------------------------------------------\nEpoch 19/30\nTrain - Loss: 7.559010 | MAE: 387.8 mL\nVal   - Loss: 6.779141 | MAE: 342.9 mL\nVal   - R¬≤: 0.6575 | Correlation: 0.8969\nVal   - Laplace LL: -7.657681\nVal   - RMSE: 460.3 mL\n‚úÖ NEW BEST MAE! Model saved: 342.9 mL (Laplace LL: -7.6577)\n------------------------------------------------------------\nEpoch 20/30\nTrain - Loss: 7.450092 | MAE: 381.8 mL\nVal   - Loss: 6.400335 | MAE: 267.3 mL\nVal   - R¬≤: 0.8155 | Correlation: 0.9415\nVal   - Laplace LL: -7.320960\nVal   - RMSE: 337.8 mL\n‚úÖ NEW BEST MAE! Model saved: 267.3 mL (Laplace LL: -7.3210)\nüíæ Best Laplace LL model saved: -7.3210 (MAE: 267.3 mL)\n------------------------------------------------------------\nEpoch 21/30\nTrain - Loss: 7.451907 | MAE: 369.6 mL\nVal   - Loss: 6.538450 | MAE: 290.4 mL\nVal   - R¬≤: 0.7959 | Correlation: 0.9463\nVal   - Laplace LL: -7.458961\nVal   - RMSE: 355.3 mL\n------------------------------------------------------------\nEpoch 22/30\nTrain - Loss: 7.732823 | MAE: 376.5 mL\nVal   - Loss: 6.538032 | MAE: 292.9 mL\nVal   - R¬≤: 0.7906 | Correlation: 0.9457\nVal   - Laplace LL: -7.465319\nVal   - RMSE: 359.9 mL\n------------------------------------------------------------\nEpoch 23/30\nTrain - Loss: 7.435363 | MAE: 369.5 mL\nVal   - Loss: 6.330201 | MAE: 242.2 mL\nVal   - R¬≤: 0.8420 | Correlation: 0.9427\nVal   - Laplace LL: -7.224372\nVal   - RMSE: 312.6 mL\n‚úÖ NEW BEST MAE! Model saved: 242.2 mL (Laplace LL: -7.2244)\nüíæ Best Laplace LL model saved: -7.2244 (MAE: 242.2 mL)\n------------------------------------------------------------\nEpoch 24/30\nTrain - Loss: 7.187570 | MAE: 378.3 mL\nVal   - Loss: 6.772543 | MAE: 288.5 mL\nVal   - R¬≤: 0.7851 | Correlation: 0.9277\nVal   - Laplace LL: -7.554183\nVal   - RMSE: 364.5 mL\n------------------------------------------------------------\nEpoch 25/30\nTrain - Loss: 7.295136 | MAE: 356.7 mL\nVal   - Loss: 6.386492 | MAE: 259.7 mL\nVal   - R¬≤: 0.8092 | Correlation: 0.9440\nVal   - Laplace LL: -7.267075\nVal   - RMSE: 343.5 mL\n------------------------------------------------------------\nEpoch 26/30\nTrain - Loss: 7.447204 | MAE: 354.1 mL\nVal   - Loss: 6.440166 | MAE: 254.9 mL\nVal   - R¬≤: 0.8200 | Correlation: 0.9306\nVal   - Laplace LL: -7.297576\nVal   - RMSE: 333.7 mL\n------------------------------------------------------------\nEpoch 27/30\nTrain - Loss: 7.390135 | MAE: 353.7 mL\nVal   - Loss: 6.319900 | MAE: 263.4 mL\nVal   - R¬≤: 0.8147 | Correlation: 0.9402\nVal   - Laplace LL: -7.268272\nVal   - RMSE: 338.6 mL\n------------------------------------------------------------\nEpoch 28/30\nTrain - Loss: 7.361809 | MAE: 358.5 mL\nVal   - Loss: 6.359122 | MAE: 261.8 mL\nVal   - R¬≤: 0.7992 | Correlation: 0.9399\nVal   - Laplace LL: -7.250670\nVal   - RMSE: 352.4 mL\n------------------------------------------------------------\nEpoch 29/30\nTrain - Loss: 7.267698 | MAE: 360.1 mL\nVal   - Loss: 6.194027 | MAE: 215.3 mL\nVal   - R¬≤: 0.8498 | Correlation: 0.9377\nVal   - Laplace LL: -7.039012\nVal   - RMSE: 304.8 mL\n‚úÖ NEW BEST MAE! Model saved: 215.3 mL (Laplace LL: -7.0390)\nüíæ Best Laplace LL model saved: -7.0390 (MAE: 215.3 mL)\n------------------------------------------------------------\nEpoch 30/30\nTrain - Loss: 7.465452 | MAE: 357.8 mL\nVal   - Loss: 6.364793 | MAE: 271.4 mL\nVal   - R¬≤: 0.7968 | Correlation: 0.9170\nVal   - Laplace LL: -7.300376\nVal   - RMSE: 354.5 mL\n------------------------------------------------------------\n\nüèÜ Training Summary:\n   Best Validation MAE: 215.329227\n   Best Laplace Log Likelihood: -7.039012\n\nüéØ Training completed!\n   Best MAE: 215.329227\n   Best Laplace LL: -7.039012\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}